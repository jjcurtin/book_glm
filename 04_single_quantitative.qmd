--- 
editor_options:  
  chunk_output_type: console
--- 
 

# Unit 4: Inferences About a Single Quantitative Predictor

```{r}
#| echo: false

options(scipen = 999) # turns off scientfic notation


sse <- function(model) {
  sum(residuals(model)^2)
}
```

## Two Parameter (One Predictor) Models

We started with a very simple model of FPS:

$\hat{FPS}= \beta_0$     

\

- However, we measured their FPS in the context of an experiment where some of the participants were sober and some were given alcohol.   
- And although we standardized the alcohol dose, participants who were given alcohol achieved varying blood alcohol concentrations (BAC)
- Luckily, we measured their BAC as part of the experiment.

-----

::: {.callout-important}
# Question

How could we uses their BACs to build a better model of the FPS scores?  What would the model look like?  What question(s) does this model allow us to test?
:::

:::{.fragment}
[**DATA = MODEL + ERROR**]{style="color:blue;"}

- $Y_i= \beta_0+\beta_1*X_1+\varepsilon_i$

- $\hat{Y}_i=\beta_0+\beta_1*X_1$

- $\varepsilon_i = Y_i - \hat{Y}_i$

\

$\hat{FPS}_i=\beta_0+\beta_1*BAC_i$

[We could use this model to test two questions:]{style="color:blue;"}

- [The relationship between BAC and FPS scores]{style="color:blue;"}
- [The typical FPS scores for participants with a specific value for BAC (default is BAC = 0)]{style="color:blue;"}

[Each of these questions will be linked to a test of a specific parameter in the model.]{style="color:blue;"}
:::

-----

```{r}
#| message: false
#| echo: false

library(tidyverse)
library(patchwork)

theme_set(theme_classic()) 

path_data <- "data_lecture" 

data <- read_csv(here::here(path_data, "04_single_quantitative_bac_fps.csv"),
                 show_col_types = FALSE)
```

```{r}
#| echo: false

m_1 <- lm(fps ~ 1, data = data)   
m_2 <- lm(fps ~ 1 + bac, data = data) 
```


```{r}
#| echo: false

plot_mean <- data |> 
  ggplot(aes(x = "", y = fps)) +
  geom_jitter(width = 0.1, alpha = .6, size = 2) +
  theme(axis.line.x = element_blank(),
        axis.ticks.x = element_blank()) +
  xlab(NULL) +
  geom_abline(aes(intercept = coef(m_1),
                  slope = 0),
              color = "blue", linewidth = 1)

plot_x <- data |> 
  ggplot(aes(x = bac, y = fps)) +
  geom_point(alpha = .6, size = 2) +
  geom_abline(aes(intercept = coef(m_2)[1],
                  slope = coef(m_2)[2]),
              color = "red", linewidth = 1) +
  xlim(0, .15)
```

```{r}
#| echo: false  

plot_mean + (plot_x + geom_abline(aes(intercept = coef(m_1),
                                      slope = 0),
                                  color = "blue", linewidth = 1))
```

-----

## The Two Parameter Model

$\hat{Y}_i=\beta_0+\beta_1*X_1$    

As before, the population parameters in the model ($\beta_0, \beta_1$) are estimated by $b_0$ & $b_1$ calculated from sample data based on the least squares criterion such that they minimize SSE in the sample data.    

\

**Sample model:**   
$\hat{Y}_i=b_0+b_1*X_1$    

\

- To derive these parameter estimates you must solve a series of simultaneous equations using linear algebra and matrices (see supplemental reading).    
- Or use R!

-----

## Least Squares Criterion

$e_i = Y_i- \hat{Y}_i$    

$SSE = \sum e_i^2$   


```{r}
#| echo: false

# add lines to residuals

plot_mean + plot_x
```

-----

## Interpretation of $b_0$ in Two Parameter Model

$\hat{Y}_i=b_0+b_1*X_1$    

- $b_0$ is predicted value for $Y$ when $X_1$ = 0. 
- Graphically, this is the $Y$ intercept for the regression line (value of $Y$ where regression line crosses Y-axis at $X_1$ = 0).  


```{r}
#| echo: false

plot_x
```

-----

::: {.callout-important}
# Question
Approximately what is $b_0$ in this example?
:::

:::{.fragment}
[42.5]{style="color:blue;"}
:::


```{r}
#| echo: false

plot_x + 
  geom_abline(aes(intercept = coef(m_1),
                  slope = 0),
              color = "blue", linewidth = 1)
```

-----

```{r}
#| echo: false

plot_x + 
  geom_abline(aes(intercept = coef(m_1),
                  slope = 0),
              color = "blue", linewidth = 1)
```

::: {.callout-important}
# Question
Notice that $b_0$ is very different in the two parameter model (42.5) than in the previous one parameter model (32.2).  Why?
:::

:::{.fragment}
[In the one parameter model $b_0$ was our sample estimate of the mean FPS score in everyone. $b_0$ in the two parameter model is our sample estimate of the mean FPS score for people with BAC = 0, not everyone.]{style="color:blue;"}
:::

-----

## Interpretation of $b_1$ in Two Parameter Model


$\hat{Y}_i=b_0+b_1*X_1$    

$b_1$ is the predicted change in $Y$ for every one unit change in $X_1$. Graphically it is represented by the slope of the regression line. If you understand the units of your predictor and DV, this is an attractive description of their relationship.   

\

$\hat{FPS}_i=42.5+ -184.1*BAC_i$    

- For every 1% increase in BAC, FPS decreases by 184.1 microvolts.    

- For every .01% increase in BAC, FPS decreases by 1.841 microvolts.  

```{r}
#| echo: false

plot_x
```

-----

## Testing Inferences about $\beta_1$

Does alcohol affect people’s fear/anxiety?

$\hat{FPS}_i=\beta_0+\beta_1*BAC_i$    

::: {.callout-important}
# Question
What are your null and alternative hypotheses about a model parameter to evaluate this question?
:::

:::{.fragment}
$H_0: \beta_1=0$    
$H_a: \beta_1 \neq 0$

\

[If $\beta_1 = 0$, this means that FPS does not change with changes in BAC. In other words, there is no effect of BAC on FPS.]{style="color:blue;"}

[If $\beta_1 < 0$, this means that FPS decreases with increasing BAC (people are less anxious when drunk).]{style="color:blue;"}

[If $\beta_1 > 0$, this means FPS increases with increasing BAC (people are more anxious when drunk).]{style="color:blue;"}
:::

-----

## Estimating a Two Parameter Model in R

Set up our environment

\

```{r}
#| message: false

options(conflicts.policy = "depends.ok") 
library(tidyverse)
library(broom)
library(patchwork)

theme_set(theme_classic()) 

path_data <- "data_lecture" 

data <- read_csv(here::here(path_data, "04_single_quantitative_bac_fps.csv"),
                 show_col_types = FALSE)
```

-----

Skim the data

```{r}
data |> 
  skimr::skim_without_charts()
```

-----

Fit the model (i.e., get our parameter estimates).  

Note that the `1` is not needed but I include it for now to make it clear that we are fitting a model with an intercept.  We will remove it later.

\

```{r}
m_2 <- lm(fps ~ 1 + bac, data = data)

m_2 |> 
  tidy()
```

-----

```{r}
m_2 |> 
  tidy()
```

::: {.callout-important}
# Question
Does BAC affect FPS? Explain this conclusion in terms of the parameter estimate, $b_1$ and its standard error.
:::

:::{.fragment}
[Under the $H_0: \beta_1 = 0$, the sampling distribution for $b_1$ will have a mean of 0 with an estimated standard deviation `r round(subset(tidy(m_2), term == "bac")$std.error, 2)`]{style="color:blue;"}

- [$t (`r nrow(data)` - 1) = \frac{`r round(subset(tidy(m_2), term == "bac")$estimate, 2)` - 0}{`r round(subset(tidy(m_2), term == "bac")$std.error, 2)` } = `r round(subset(tidy(m_2), term == "bac")$estimate/subset(tidy(m_2), term == "bac")$std.error, 2)`$]{style="color:blue;"}

[Our value of the parameter estimate, $b_1$, is `r abs(round(subset(tidy(m_2), term == "bac")$estimate/subset(tidy(m_2), term == "bac")$std.error, 2))` standard deviations below the expected mean of the sampling distribution for $b_0$ given $H_0$.]{style="color:blue;"}

```{r}
pt(-1.92, 94, lower.tail = TRUE) * 2
```

[A $b_1$ of this size is not unlikely under the null, therefore you fail to reject the null and conclude that BAC has no effect on FPS.]{style="color:blue;"}
:::

-----

## Testing Inferences about $\beta_1$

```{r}
m_2 |> 
  tidy()
```

\

**Two tailed p-value**:     

$H_0: \beta_1 = 0$   
$H_1: \beta_1 \neq 0$

```{r}
pt(-1.92, 94, lower.tail = TRUE) * 2
```

-----

**Two tailed p-value**:     

\

```{r}
#| code-fold: true
 
tibble(b1 = seq(-400,400,.01),
       probability = dt(b1/subset(tidy(m_2), term == "bac")$std.error, m_2$df.residual)) |> 
  ggplot(aes(x = b1, y = probability)) +
  geom_line() +
  geom_vline(xintercept = subset(tidy(m_2), term == "bac")$estimate, 
             color = "red") +
  geom_vline(xintercept = -subset(tidy(m_2), term == "bac")$estimate, 
             color = "red") +
  labs(title = "Sampling Distribution for b1")
```

-----

**One tailed p-value**:   

$H_0: \beta_1 = 0$   
$H_1: \beta_1 < 0$
```{r}
pt(-1.92, 94, lower.tail = TRUE)
```

```{r}
#| code-fold: true

tibble(b1 = seq(-400,400,.01),
       probability = dt(b1/subset(tidy(m_2), term == "bac")$std.error, m_2$df.residual)) |> 
  ggplot(aes(x = b1, y = probability)) +
  geom_line() +
  geom_vline(xintercept = subset(tidy(m_2), term == "bac")$estimate, 
             color = "red") +
  labs(title = "Sampling Distribution for b1")
```

-----

## Model Comparison: Testing Inferences about $\beta_1$

$H_0: \beta_1 = 0$   
$H_1: \beta_1 \neq 0$    


::: {.callout-important}
# Question
What two models are you comparing when you test hypotheses about $\beta_1$? Describe the logic.
:::

:::{.fragment}
[Compact model:]{style="color:blue;"}

- $\hat{FPS}_i = \beta_0+0*BAC_i$
- $P_c=1$     
- $SSE_c=`r round(sse(m_1), 1)`$     

\

[Augmented model:]{style="color:blue;"} 

- $\hat{FPS}_i = \beta_0+\beta_1*BAC_i$
- $P_a=2$   
- $SSE_a=`r round(sse(m_2), 1)`$  

\

$F(P_a-P_c, N-P_a) = \frac{SSE_c-SSE_a/(P_a-P_c)}{SSE_a/(N-P_a)}$

F(1,94) = 3.685, p = 0.058
:::

-----

You can use the `anova()` function to explicitly compare the two models and calculate the F-statistic and p-value for the comparison
```{r}
m_1 <- lm(fps ~ 1, data = data)   
m_2 <- lm(fps ~ 1 + bac, data = data) 
```

```{r}
anova(m_1, m_2)
```

but this comparison is statistically equivalent to the t-test of $b_1$ = 0 (and that takes less code to write!)

```{r}
m_2 |> 
  tidy()
```

  
-----

## Sum of Squared Errors

::: {.callout-important}
# Question
If there is a perfect relationship between $X_1$ and $Y$ in your sample, what will the SSE be in the two parameter model (augmented) and why?
:::

:::{.fragment}
[$SSE_a=0$. All data points will fall perfectly on the regression line. All errors will be 0.]{style="color:blue;"}
:::

-----

::: {.callout-important}
# Question
If there is no relationship at all between $X_1$ and $Y$ in your sample ($b_1$ = 0), what will the SSE be in the two parameter model (augmented) and why?
:::

:::{.fragment}
[$SSE_a=SSE$ of the mean-only model. $X_1$ provides no additional information about the DV. Your best prediction will still be the mean of the DV.]{style="color:blue;"}
:::

-----

## Testing Inferences about $\beta_0$

```{r}
m_2 |> 
  tidy()
```

::: {.callout-important}
# Question
What is the interpretation of $b_0$ in this two parameter model?
:::

:::{.fragment}
[It is the predicted FPS for a person with BAC = 0 (sober).]{style="color:blue;"}

\

[The test of this parameter estimate could inform us if the shock procedure worked among our sober participants. This is probably a more appropriate manipulation check than testing if it worked in everyone including drunk people given that alcohol could have reduced FPS.]{style="color:blue;"}
:::

-----

```{r}
#| echo: false

plot_x
```

-----





::: {.callout-important}
# Question
What two models are being compared?
:::

:::{.fragment}
[Compact model:]{style="color:blue;"}

- $\hat{FPS}_i= 0 + \beta_1* BAC_i$

\

[Augmented model:]{style="color:blue;"}

- $\hat{FPS}_i= \beta_0 + \beta_1* BAC_i$
:::
 
-----

## Mean Centering Predictor Variables

In this example, I have been using raw BAC. In many instances, we will **mean center** our quantitative predictor variables.    

\

Mean centering simply involves subtracting the mean of the predictor variable from all scores for that predictor variable.    

-----

```{r}
data <- data |> 
  mutate(bac_c = bac - mean(bac)) #<1>
```

1. We use `mutate()` to update and create new variables (e.g., centered quantitative predictors, changing character variables to factors).   

-----

```{r}
data |> 
  select(starts_with("bac")) |> 
  pivot_longer(everything(), names_to = "var") |> #<1>
  group_by(var) |> 
  summarize(mean = mean(value), 
            sd = sd(value), 
            min = min(value), 
            max = max(value)) |> 
  mutate(across(mean:max, ~round(.x, 2))) #<2>
```

1. `pivot_longer()` and `pivot_wider()` are two tidy functions for transforming your data frame (i.e., wide to long data frame and long to wide data frame).  
2. Here we use `mutate()` again, but are now combing it with `across()` so that we can apply our transformation (rounding to 2 decimal places) to several variables in one statement.   

-----

```{r}
m_2 |> 
  tidy()
```

\

::: {.callout-important}
# Question
How would the parameter estimates and interpretations change if I mean centered BAC?
:::

:::{.fragment}

```{r}
m_2_c <- lm(fps ~ 1 + bac_c, data = data)  

m_2_c |> 
  tidy()
```

\

[The value and interpretation of $b_0$ will change because it is the predicted FPS score at 0 on $X$. $b_0$ is now the predicted value for someone with the mean BAC in the sample.]{style="color:blue;"}

[But there is no change to interpretation of $b_1$. Why? Think about it...]{style="color:blue;"}
:::

-----

## Raw vs. Centered BAC

::: {.callout-important}
# Question
How would the graphs look different when using raw vs. mean-centered BAC? Connect this to your understanding of how centering BAC affects the parameter estimates
:::

:::{.fragment}

```{r}
#| code-fold: true

plot_x <- data |> 
  ggplot(aes(x = bac, y = fps)) +
  geom_point(alpha = .6, size = 2) +
  geom_abline(aes(intercept = coef(m_2)[1],
                  slope = coef(m_2)[2]),
              color = "red", linewidth = 1) +
  xlim(-.075, .15)


plot_x_c <- data |> 
  ggplot(aes(x = bac_c, y = fps)) +
  geom_point(alpha = .6, size = 2) +
  geom_abline(aes(intercept = coef(m_2_c)[1],
                  slope = coef(m_2_c)[2]),
              color = "red", linewidth = 1) +
  xlim(-.075, .15)

plot_x + plot_x_c
```

[The slope of the line is not changed and therefore $b_1$ has not changed.  The y-intercept has changed and therefore $b_0$ did change.]{style="color:blue;"}
:::

-----

## Confidence Interval for $b_j$ or $b_0$

You can provide confidence intervals for each parameter estimate in your model.  

```{r}
confint(m_2)
```

\

The underlying logic from your understanding of sampling distributions remains the same.   

$CI_b = b\pm t(\alpha; N-P)*SE_b$ where $P$ = total # of parameters.    

-----

```{r}
confint(m_2)
```

::: {.callout-important}
# Question
How can we tell if a parameter is **significant** from the confidence interval?
:::

:::{.fragment}
[If a parameter $\neq 0$, at $\alpha$ = .05, then the 95% confidence interval should not include 0]{style="color:blue;"}

- [This is true for any $b$ (e.g., $b_0$, $b_1$)]{style="color:blue;"}
- [You can also compare $\beta$ to any other non-zero value as well]{style="color:blue;"}
:::

-----

## Partial Eta Squared ($\eta_p^2$) or PRE for $\beta_1$


::: {.callout-important}
# Question
How can you calculate the effect size estimate $\eta_p^2$ (PRE) for $\beta_1$?
:::

:::{.fragment}
[Compare the SSE across the two relevant models.]{style="color:blue;"}


**Compact model:** 

- $\hat{FPS}_i= \beta_0 + 0* BAC_i$     
- $SSE_c =  `r round(sse(m_1), 1)`$   

**Augmented model:** 

- $\hat{FPS}_i= \beta_0 + \beta_1* BAC_i$  
- $SSE_a =  `r round(sse(m_2), 1)`$    

\

$\frac{SSE_c - SSE_a}{SSE_c}=\frac{`r round(sse(m_1), 1)`- `r round(sse(m_2), 1)`}{`r round(sse(m_1), 1)`}= `r round((sse(m_1) -  sse(m_2)) / sse(m_1), 3)`$ 

\

```{r}
(sum(residuals(m_1)^2) - sum(residuals(m_2)^2)) / sum(residuals(m_1)^2) 
```

\

[Our augmented model that includes a non-zero effect for BAC reduces prediction error (SSE) by only `r round((sse(m_1) - sse(m_2)) / sse(m_1), 3) * 100`% over the compact model that fixes this parameter at 0.]{style="color:blue;"}
:::

-----


::: {.callout-important}
# Question
How can you calculate the effect size estimate $\eta_p^2$ (PRE) for $\beta_0$?
:::

:::{.fragment}
[Compare the SSE across the two relevant models.]{style="color:blue;"}

\

```{r}
m_2_0 <- lm(fps ~ 0 + bac, data = data) #<1>
```
1. We can use 0 to remove the intercept (i.e., set it equal to 0) from our new compact model.

\

**Compact model:** 
 
- $\hat{FPS}_i= 0 + \beta_1* BAC_i$**   
- $SSE_c =  `r round(sse(m_2_0), 1)`$   

**Augmented model:**

- $\hat{FPS}_i= \beta_0 + \beta_1* BAC_i$
- $SSE_a =  `r round(sse(m_2), 1)`$     

\

$\frac{SSE_c - SSE_a}{SSE_c}=\frac{`r round(sse(m_2_0), 1)`- `r round(sse(m_2), 1)`}{`r round(sse(m_2_0), 1)`}= `r round((sse(m_2_0) - sse(m_2)) / sse(m_2_0), 3)`$  

\

```{r}
(sum(residuals(m_2_0)^2)- sum(residuals(m_2)^2))/sum(residuals(m_2_0)^2) 
```

\

[Our augmented model that allows FPS to be non-zero for people with BAC=0 (sober people) reduces prediction error (SSE) by `r round((sse(m_2_0) - sse(m_2)) / sse(m_2_0), 3) * 100`% from the model that fixes FPS at 0 when BAC=0!]{style="color:blue;"}
:::

-----

## Coefficient of Determination ($R^2$)

**Coefficient of Determination ($R^2$):**  Proportion of explained variance (i.e., proportion of variance in $Y$ accounted for by all $Xs$ in model).     

\

DATA = MODEL + ERROR    


For individuals:    

- $Y_i=Y_i+e_i$

\

With respect to variance:   

- $S_{Y_i}^2=S_{\hat{Y}_i}^2+S_{e_i}^2$    

- $R^2=\frac{S_{\hat{Y}_i}^2}{S_{Y_i}^2}$   

-----

We can calculate $R^2$ manually by computing the ratio of the variance of the predicted values to the variance of the actual values.   

\

```{r}
var(predict(m_2)) / var(data$fps)
```

-----

We can also use the `glance()` function in the `broom` package to return various model fit indices.  `glance()` returns a dataframe that we can `glimpse()`

```{r}
m_2 |> 
  glance() |>
  glimpse()
```

-----

Since we are only interested in $R^2$ we can use the following code to pull out this single value.

```{r}
glance(m_2)$r.squared
```

or more tidy....

```{r}
m_2 |> 
  glance() |>
  pull(r.squared)
```

-----

## $R^2$ and the Mean-Only Model

::: {.callout-important}
# Question?
Why did the mean-only model not have an $R^2$?
:::

:::{.fragment}
[It did but it was just 0. It explained no variance in $Y_i$ because it predicted the same value (mean) for every person. The variance of the predicted values is 0 in the mean-only model.]{style="color:blue;"}

- $R^2=\frac{S_{\hat{Y}_i}^2}{S_{Y_i}^2}$  

```{r}
m_1 <- lm(fps ~ 1, data = data)  

glance(m_1)$r.squared
```


[In fact, the SSE for the mean-only model is the numerator of the formula for the variance for $Y_i$.]{style="color:blue;"}

- $SSE=\frac{\sum(Y_i-\hat{Y_i})^2}{}$   
- $S^2 = \frac{\sum(Y_i-\overline{Y})^2}{N-1}$
:::

-----

This leads to an alternative formula for $R^2$ for an augmented model.   

$R^2=\frac{SSE_{mean-only}-SSE_a}{SSE_{mean-only}}$   

\

Mean-only model: $\hat{FPS}_i=\beta_0$    

- $SSE_{mean-only} = `r round(sse(m_1), 1)`$    


Augmented model: $\hat{FPS}_i=\beta_0 + \beta_1*BAC_i$     
 
- $SSE_a = `r round(sse(m_2), 1)`$   

\
$R^2= \frac{`r round(sse(m_1), 1)` - `r round(sse(m_2), 1)`}{`r round(sse(m_1), 1)`} = `r round((sse(m_1) - sse(m_2)) / sse(m_1), 5)`$    

\

In this augmented model, $R^2$ is fully accounted for by BAC. In more complex models, $R^2$ will be the aggregate of multiple predictors. $R^2$ is only defined for models that include $b_0$.   

-----

## Test of $\beta_1$ in Two Parameter Model: Special Case

::: {.callout-important}
# Question
When both the predictor variable and the dependent variable are quantitative, the test of $\beta_1$ = 0 is statistically equivalent to the what other common statistical test?  
:::

:::{.fragment}
[The test of the Pearson’s correlation coefficient]{style="color:blue;"}
:::

-----

```{r}
cor.test(data$bac, data$fps)
```

-----

Furthermore, $r^2=R^2$ for this 2 parameter model only

\

```{r}
round(cor.test(data$bac, data$fps)$estimate^2, 3)
```

\

```{r}
round((sum(residuals(m_1)^2) - sum(residuals(m_2)^2)) / sum(residuals(m_1)^2), 3)
```

-----

## Visualizing the Model

Your model is predicting the mean $Y$ for any $X$. 

- There is a sampling distribution around this mean. 
- The true population mean $Y$ for any $X$ is uncertain. 
- You can display this uncertainty by displaying information about the sampling distribution at any/every $X$.  
- This is equivalent to error bars in ANOVA.  
- There are several choices you have for how to display information about the sampling distribution for the mean (the uncertainty about the population mean)


## Predicted means with 95% Confidence Intervals

The first option is to present the predicted means with a shaded region that represents the 95% CIs for each predicted mean

- 95% of these intervals would be expected to contain the true population mean $Y$ for a given $X$ 
- First, we need values for BAC for which to make predictions.  We can put them into an dataframe 
 
\

```{r}
x <- tibble(bac = seq(from = min(data$bac), to = max(data$bac), by = .001))
```

-----

To get predicted mean FPS for each of these BACs, we use the `predict()` function

- We use the model object from `lm()`
- We pass that model into the `predict()` function, along with the data
- We set the `interval` to "confidence" and the appropriate `level`
- We then put the BACs into this dataframe to keep everything together (this could all be done in one pipeline but kept separate here to make it clearer)
\

```{r}
preds <- predict(m_2, x, interval = "confidence", level = .95) |> 
  as_tibble() 

preds <- preds |> 
  bind_cols(x)
```

-----

```{r}
preds  |> slice_head(n = 20)
```

-----

- We can now plot the raw data from the `data` dataframe
- We can plot the model line and confidence intervals using BACs and predicted Ys in `preds`

\

```{r}
ci_plot <- ggplot() +
  geom_point(aes(x = data$bac, y = data$fps), alpha = .6, size = 2) +
  geom_line(aes(x = preds$bac, y = preds$fit),
              color = "black", linewidth = 1) +
  geom_ribbon(aes(x = preds$bac, ymin = preds$lwr, ymax = preds$upr), alpha = 0.2) +
  labs(x = "BAC",
       y = "FPS") 
```

-----

```{r}
ci_plot
```

The confidence intervals for each predicted FPS score use the standard error for these predicted values.  

-----

::: {.callout-important}
# Question
Why are the error bands not linear?
:::


:::{.fragment}
[Model predictions are better (less error) near the center of your data ($X_i$).  The regression line will always go through mean of $X$ and $Y$. Small changes in $b_1$ across samples will produce bigger variation in $\hat{Y}_i$ at the edge of the model (far from the mean $X$).]{style="color:blue;"}

$\hat{FPS_i}=42.5 + -184.1 * BAC_i$    

$SE_\hat{Y_i}=\sqrt{\frac{SSE}{N-P}}*\sqrt{\frac{1}{N}+\frac{(X_i-\overline{X})^2}{(N-1)s_x^2}}$  

$CI_\hat{Y_i}=\hat{Y_i}\pm t(\alpha; N-k-1)SE_\hat{Y_i}$
:::

-----

Lets compare the SE for $b_0$ to the standard error for $\hat{Y_i}$ at different values of $X_i$.

\

$SE_\hat{Y_i}=\sqrt{\frac{SSE}{N-P}}*\sqrt{\frac{1}{N}+\frac{(X_i-\overline{X})^2}{(N-1)s_x^2}}$  

$SE_{b_0}=\sqrt{\frac{SSE}{N-P}}*\sqrt{\frac{1}{N}+\frac{(\overline{X})^2}{(N-1)s_x^2}}$   

\

- $b_0$ is simply the predicted value for $Y$ when $X$ = 0.

- We can use additive transformations of $X$ to make tests of the predicted value at  $X$ = 0. Most common in repeated measures designs but used elsewhere as well.


-----

## A Second Option for Displaying Model


In some disciplines, it is more common to display the uncertainty regarding predicted mean Y using +/- 1 SE rather than the full 95% CI (which is ~ +/- 2 SE)

\

We can get this out of `predict()` as well.

\

```{r}
preds <- predict(m_2, x, se.fit = TRUE) |> 
  as_tibble() 

preds <- preds |> 
  bind_cols(x) |> 
  mutate(upr = fit + se.fit, 
         lwr = fit - se.fit)
```

-----

```{r}
preds  |> slice_head(n = 20)
```

-----


```{r}
se_plot <- ggplot() +
  geom_point(aes(x = data$bac, y = data$fps), alpha = .6, size = 2) +
  geom_line(aes(x = preds$bac, y = preds$fit),
              color = "black", linewidth = 1) +
  geom_ribbon(aes(x = preds$bac, ymin = preds$lwr, ymax = preds$upr), alpha = 0.2) +
  labs(x = "BAC",
       y = "FPS") 
```


```{r}
se_plot
```

-----

There is a final plot that you will not see often but is worth understanding conceptually.  In this plot we represent uncertainty about the predictions for individuals rather than the mean Y.  

- This is called a prediction interval, rather than a confidence interval
- You can get this interval from `predict()` as well
- This plot uses the approximately 2 SEE around the predicted means
- 95% of these intervals will capture any raw Y in the population

```{r}
preds <- predict(m_2, x, interval = "prediction", level = 0.95) |> 
  as_tibble() 

preds <- preds |> 
  bind_cols(x)
```

-----

```{r}
preds  |> slice_head(n = 20)
```

-----

```{r}
pred_plot <- ggplot() +
  geom_point(aes(x = data$bac, y = data$fps), alpha = .6, size = 2) +
  geom_line(aes(x = preds$bac, y = preds$fit),
              color = "black", linewidth = 1) +
  geom_ribbon(aes(x = preds$bac, ymin = preds$lwr, ymax = preds$upr), alpha = 0.2) +
  labs(x = "BAC",
       y = "FPS")

pred_plot 
```

-----

## Look at what we now know!!!


- We now understand how to create a two parameter model of $\hat{Y}$ based on a single predictor variable coded as $X$
- We understand how to interpret the parameter estimates in this model ($b_0$ and $b_1$)
- We understand that these parameters are estimated such that the minimize the SSE in our sample
- We understand how to form null and alternative hypotheses about these parameters
- We can test those hypotheses using either a t-test based on the sampling distribution for the parameter estimate or an F-test comparing the augmented model to a compact model
- We understand how to interpret the t-statistic in terms of standard deviations from the mean of the sampling distribution under the null
- For the model comparison approach, we can specify the form of the compact model and augmented model for tests of $\Beta_0$ and $\Beta_1$
- We know how to calculate and interpret confidence intervals for these parameters
- We know how to calculate and interpret an effect size estimate ($\eta_p^2$ or PRE) for these parameters
- We know how to calculate and interpret $R^2$ for the overall model both in terms of variance explained and in terms of reduction in SSE from the mean-only model
- We know how to visualize these models