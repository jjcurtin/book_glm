{
  "hash": "4e29004fb0b06c7104f223606cd291f7",
  "result": {
    "engine": "knitr",
    "markdown": "--- \noutput: html_document \neditor_options:  \n  chunk_output_type: console\n--- \n\n\n\n \n\n# Inferences About a Single Quantitative Predictor\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Two Parameter (One Predictor) Models\n\nWe started with a very simple model of FPS: $\\hat{\\text{FPS}}= \\beta_0$     \n\nWhat if some participants were drunk and we knew their blood alcohol concentrations (BAC)?    \n\n<span style=\"color: red;\">Question: Would it help?  What would the model look like?  What question(s) does this model allow us to test?\n\n-----\n\n<span style=\"color: blue;\">**DATA = MODEL + ERROR**</span>    \n\n<span style=\"color: blue;\">$Y_i= \\beta_0+\\beta_1*X_1+\\varepsilon_i$</span>    \n\n<span style=\"color: blue;\">$\\hat{Y}_i=\\beta_0+\\beta_1*X_1$</span>    \n\n<span style=\"color: blue;\">$\\varepsilon_i = Y_i - \\hat{Y}_i$</span>    \n\n\\\n<span style=\"color: blue;\">$\\hat{\\text{FPS}}_i=\\beta_0+\\beta_1*\\text{BAC}_1$</span>\n\n\n-----\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n\n-----\n\n## The Two Parameter Model\n\n$\\hat{Y}_i=\\beta_0+\\beta_1*X_1$    \n\nAs before, the population parameters in the model ($\\beta_0, \\beta_1$) are estimated by $b_0$ & $b_1$ calculated from sample data based on the least squares criterion such that they minimize SSE in the sample data.    \n\n**Sample model:**   \n$\\hat{Y}_i=b_0+b_1*X_1$    \n\nTo derive these parameter estimates you must solve a series of simultaneous equations using linear algebra and matrices (see supplemental reading).    \n\nOr use R!\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\n-----\n\n## Least Squares Criterion\n\n$e_i = Y_i- \\hat{Y}_i$    \n\n$\\text{SSE} = \\sum e_i^2$   \n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n-----\n\n## Interpretation of $b_0$ in Two Parameter Model\n\n\n$\\hat{Y}_i=b_0+b_1*X_1$    \n\n$b_0$ is predicted value for $Y$ when $X_1$ = 0. Graphically, this is the $Y$ intercept for the regression line (value of $Y$ where regression line crosses Y-axis at $X_1$ = 0).  \n\n<span style=\"color: red;\">Question: Approximately what is $b_0$ in this example?</span>\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n<span style=\"color: blue;\">42.5</span>    \n\n*IMPORTANT: Notice that $b_0$ is very different in the two parameter model (42.5) than in the previous one parameter model (32.2).*    \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n\n<span style=\"color: red;\">Question: Why?   \n\n\n-----\n\n<span style=\"color: blue;\">In the one parameter model $b_0$ was our sample estimate of the mean FPS score in everyone. $b_0$ in the two parameter model is our sample estimate of the mean FPS score for people with BAC = 0, not everyone.</span>   \n\n\n-----\n\n## Interpretation of $b_1$ in Two Parameter Model\n\n\n$\\hat{Y}_i=b_0+b_1*X_1$    \n\n$b_1$ is the predicted change in $Y$ for every one unit change in $X_1$. Graphically it is represented by the slope of the regression line. If you understand the units of your predictor and DV, this is an attractive description of their relationship.   \n\n$\\hat{\\text{FPS}}_i=42.5+ -184.1*\\text{BAC}_i$    \n\nFor every 1% increase in BAC, FPS decreases by 184.1 microvolts.    \n\nFor every .01% increase in BAC, FPS decreases by 1.841 microvolts.  \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n-----\n\n## Testing Inferences about $\\beta_1$\n\nDoes alcohol affect people’s anxiety?\n\n$\\hat{\\text{FPS}}_i=\\beta_0+\\beta_1*\\text{BAC}_i$    \n\n\n<span style=\"color: red;\">Question: What are your null and alternative hypotheses about a model parameter to evaluate this question?</span>   \n\n-----\n\n<span style=\"color: blue;\">$H_0: \\beta_1=0$</span>    \n<span style=\"color: blue;\">$H_a: \\beta_1 \\neq 0$</span>   \n\n\nIf $\\beta_1 = 0$, this means that FPS does not change with changes in BAC. In other words, there is no effect of BAC on FPS. If $\\beta_1 < 0$, this means that FPS decreases with increasing BAC (people are less anxious when drunk).    \n\nIf $\\beta_1 > 0$, this means FPS increases with increasing BAC (people are more anxious when drunk).    \n\n-----\n\n## Estimating a Two Parameter Model in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(patchwork)\n\ntheme_set(theme_classic()) \n\npath_data <- \"data_lecture\" \n\ndata <- read_csv(here::here(path_data, \"4_single_quantitative_bac_fps.csv\"),\n                 show_col_types = FALSE)\n```\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  skimr::skim()\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |data |\n|Number of rows           |96   |\n|Number of columns        |3    |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |1    |\n|numeric                  |2    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|subid         |         0|             1|   4|   4|     0|       96|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|  mean|    sd|    p0|  p25|   p50|   p75|   p100|hist  |\n|:-------------|---------:|-------------:|-----:|-----:|-----:|----:|-----:|-----:|------:|:-----|\n|bac           |         0|             1|  0.06|  0.04|   0.0| 0.02|  0.06|  0.08|   0.14|▇▆▇▆▂ |\n|fps           |         0|             1| 32.19| 37.54| -98.1| 6.79| 19.46| 50.46| 162.74|▁▃▇▂▁ |\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_2 <- lm(fps ~ bac, data = data)\n\nm_2 |> \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  <chr>          <dbl>     <dbl>     <dbl>         <dbl>\n1 (Intercept)     42.5      6.55      6.48 0.00000000411\n2 bac           -184.      95.9      -1.92 0.0579       \n```\n\n\n:::\n:::\n\n\n\n\n\n\n<span style=\"color: red;\">Question: Does BAC affect FPS? Explain this conclusion in terms of the parameter estimate, $b_1$ and its standard error.</span>   \n\n-----\n\n\n<span style=\"color: blue;\">Under the $H_0: \\beta_1 = 0$, the sampling distribution for $\\beta_1$ will have a mean of 0 with an estimated standard deviation 95.89.</span>    \n\n$t (96 - 1) = \\frac{-184.09 - 0}{95.89 } = -1.92$     \n\n<span style=\"color: blue;\">Our value of the parameter estimate, $b_1$, is 1.92 standard deviations below the expected mean of the sampling distribution for $H_0$.</span>\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npt(-1.92, 94, lower.tail = TRUE)*2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.05788984\n```\n\n\n:::\n:::\n\n\n\n\n\nA $b_1$ of this size is not unlikely under the null, therefore you fail to reject the null and conclude that BAC has no effect on FPS.\n\n-----\n\n## Testing Inferences about $\\beta_1$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_2 |> \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  <chr>          <dbl>     <dbl>     <dbl>         <dbl>\n1 (Intercept)     42.5      6.55      6.48 0.00000000411\n2 bac           -184.      95.9      -1.92 0.0579       \n```\n\n\n:::\n:::\n\n\n\n\n**One tailed p-value**:   \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npt(-1.92, 94, lower.tail = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02894492\n```\n\n\n:::\n:::\n\n\n\n\n$H_0: \\beta_1 = 0$   \n$H_1: \\beta_1 < 0$\n\n-----\n\n**Two tailed p-value**:     \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npt(-1.92, 94, lower.tail = TRUE)*2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.05788984\n```\n\n\n:::\n:::\n\n\n\n\n\n$H_0: \\beta_1 = 0$   \n$H_1: \\beta_1 \\neq 0$\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntibble(b1 = seq(-400,400,.01),\n       probability = dt(b1/subset(broom::tidy(m_2), term == \"bac\")$std.error, m_2$df.residual)) |> \n  ggplot(aes(x = b1, y = probability)) +\n  geom_line() +\n  geom_vline(xintercept = subset(broom::tidy(m_2), term == \"bac\")$estimate, \n             color = \"red\") +\n  geom_vline(xintercept = -subset(broom::tidy(m_2), term == \"bac\")$estimate, \n             color = \"red\") +\n  labs(title = \"Sampling Distribution for b1\")\n```\n\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\n\n-----\n\n## Model Comparison: Testing Inferences about $\\beta_1$\n\n$H_0: \\beta_1 = 0$   \n$H_1: \\beta_1 \\neq 0$    \n\n\n<span style=\"color: red;\">Question: What two models are you comparing when you test hypotheses about $\\beta_1$? Describe the logic.</span>   \n\n-----\n\n<span style=\"color: blue;\">Compact model: $\\hat{\\text{FPS}}_i = \\beta_0+0*\\text{BAC}_i$</span>    \n<span style=\"color: blue;\">$P_c=1$</span>     \n<span style=\"color: blue;\">$\\text{SSE}_c=133888.3$</span>     \n\n\n<span style=\"color: blue;\">Augmented model: $\\hat{\\text{FPS}}_i = \\beta_0+\\beta_1*\\text{BAC}_i$</span>    \n<span style=\"color: blue;\">$P_a=2$</span>   \n<span style=\"color: blue;\">$\\text{SSE}_a=128837.1$</span>  \n\\\n$F(P_a-P_c, N-P_a) = \\frac{\\text{SSE}_c-\\text{SSE}_a/(P_a-P_c)}{\\text{SSE}_a/(N-P_a)}$\n\nF(1,94) = 3.685, p = 0.058\n\n-----\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_1 <- lm(fps ~ 1, data = data)   \nm_2 <-  lm(fps ~ bac, data = data) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(m_1, m_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: fps ~ 1\nModel 2: fps ~ bac\n  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  \n1     95 133888                              \n2     94 128837  1    5051.2 3.6854 0.05792 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n## Sum of Squared Errors\n\n<span style=\"color: red;\">Question: If there is a perfect relationship between $X_1$ and $Y$ in your sample, what will the SSE be in the two parameter model (augmented) and why?</span>   \n\n-----\n\n<span style=\"color: blue;\">$\\text{SSE}_a=0$. All data points will fall perfectly on the regression line. All errors will be 0.</span>\n\n-----\n\n<span style=\"color: red;\">Question: If there is no relationship at all between $X_1$ and $Y$ in your sample ($b_1$ = 0), what will the SSE be in the two parameter model (augmented) and why?</span>   \n\n-----\n\n<span style=\"color: blue;\">$\\text{SSE}_a=\\text{SSE}$ of the mean-only model. $X_1$ provides no additional information about the DV. Your best prediction will still be the mean of the DV.</span>\n\n-----\n\n## Testing Inferences about $\\beta_0$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_2 |> \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  <chr>          <dbl>     <dbl>     <dbl>         <dbl>\n1 (Intercept)     42.5      6.55      6.48 0.00000000411\n2 bac           -184.      95.9      -1.92 0.0579       \n```\n\n\n:::\n:::\n\n\n\n\n\n\n<span style=\"color: red;\">Question: What is the interpretation of $b_0$ in this two parameter model?</span>   \n\n-----\n\n<span style=\"color: blue;\">It is the predicted FPS for a person with BAC = 0 (sober).</span>   \n\n\n<span style=\"color: blue;\">The test of this parameter estimate could inform us if the shock procedure worked among our sober participants. This is probably a more appropriate manipulation check than testing if it worked in everyone including drunk people given that alcohol could have reduced FPS.</span>    \n\n-----\n\n<span style=\"color: red;\">Question: What two models are being compared?</span> \n\n-----\n \n<span style=\"color: blue;\">Compact model: $\\hat{\\text{FPS}}_i= 0 + \\beta_1* \\text{BAC}_i$</span>    \n\n<span style=\"color: blue;\">Augmented model: $\\hat{\\text{FPS}}_i= \\beta_0 + \\beta_1* \\text{BAC}_i$</span>\n\n-----\n\n## Mean Centering Predictor Variables\n\nIn this example, I have been using raw BAC. In many instances, we will *mean center* our quantitative predictor variables.    \n\n\nMean centering simply involves subtracting the mean of the predictor variable from all scores for that predictor variable.    \n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  mutate(bac_c = bac - mean(bac)) #<1>\n```\n:::\n\n\n\n\n1. We use `mutate()` to update and create new variables (e.g., centered quantitative predictors, changing character variables to factors).   \n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  select(starts_with(\"bac\")) |> \n  pivot_longer(everything(), names_to = \"var\") |> #<1>\n  group_by(var) |> \n  summarize(mean = mean(value), \n            sd = sd(value), \n            min = min(value), \n            max = max(value)) |> \n  mutate(across(mean:max, ~round(.x, 2))) #<2>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  var    mean    sd   min   max\n  <chr> <dbl> <dbl> <dbl> <dbl>\n1 bac    0.06  0.04  0     0.14\n2 bac_c  0     0.04 -0.06  0.08\n```\n\n\n:::\n:::\n\n\n\n\n1. `pivot_longer()` and `pivot_wider()` are two tidy functions for transforming your data frame (i.e., wide to long data frame and long to wide data frame).  \n2. Here we use `mutate()` again, but are now combing it with `across()` so that we can apply our transformation (rounding to 2 decimal places) to several variables in one statement.   \n\n-----\n\n<span style=\"color: red;\">Question: How would the parameter estimate values and interpretations change if I mean centered BAC?</span> \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_2 |> \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  <chr>          <dbl>     <dbl>     <dbl>         <dbl>\n1 (Intercept)     42.5      6.55      6.48 0.00000000411\n2 bac           -184.      95.9      -1.92 0.0579       \n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_2_c <- lm(fps ~ bac_c, data = data)  \n\nm_2_c |> \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     32.2      3.78      8.52 2.57e-13\n2 bac_c         -184.      95.9      -1.92 5.79e- 2\n```\n\n\n:::\n:::\n\n\n\n\n<span style=\"color: blue;\">The value and interpretation of $b_0$ will change because it is the predicted FPS score at 0 on $X$. $b_0$ is now the predicted value for someone with the mean BAC in the sample.</span>   \n\n<span style=\"color: blue;\">No change to interpretation of $b_1$. Why? Think about it...</span>\n\n-----\n\n## Raw vs. Centered BAC\n\n<span style=\"color: red;\">Question: How would the graph look different? Where is $b_0$ and $b_1$ on the new figure? Would you center BAC in this example?</span> \n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_x <- data |> \n  ggplot(aes(x = bac, y = fps)) +\n  geom_point(alpha = .6, size = 2) +\n  geom_abline(aes(intercept = coef(m_2)[1],\n                  slope = coef(m_2)[2]),\n              color = \"red\", linewidth = 1) +\n  xlim(0, .15)\n\n\nplot_x_c <- data |> \n  ggplot(aes(x = bac_c, y = fps)) +\n  geom_point(alpha = .6, size = 2) +\n  geom_abline(aes(intercept = coef(m_2)[1],\n                  slope = coef(m_2)[2]),\n              color = \"red\", linewidth = 1)\n```\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_x + plot_x_c\n```\n\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n## Confidence Interval for $b_j$ or $b_0$\n\nYou can provide confidence intervals for each parameter estimate in your model.  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfint(m_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %    97.5 %\n(Intercept)   29.45597 55.457721\nbac         -374.49261  6.308724\n```\n\n\n:::\n:::\n\n\n\n\nThe underlying logic from your understanding of sampling distributions remains the same.   \n\n$CI_b = b\\pm t(\\alpha; N-P)*SE_b$ where $P$ = total # of parameters.    \n\n\n<span style=\"color: red;\">Question: How can we tell if a parameter is *significant* from the confidence interval?</span>    \n\n-----\n\n<span style=\"color: blue;\">If a parameter $\\neq 0$, at $\\alpha$ = .05, then the 95% confidence interval should not include 0. True for any other non-zero value for $b$ as well.</span>  \n\n-----\n\n## Partial Eta Squared ($\\eta_p^2$) or PRE for $\\beta_1$\n\n<span style=\"color: red;\">Question: How can you calculate the effect size estimate $\\eta_p^2$ (PRE) for $\\beta_1$? </span>    \n\n-----\n\n<span style=\"color: blue;\">Compare the SSE across the two relevant models.</span>    \n\n**Compact model:** $\\hat{\\text{FPS}}_i= \\beta_0 + 0* \\text{BAC}_i$     \n\n$\\text{SSE}_c =  133888.3$   \n\n**Augmented model:** $\\hat{\\text{FPS}}_i= \\beta_0 + \\beta_1* \\text{BAC}_i$  \n\n$\\text{SSE}_a =  128837.1$    \n\n$\\frac{\\text{SSE}_c - \\text{SSE}_a}{\\text{SSE}_c}=\\frac{133888.3- 128837.1}{133888.3}= 0.038$ \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(sum(residuals(m_1)^2)- sum(residuals(m_2)^2))/sum(residuals(m_1)^2) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03772707\n```\n\n\n:::\n:::\n\n\n\n\n<span style=\"color: blue;\">Our augmented model that includes a non-zero effect for BAC reduces prediction error (SSE) by only 3.8% over the compact model that fixes this parameter at 0.</span>\n\n-----\n\n\n<span style=\"color: red;\">Question: How can you calculate the effect size estimate $\\eta_p^2$ (PRE) for $\\beta_0$? </span>  \n\n-----\n\n<span style=\"color: blue;\">Compare the SSE across the two relevant models.</span>  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_2_0 <- lm(fps ~ bac - 1, data = data) #<1>\n```\n:::\n\n\n\n\n1. We can use -1 to remove the intercept (i.e., set it equal to 0) from our new compact model.\n\n**Compact model: $\\hat{\\text{FPS}}_i= 0 + \\beta_1* \\text{BAC}_i$**   \n\n$\\text{SSE}_c =  186462.4$   \n\n**Augmented model: $\\hat{\\text{FPS}}_i= \\beta_0 + \\beta_1* \\text{BAC}_i$**   \n\n$\\text{SSE}_a =  128837.1$     \n\n\n$\\frac{\\text{SSE}_c - \\text{SSE}_a}{\\text{SSE}_c}=\\frac{186462.4- 128837.1}{186462.4}= 0.309$  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(sum(residuals(m_2_0)^2)- sum(residuals(m_2)^2))/sum(residuals(m_2_0)^2) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3090451\n```\n\n\n:::\n:::\n\n\n\n\n<span style=\"color: blue;\">Our augmented model that allows FPS to be non-zero for people with BAC=0 (sober people) reduces prediction error (SSE) by 30.9% from the model that fixes FPS at 0 when BAC=0!</span>   \n\n-----\n\n## Coefficient of Determination ($R^2$)\n\n**Coefficient of Determination ($R^2$):**    \nProportion of explained variance (i.e., proportion of variance in $Y$ accounted for by all $Xs$ in model).     \n\nDATA = MODEL + ERROR    \n\nFor individuals:    \n\n$Y_i=Y_i+e_i$\n\n\nWith respect to variance:   \n\n$S_{Y_i}^2=S_{\\hat{Y}_i}^2+S_{e_i}^2$    \n\n$R^2=\\frac{S_{\\hat{Y}_i}^2}{S_{Y_i}^2}$   \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar(predict(m_2))/ var(data$fps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03772707\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n## $R^2$ and the Mean-Only Model\n\n<span style=\"color: red;\">Question: Why did the mean-only model not have an $R^2$? </span>  \n\n-----\n\n<span style=\"color: blue;\">It did but it was just 0. It explained no variance in $Y_i$ because it predicted the same value (mean) for every person. The variance of the predicted values is 0 in the mean-only model.</span>    \n\n$R^2=\\frac{S_{\\hat{Y}_i}^2}{S_{Y_i}^2}$    \n\nIn fact, the SSE for the mean-only model is the numerator of the formula for the variance for $Y_i$.     \n\n$\\text{SSE}=\\frac{\\sum(Y_i-\\hat{Y_i})^2}{}$   \n\n$S^2 = \\frac{\\sum(Y_i-\\overline{Y})^2}{N-1}$\n\n-----\n\nThis leads to an alternative formula for $R^2$ for an augmented model.   \n\n$R^2=\\frac{\\text{SSE}_\\text{mean-only}-\\text{SSE}_a}{\\text{SSE}_\\text{mean-only}}$   \n\nMean-only model: $\\hat{\\text{FPS}}_i=\\beta_0$    \n\n$\\text{SSE}_{\\text{mean-only}} = 133888.3$    \n\nAugmented model: $\\hat{\\text{FPS}}_i=\\beta_0 + \\beta_1*\\text{BAC}_i$     \n \n$\\text{SSE}_a = 128837.1$   \n\n$R^2= \\frac{133888.3 - 128837.1}{133888.3} = 0.03773$    \n\nIn this augmented model, $R^2$ is fully accounted for by BAC. In more complex models, $R^2$ will be the aggregate of multiple predictors. $R^2$ is only defined for models that include $b_0$.   \n\n-----\n\n## Test of $\\beta_1$ in Two Parameter Model: Special Case\n\n<span style=\"color: red;\">Question: When both the predictor variable and the dependent variable are quantitative, the test of $\\beta_1$ = 0 is statistically equivalent to the what other common statistical test? </span> \n\n-----\n\n<span style=\"color: blue;\">The test of the Pearson’s correlation coefficient, r.</span>    \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npsych::corr.test(data$bac, data$fps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:psych::corr.test(x = data$bac, y = data$fps)\nCorrelation matrix \n[1] -0.19\nSample Size \n[1] 96\nThese are the unadjusted probability values.\n  The probability values  adjusted for multiple tests are in the p.adj object. \n[1] 0.06\n\n To see confidence intervals of the correlations, print with the short=FALSE option\n```\n\n\n:::\n:::\n\n\n\n\n**Furthermore, $r^2=R^2$ for this model only.**   \n\n$-0.194^2 = 0.038$\n\n-----\n\n## Visualizing the Model\n\nThe `effect()` function in the `effects` package can be used to quickly fit model values and calculate 95% confidence intervals for plotting the model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(e <- effects::effect('bac', m_2) |>  \n  as_tibble())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 5\n    bac   fit    se lower upper\n  <dbl> <dbl> <dbl> <dbl> <dbl>\n1 0      42.5  6.55 29.5   55.5\n2 0.035  36.0  4.27 27.5   44.5\n3 0.07   29.6  4.02 21.6   37.5\n4 0.1    24.0  5.68 12.8   35.3\n5 0.14   16.7  8.92 -1.02  34.4\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(e, aes(x = bac, y = fit)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +\n  labs(title = \"Effect of BAC\",\n       x = \"BAC\",\n       y = \"FPS\") \n```\n\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n## Error Band for $\\hat{Y}_i$\n\nYou are predicting the mean $Y$ for any $X$. There is a sampling distribution around this mean. The true population mean $Y$ for any $X$ is uncertain. You can display this uncertainty by displaying information about the sampling distribution at any/every $X$.  This is equivalent to error bars in ANOVA.   \n\nThe `effect()` function calculates 95% CI for $\\hat{Y}_i$. However, I prefer $\\pm$ 1 SE for publications.   \n\n$\\text{SEE} = \\sqrt{\\frac{\\text{SSE}}{N-P}}$   \n\n$SE_\\hat{Y_i}=\\text{SEE}\\sqrt{\\frac{1}{N}+\\frac{(X_i-\\overline{X})^2}{(N-1)s_x^2}}$  \n\n$CI_\\hat{Y_i}=\\hat{Y_i}\\pm t(\\alpha; N-k-1)SE_\\hat{Y_i}$\n\n\n-----\n\n<span style=\"color: red;\">Question: Why are the error bands not linear? </span> \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(e, aes(x = bac, y = fit)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +\n  labs(title = \"Effect of BAC\",\n       x = \"BAC\",\n       y = \"FPS\") \n```\n\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n<span style=\"color: blue;\">Model predictions are better (less error) near the center of your data ($X_i$).  The regression line will always go through mean of $X$ and $Y$. Small changes in $b_1$ across samples will produce bigger variation in $\\hat{Y}_i$ at the edge of the model (far from the mean $X$).</span>   \n\n$\\hat{\\text{FPS}_i}=42.5 + -184.1 * \\text{BAC}_i$    \n\n$SE_\\hat{Y_i}=\\sqrt{\\frac{\\text{SSE}}{N-P}}*\\sqrt{\\frac{1}{N}+\\frac{(X_i-\\overline{X})^2}{(N-1)s_x^2}}$  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfint(m_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %    97.5 %\n(Intercept)   29.45597 55.457721\nbac         -374.49261  6.308724\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n<span style=\"color: red;\">Compare to the SE for $b_0$. </span> \n\n-----\n\n$SE_\\hat{Y_i}=\\sqrt{\\frac{\\text{SSE}}{N-P}}*\\sqrt{\\frac{1}{N}+\\frac{(X_i-\\overline{X})^2}{(N-1)s_x^2}}$  \n\n$SE_{b_0}=\\sqrt{\\frac{\\text{SSE}}{N-P}}*\\sqrt{\\frac{1}{N}+\\frac{(\\overline{X})^2}{(N-1)s_x^2}}$   \n\n<span style=\"color: blue;\">$b_0$ is simply the predicted value for $Y$ when $X$ = 0.</span>    \n\n<span style=\"color: blue;\">We can use additive transformations of $X$ to make tests of the predicted value at  $X$ = 0. Most common in repeated measures designs but used elsewhere as well.</span>   \n\n\n-----\n\n## Publication Quality Figure\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- predict(m_2, data, se.fit = TRUE) |> #<1>\n  as_tibble() |> \n  mutate(upper = fit + se.fit,  #<2>\n         lower= fit - se.fit)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_pub <- preds |>  \n  ggplot() +\n  geom_point(aes(x = data$bac, y = data$fps), alpha = .6, size = 2) +\n  geom_line(aes(x = data$bac, y =fit),\n              color = \"black\", linewidth = 1) +\n  geom_ribbon(aes(x = data$bac, ymin = lower, ymax = upper), alpha = 0.2) +\n  labs(x = \"Blood alcohol concentration\",\n       y = \"Fear-potentiated startle\") \n```\n:::\n\n\n\n\n1. We can use our model to generate predictions. We use the `se.fit = TRUE` argument to return the standard error for each prediction.  \n\n2. We use `mutate()` to calculate $\\pm$ 1 standard error values for each prediction.   \n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_pub\n```\n\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-40-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n## Review of Concepts\n\n- $b_0, b_1$\n- NHSTs\n- Effect sizes\n- CIs\n- Conclusions\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_2 <- lm(fps ~ bac + 1, data = data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nm_2 |> \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  <chr>          <dbl>     <dbl>     <dbl>         <dbl>\n1 (Intercept)     42.5      6.55      6.48 0.00000000411\n2 bac           -184.      95.9      -1.92 0.0579       \n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\ndata |> \n  ggplot(aes(x = bac, y = fps)) +\n  geom_point(alpha = .6, size = 2) +\n  geom_abline(aes(intercept = coef(m_2)[1],\n                  slope = coef(m_2)[2]),\n              color = \"red\", linewidth = 1)\n```\n\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n:::\n\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_2_0 <- lm(fps ~ bac - 1, data = data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nm_2_0 |> \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  term  estimate std.error statistic    p.value\n  <chr>    <dbl>     <dbl>     <dbl>      <dbl>\n1 bac       324.      66.2      4.89 0.00000412\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\ndata |> \n  ggplot(aes(x = bac, y = fps)) +\n  geom_point(alpha = .6, size = 2) +\n  geom_abline(aes(intercept = 0,\n                  slope = coef(m_2_0)),\n              color = \"blue\", linewidth = 1)\n```\n\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_1 <- lm(fps ~ 1, data = data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nm_1 |> \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     32.2      3.83      8.40 4.26e-13\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\ndata |> \n  ggplot(aes(x = bac, y = fps)) +\n  geom_point(alpha = .6, size = 2) +\n  geom_abline(aes(intercept = coef(m_1),\n                  slope = 0),\n              color = \"blue\", linewidth = 1)\n```\n\n::: {.cell-output-display}\n![](04_single_quantitative_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "04_single_quantitative_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}