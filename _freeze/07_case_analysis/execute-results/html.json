{
  "hash": "bfdc15af8bff5b7797b64e74b2f111e6",
  "result": {
    "engine": "knitr",
    "markdown": "--- \noutput: html_document \neditor_options:  \n  chunk_output_type: console\n--- \n\n\n\n \n\n# Dealing with Messy Data I: Case Analysis\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## Anscombe's Quartet\n\n\n\n-----\n\n## Case Analysis\n\n- Goal is to identify any unusual or excessively influential data. These data points may either bias results and/or reduce power to detect effects (inflate standard errors and/or decrease $R^2$).   \n\n- Three aspects of individual observations we attend to:\n  1. Leverage\n  2. Regression Outlier\n  3. Influence\n\n- Case Analysis also provides an important first step as you get to *know* your data.  \n\n-----\n\n## Case Analysis: Unusual and Influential Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ndata <- read_csv(here::here(\"data_lecture/6_two_predictors_fps.csv\"), \n                 show_col_types = FALSE) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 96\nColumns: 4\n$ subid <chr> \"0125\", \"0013\", \"0113\", \"0116\", \"0111\", \"0014\", \"0124\", \"0022\", …\n$ bac   <dbl> 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, …\n$ ta    <dbl> 110, 120, 35, 119, 26, 103, 52, 34, 208, 34, 254, 84, 249, 163, …\n$ fps   <dbl> -98.0977778, -22.5285000, 0.4632944, 1.1943667, 2.7280444, 6.723…\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_1 <- lm(fps ~ bac + ta, data = data)\n\nbroom::tidy(m_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic    p.value\n  <chr>          <dbl>     <dbl>     <dbl>      <dbl>\n1 (Intercept)   19.4      7.66        2.54 0.0128    \n2 bac         -177.      86.6        -2.04 0.0437    \n3 ta             0.153    0.0324      4.73 0.00000807\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n## Univariate Statistics and Graphs\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  select(-subid) |> \n  pivot_longer(everything(), names_to = \"var\") |>\n  group_by(var) |> \n  summarize( n = n(),\n             mean = mean(value), \n             sd = sd(value), \n             min = min(value), \n             max = max(value)) |> \n  mutate(across(mean:max, ~round(.x, 2)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 6\n  var       n   mean     sd   min    max\n  <chr> <int>  <dbl>  <dbl> <dbl>  <dbl>\n1 bac      96   0.06   0.04   0     0.14\n2 fps      96  32.2   37.5  -98.1 163.  \n3 ta       96 148.   106.    10   445   \n```\n\n\n:::\n:::\n\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# univariate plots\n```\n:::\n\n\n\n\n-----\n\n## Bivariate Correlations\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  select(-subid) |> \n  cor() |> \n  round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      bac    ta   fps\nbac  1.00 -0.02 -0.19\nta  -0.02  1.00  0.44\nfps -0.19  0.44  1.00\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n## Bivariate Plots\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# bivariate plots\n```\n:::\n\n\n\n\n-----\n\n## Leverage (Cartoon Data)\n\n**Check for high Leverage points**   \n\nLeverage is a property of the predictors (DV is not considered for leverage analysis). An observation will have increased *leverage* on the results as its distance from the mean of all predictors increases. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cartoon leverage plot\n```\n:::\n\n\n\n\n<span style=\"color: red;\">Question: Which colored points have the most leverage in the 1 predictor example above?</span> \n\n-----\n\n## Leverage\n\nHat values ($h_i$) provide an index of leverage.   \n\nIn the one predictor case:  \n$h_i = \\frac{1}{N} + \\frac{(X_i- \\overline X)^2}{\\sum(X_j- \\overline X)^2}$ (for $j=1$ to $N$ in summation)  \n\nWith multiple predictors, $h_i$ measures the distance from the centroid (point of means) of the $X$s. Hat values are bounded between $\\frac{1}{N}$ and 1. \n\n**Mean Hat value = $\\frac{P}{N}$.**  \n\nRules of thumb:  \n- $h_i > 3* \\overline h$ for small samples ($N < 100$)\n- $h_i > 2* \\overline h$ for large samples   \n\n\n**Do not blindly apply rules of thumb. Hat values should be separated from distribution of $h_i$. View a histogram of $h_i$.**\n\nNote: Mahalanobis (Maha) distance = $(N - 1)(h_i - \\frac{1}{N})$.   \nSPSS reports centered leverage ($h - \\frac{1}{N}$).\n\n-----\n\n## Leverage (Cartoon Data; Continued)\n\n\nHigh leverage values are not always bad. In fact, in some cases they are good. Must also consider if they are regression outliers.  \n\n<span style=\"color: red;\">Question: Why?</span> \n\n-----\n\n$R^2 = \\frac{\\text{SSE}_{\\text{mean-only}}- \\text{SSE}_a}{\\text{SSE}_{\\text{mean-only}}}$  \n\n$\\text{SE}_{bi} = \\frac{s_y}{s_i} = \\frac{\\sqrt{(1-R^2_y)}}{\\sqrt{(N - k - 1)}}*\\frac{1}{\\sqrt{(1-R^2_i)}}$\n\n\n<span style=\"color: blue;\">- High leverage points that are fit well by the model increase the difference between $\\text{SSE}_{\\text{mean-only}}$ and $\\text{SSE}_a$, which increases $R^2$.</span>\n\n<span style=\"color: blue;\">- High leverage points that are fit well also increase variance for predictor. This reduces the SE for predictors and yields more power.</span>\n\n<span style=\"color: blue;\">- Well fit, high leverage points do **not** alter $b$s.</span>\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cartoon leverage plot\n```\n:::\n\n\n\n\n-----\n\n## Leverage (Real Data)\n\n\n\n\n\n\n\n## Enter the Real World\n\n<span style=\"color: red;\">Question: So what do you do?</span> \n\n\n-----\n\n## Overall Impact of Problem Scores: Real Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code example\n```\n:::\n\n\n\n\n\n-----\n\n## What to Do\n\n<span style=\"color: blue;\">- Don’t worry about leverage alone.</span>\n\n<span style=\"color: blue;\">- Worry about model outliers always.</span>\n\n<span style=\"color: blue;\">- Worry about influence (overall model or predictors by field).</span>\n\n<span style=\"color: blue;\">- Drop, retain, or bring model outliers to the fence.</span>\n\n<span style=\"color: blue;\">- Drop or retain influential participants.</span>\n\n<span style=\"color: blue;\">- Report both ways (in olden day…).</span>\n\n<span style=\"color: blue;\">- Get with the program and pre-register instead (what you worry about, how you define it, and what you do)!</span>\n\n\n",
    "supporting": [
      "07_case_analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}