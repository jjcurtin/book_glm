{
  "hash": "91e1c9c2fc1206aad53e2ce2d26a9aa9",
  "result": {
    "engine": "knitr",
    "markdown": "---\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n# Simulate SEs for Logistic Regression {.unnumbered}\n\n\n## Setup \n\n\n\n::: {.cell messages='false' warnings='false'}\n\n```{.r .cell-code}\n# packages\noptions(conflicts.policy = \"depends.ok\")\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(furrr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: future\n```\n\n\n:::\n\n```{.r .cell-code}\n# source  \ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\", \n                     sha1 = \"a58e57da996d1b70bb9a5b58241325d6fd78890f\")\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/my_skim.R?raw=true\",\n                     sha1 = \"839a13530805f9d28f407483a18b7e3368389fe7\")\n\n\n# options\ntheme_set(theme_classic()) \n```\n:::\n\n\n\n\n## Functions \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmake_data <- function(n, b0, b1){\n  x <- runif(n, -10, 10) \n  z <- b0 + b1 * x\n  p <- 1 / (1 + exp(-z))\n  y <- rbinom(n, 1, p)\n  tibble(y = y, x = x)  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nget_preds <- function(sim, n, b0, b1){\n  d <- make_data(n, b0, b1)\n  m <- glm(y ~ x, data = d, family = binomial) \n  preds <- tibble(x = c(-8, -3, 0, 3, 8))\n  preds <- preds |> \n    bind_cols(predict(m, newdata = preds,\n                      type = \"link\",\n                      se.fit = TRUE)) |> \n    select(x, se_lo = se.fit, fit_lo = fit)\n  preds |> \n    bind_cols(predict(m, newdata = preds, \n                      type = \"response\",\n                      se.fit = TRUE),\n           sim = sim) |>\n    select(sim, x, fit_lo, fit_pr = fit, se_lo, se_pr = se.fit)\n}\n```\n:::\n\n\n\n\n## Simulate sampling distribution\n\nSettings\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set n high to have robust models (and to handle uncertainty about z vs. t)\nn <- 1000 \nb0 <- 0\nb1 <- 0.5 \nn_sims <- 50000\n```\n:::\n\n\n\n\nsimulate predictions to create sampling distribution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE))\ndoParallel::registerDoParallel(cl)\nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n\npreds <- 1:n_sims |> \n  future_map(\\(sim) get_preds(sim, n, b0, b1),\n             .options = furrr_options(seed = 2468)) |>\n  list_rbind()\n\nplan(sequential)\n```\n:::\n\n\n\n\n## Add post simulation calcs to preds\n\nTransform log-odds to pr and get CIs for log-odds, pr from log-odds, and native pr\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- preds |> \n  mutate(upr_lo = fit_lo + 1.96 * se_lo,\n         lwr_lo = fit_lo - 1.96 * se_lo,\n         fit_lo_pr = plogis(fit_lo),\n         upr_lo_pr = plogis(upr_lo),\n         lwr_lo_pr = plogis(lwr_lo),\n         upr_pr = fit_pr + 1.96 * se_pr,\n         lwr_pr = fit_pr - 1.96 * se_pr) \n```\n:::\n\n\n\n\nCalc true values and join with preds \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrue_values <- tibble(x = c(-8, -3, 0, 3, 8)) |> \n  mutate(true_lo = b0 + b1 * x,\n         true_pr = plogis(true_lo))\n\npreds <- preds |> \n  left_join(true_values, by = \"x\") |> \n  relocate(sim, x, true_lo, true_pr, \n           fit_lo, lwr_lo, upr_lo, \n           fit_lo_pr, lwr_lo_pr, upr_lo_pr,\n           fit_pr, lwr_pr, upr_pr)\n```\n:::\n\n\n\n\nCalculate true SE (sd of sampling distribution for fits across simulations)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nse_true <- preds |> \n  group_by(x) |>\n  summarise(se_lo_true = sd(fit_lo), \n            se_pr_true = sd(fit_pr),\n            .groups = \"drop\")\n```\n:::\n\n\n\n\nReview preds\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 15\n     sim     x true_lo true_pr  fit_lo lwr_lo  upr_lo fit_lo_pr lwr_lo_pr\n   <int> <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>     <dbl>     <dbl>\n 1     1    -8    -4    0.0180 -3.82   -4.30  -3.34      0.0215   0.0133 \n 2     1    -3    -1.5  0.182  -1.51   -1.76  -1.25      0.181    0.147  \n 3     1     0     0    0.5    -0.118  -0.304  0.0674    0.470    0.425  \n 4     1     3     1.5  0.818   1.27    1.03   1.51      0.781    0.737  \n 5     1     8     4    0.982   3.58    3.12   4.04      0.973    0.958  \n 6     2    -8    -4    0.0180 -4.35   -4.91  -3.79      0.0128   0.00732\n 7     2    -3    -1.5  0.182  -1.62   -1.91  -1.33      0.165    0.129  \n 8     2     0     0    0.5     0.0119 -0.200  0.224     0.503    0.450  \n 9     2     3     1.5  0.818   1.65    1.36   1.93      0.838    0.796  \n10     2     8     4    0.982   4.37    3.81   4.93      0.988    0.978  \n# ℹ 6 more variables: upr_lo_pr <dbl>, fit_pr <dbl>, lwr_pr <dbl>,\n#   upr_pr <dbl>, se_lo <dbl>, se_pr <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n## Visual sampling distributions for predictions\n\nFor log-odds\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> \n  ggplot(aes(x = fit_lo, fill = fct(as.character(x)))) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Sampling Distribution of Log-Odds\",\n       x = \"Log-Odds\",\n       y = \"Density\") + \n  scale_fill_discrete(name = \"X\")\n```\n\n::: {.cell-output-display}\n![](app4_logistic_se_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\nFor pr from log-odds\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> \n  ggplot(aes(x = fit_lo_pr, fill = fct(as.character(x)))) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Sampling Distribution of Pr from Log-Odds\",\n       x = \"Pr\",\n       y = \"Density\") + \n  scale_fill_discrete(name = \"X\")\n```\n\n::: {.cell-output-display}\n![](app4_logistic_se_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\nFor pr\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> \n  ggplot(aes(x = fit_pr, fill = fct(as.character(x)))) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Sampling Distribution of Pr\",\n       x = \"Pr\",\n       y = \"Density\") + \n  scale_fill_discrete(name = \"X\")\n```\n\n::: {.cell-output-display}\n![](app4_logistic_se_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\nLook more closely at edge of X.  Its mostly but not completely symetric.   This is why a symetric confidence interval will NOT work optimally for pr. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> \n  filter(x == -8) |> \n  ggplot(aes(x = fit_pr)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Sampling Distribution of Pr for X = -8\",\n       x = \"Pr\",\n       y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](app4_logistic_se_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Review min and max values for probability based CIs\n\nCIs for probability are NOT equivalent when formed from log-odds vs. pr.  This is because the transformation from log-odds to pr is non-linear (after adding/subtracting SE).\n\nIn this example, the CI boundaries for probability are never < 0 or greater than 1 even when calculated directly as probability + 1.96 SE.  But that may  not be always true.  Also clear that +- 1.96 SE is not appropriate for a probability CI given its not symetric and therefore clearly not always normal.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> \n  group_by(x) |> \n  summarise(min_lwr_lo_pr = min(lwr_lo_pr),\n            min_lwr_pr = min(lwr_pr),\n            max_upr_lo_pr = max(upr_lo_pr),\n            max_upr_pr = max(upr_pr),\n            .groups = \"drop\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 5\n      x min_lwr_lo_pr min_lwr_pr max_upr_lo_pr max_upr_pr\n  <dbl>         <dbl>      <dbl>         <dbl>      <dbl>\n1    -8       0.00234    0.00134        0.0657     0.0623\n2    -3       0.0746     0.0705         0.343      0.341 \n3     0       0.338      0.336          0.656      0.657 \n4     3       0.686      0.688          0.925      0.929 \n5     8       0.936      0.939          0.998      0.999 \n```\n\n\n:::\n:::\n\n\n\n\n## Check model SEs (from predict) for lo and pr\n\nNow fit a single model and use `predict()` to se.fit for lo and pr \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- make_data(n, b0, b1)\nm <- glm(y ~ x, data = d, family = binomial) \nsample_preds <- tibble(x = c(-8, -3, 0, 3, 8))\nsample_preds <- sample_preds |> \n  bind_cols(predict(m, newdata = sample_preds, \n                        type = \"link\",\n                        se.fit = TRUE)) |> \n  select(x, se_lo_mod = se.fit)\nsample_preds <- sample_preds |> \n  bind_cols(predict(m, newdata = sample_preds, \n                        type = \"response\",\n                        se.fit = TRUE)) |> \n  select(x, se_lo_mod, se_pr_mod = se.fit)\n```\n:::\n\n\n\n\nNow compare model SEs to true SEs\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nse <- se_true |> \n  full_join(sample_preds, by = \"x\") |> \n  mutate(diff_lo = se_lo_true - se_lo_mod,\n         diff_pr = se_pr_true - se_pr_mod) |> \n  relocate(x, \n           se_lo_true, se_lo_mod, diff_lo, \n           se_pr_true, se_pr_mod, diff_pr)\nse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 7\n      x se_lo_true se_lo_mod  diff_lo se_pr_true se_pr_mod   diff_pr\n  <dbl>      <dbl>     <dbl>    <dbl>      <dbl>     <dbl>     <dbl>\n1    -8      0.266     0.281 -0.0152     0.00463   0.00382  0.000815\n2    -3      0.137     0.141 -0.00407    0.0202    0.0204  -0.000183\n3     0      0.102     0.104 -0.00270    0.0254    0.0261  -0.000699\n4     3      0.137     0.147 -0.00983    0.0202    0.0190   0.00119 \n5     8      0.265     0.288 -0.0230     0.00462   0.00334  0.00129 \n```\n\n\n:::\n:::\n\n\n\n\n## Check CIs\n\nFor LO\nGOOD!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> \n  mutate(value_in_ci = if_else(lwr_lo <= true_lo & \n                               upr_lo >= true_lo, \n                               1, 0)) |> \n pull(value_in_ci) |> \n mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.949692\n```\n\n\n:::\n:::\n\n\n\n\n\nFor PR from LO \nGOOD!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> \n  mutate(value_in_ci = if_else(lwr_lo_pr <= true_pr & \n                               upr_lo_pr >= true_pr, \n                               1, 0)) |> \n pull(value_in_ci) |> \n mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.949692\n```\n\n\n:::\n:::\n\n\n\n\nFor PR from LO \nNot perfect.  This is why we should use CIs for probability formed from log odds predictions!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> \n  mutate(value_in_ci = if_else(lwr_pr <= true_pr & \n                               upr_pr >= true_pr, \n                               1, 0)) |> \n pull(value_in_ci) |> \n mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.941612\n```\n\n\n:::\n:::\n\n\n\n\n\nAs expected the CI coverage is worse for the edge of the X range\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> \n  filter(x == -8) |>\n  mutate(value_in_ci = if_else(lwr_pr <= true_pr & \n                               upr_pr >= true_pr, \n                               1, 0)) |> \n pull(value_in_ci) |> \n mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.93338\n```\n\n\n:::\n:::",
    "supporting": [
      "app4_logistic_se_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}