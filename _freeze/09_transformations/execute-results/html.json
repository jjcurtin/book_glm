{
  "hash": "0442f4fafd8573d81792baf5fce3a511",
  "result": {
    "engine": "knitr",
    "markdown": "--- \noutput: html_document \neditor_options:  \n  chunk_output_type: console\n--- \n\n\n\n \n\n# Dealing with Messy Data III: Transformations\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Transformations: The Family of Power and Roots\n\n- The GLM makes **strong assumptions** about the structure of data, assumptions which often fail to hold in practice.\n\n- One solution is to abandon the GLM for more complicated models (generalized linear models; weighted least squares; robust regression).\n\n- Another solution is to transform the data (either the $X$s or $Y$) so that they conform more closely to the assumptions.  \n\n- A particularly useful group of transformations is the *family* of powers and roots: \n\n    **$X$ → $X^p$**\n\n    - If p is negative, then the transformation is an inverse power: $X^{-1} = \\frac{1}{X}$, and $X^{−2} = \\frac{1}{X^2}$\n    - If p is a fraction, then the transformation represents a root: $X^{\\frac{1}{2}} = \\sqrt{X}$, and $X^{-\\frac{1}{2}} = \\frac{1}{\\sqrt{X}}$\n    \n    \n-----\n\n- The Box-Cox family of transformations provides a comparable but more convenient form (in some cases*).\n\n    **$X$ → $X^{(p)} \\equiv \\frac{X^p- 1}{p}$**  \n    \n- Since $X^{(p)}$ is a linear function of $X^p$, the 2 transformations have the same essential effect on the data.\n\n    - Dividing by p preserves the direction of $X$, which otherwise would be reversed when p is negative.  \n    - This function also matches level and slope of curve at $X=1$.\n    \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# box cox transformation figure\n```\n:::\n\n\n\n\n-----\n\n- The power transformation $X^{(0)}$ is useless, but the very useful log transformation is a kind of *zeroth* power:\n                   \n    lim\n    $p$ → $0$   $\\frac{X^p - 1}{p} = \\text{log}_eX$\n                   \n    where $e \\approx 2.718$ is the base of the natural logarithms. Thus, we will take $X^{(0)} \\equiv log(X)$.\n\n- It is generally more convenient to use logs to the base 10 or base 2, which are more easily interpreted than logs to the base e.\n\n- Changing bases is equivalent to multiplying your variable by a constant. No effect on significance tests.\n\n\n-----\n\n- Descending the *ladder* of powers and roots from $p = 1$ (i.e., no transformation) towards $p = -2$ **compresses the large values of X and spreads out the small ones**.\n\n- Ascending the ladder of powers from $p = 1$ towards $p = 3$ has the **opposite effect**.\n\n-----\n\n- Power transformations are sensible only when all of the values of $X$ are positive:\n\n    - Some of the transformations, such as log ($p= 0$) and square root ($p= .5$), are undefined for negative or zero values of $X$.\n\n    - Power transformations are not monotone (i.e., they change to order of scores) when there are both positive and negative values among the data.\n\n    - We can add a positive constant (called a *start*) to each data value to make all of the values positive: \n\n      $X$ → $(X + s)^{(p)}$\n    \n-----\n\n- Power transformations are effective only when the ratio of the biggest data values to the smallest ones is sufficiently large; if this ratio is close to 1, then power transformations are nearly linear.  For example:  \n\n    - Power transformations will work well if range of $X = 1 – 100$.\n  \n    - Power transformations will have little effect if range of $X = 1000 – 1100$\n    \n- Using a negative start can often increase the ratio of highest/lowest score.\n\n- Using reasonable starts, if necessary, an adequate power transformation can usually be found in the range $−2 \\le p \\le 3$.\n\n-----\n\n- Power transformations of $Y$ (or sometimes $X$) can correct problems with normality of errors.\n\n- Power transformations of $Y$ (or sometimes $X$) can stabilize the variance of the errors.\n\n- Power transformations of $X$ (or sometimes $Y$) can make many nonlinear relationships more nearly linear.\n\n- You can experiment with Box-Cox transformations of $X$ or $Y$ in R using `bcPower()` in the `car` package.\n\n- In many fields, $X^p$ rather than $X^{(p)}$ may be preferred. Particularly, if $p \\ge 0$. This is simply done algebraically.\n\n-----\n\n## Transformations: Dealing with Skew\n\n- Transforming $Y$ *down the ladder* can correct positive skew in the errors (most common problem).  \n\n- Transforming $Y$ *up the ladder* corrects negative skew in the errors.\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# skew transformation plots\n```\n:::\n\n\n\n\n-----\n\n## Transformations: Dealing with Heteroscedasticity\n\n- Transforming $Y$ *down the ladder* can correct problems with increasing spread of errors as $Y$ increases (most common problem).  \n\n- Transforming $Y$ *up the ladder* corrects decreasing spread. \n\n- The problems of unequal spread and skewness commonly occur together and can be corrected together. Therefore, transforming $Y$ down the ladder can correct both issues simultaneously.\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# hetero plots\n```\n:::\n\n\n\n\n-----\n\n\n\n\n\n\n\n",
    "supporting": [
      "09_transformations_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}