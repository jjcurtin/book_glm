{
  "hash": "939a0ddd8aa7985eb7ffe8ac1e22aa49",
  "result": {
    "engine": "knitr",
    "markdown": "--- \noutput: html_document \neditor_options:  \n  chunk_output_type: console\n--- \n\n\n\n \n\n# Dealing with Messy Data III: Transformations\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Transformations: The Family of Power and Roots\n\n- The GLM makes **strong assumptions** about the structure of data, assumptions which often fail to hold in practice.\n\n- One solution is to abandon the GLM for more complicated models (generalized linear models; weighted least squares; robust regression).\n\n- Another solution is to transform the data (either the $X$s or $Y$) so that they conform more closely to the assumptions.  \n\n- A particularly useful group of transformations is the *family* of powers and roots: \n\n    **$X$ → $X^p$**\n\n    - If p is negative, then the transformation is an inverse power: $X^{-1} = \\frac{1}{X}$, and $X^{−2} = \\frac{1}{X^2}$\n    - If p is a fraction, then the transformation represents a root: $X^{\\frac{1}{2}} = \\sqrt{X}$, and $X^{-\\frac{1}{2}} = \\frac{1}{\\sqrt{X}}$\n    \n    \n-----\n\n- The Box-Cox family of transformations provides a comparable but more convenient form (in some cases*).\n\n    **$X$ → $X^{(p)} \\equiv \\frac{X^p- 1}{p}$**  \n    \n- Since $X^{(p)}$ is a linear function of $X^p$, the 2 transformations have the same essential effect on the data.\n\n    - Dividing by p preserves the direction of $X$, which otherwise would be reversed when p is negative.  \n    - This function also matches level and slope of curve at $X=1$.\n    \n-----\n    \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![The Box-Cox family of modified power transformations, $X^{(p)}= (X^p - 1)/p$, for values of $p = -1, 0, 1, 2, 3$. When $p = 0, X^{(p)} = log_e X$.](09_transformations_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n- The power transformation $X^{(0)}$ is useless, but the very useful log transformation is a kind of *zeroth* power:\n                   \n    lim\n    $p$ → $0$   $\\frac{X^p - 1}{p} = \\text{log}_eX$\n                   \n    where $e \\approx 2.718$ is the base of the natural logarithms. Thus, we will take $X^{(0)} \\equiv log(X)$.\n\n- It is generally more convenient to use logs to the base 10 or base 2, which are more easily interpreted than logs to the base e.\n\n- Changing bases is equivalent to multiplying your variable by a constant. No effect on significance tests.\n\n\n-----\n\n- Descending the *ladder* of powers and roots from $p = 1$ (i.e., no transformation) towards $p = -2$ **compresses the large values of X and spreads out the small ones**.\n\n- Ascending the ladder of powers from $p = 1$ towards $p = 3$ has the **opposite effect**.\n\n-----\n\n- Power transformations are sensible only when all of the values of $X$ are positive:\n\n    - Some of the transformations, such as log ($p= 0$) and square root ($p= .5$), are undefined for negative or zero values of $X$.\n\n    - Power transformations are not monotone (i.e., they change to order of scores) when there are both positive and negative values among the data.\n\n    - We can add a positive constant (called a *start*) to each data value to make all of the values positive: \n\n      $X$ → $(X + s)^{(p)}$\n    \n-----\n\n- Power transformations are effective only when the ratio of the biggest data values to the smallest ones is sufficiently large; if this ratio is close to 1, then power transformations are nearly linear.  For example:  \n\n    - Power transformations will work well if range of $X = 1 – 100$.\n  \n    - Power transformations will have little effect if range of $X = 1000 – 1100$\n    \n- Using a negative start can often increase the ratio of highest/lowest score.\n\n- Using reasonable starts, if necessary, an adequate power transformation can usually be found in the range $−2 \\le p \\le 3$.\n\n-----\n\n- Power transformations of $Y$ (or sometimes $X$) can correct problems with normality of errors.\n\n- Power transformations of $Y$ (or sometimes $X$) can stabilize the variance of the errors.\n\n- Power transformations of $X$ (or sometimes $Y$) can make many nonlinear relationships more nearly linear.\n\n- You can experiment with Box-Cox transformations of $X$ or $Y$ in R using `bcPower()` in the `car` package.\n\n- In many fields, $X^p$ rather than $X^{(p)}$ may be preferred. Particularly, if $p \\ge 0$. This is simply done algebraically.\n\n-----\n\n## Transformations: Dealing with Skew\n\n- Transforming $Y$ *down the ladder* can correct positive skew in the errors (most common problem).  \n\n- Transforming $Y$ *up the ladder* corrects negative skew in the errors.\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nset.seed(102030)\ny <- tibble(y_raw = rchisq(n=500, df=1),\n            y_.5 = car::bcPower(y_raw, .5),\n            y_.25 = car::bcPower(y_raw, .25),\n            y_0 = car::bcPower(y_raw, 0))    \n\nplot_raw <- y |> \n  ggplot(aes(x = y_raw)) +\n  geom_density() + \n  scale_x_continuous(limits = c(-.5, 12), breaks = c(0, 2, 4, 6, 8, 10)) +\n  labs(title = \"Raw Y\",\n       x = NULL,\n       caption = str_c(\"N = 500; bandwidth = \", round(density(y$y_raw)$bw, 4)))\n\nplot_.5 <- y |> \n  ggplot(aes(x = y_.5)) +\n  geom_density() + \n  scale_x_continuous(limits = c(-3, 5), breaks = c(-2, 0, 2, 4)) +\n  labs(title = \"p = .5; sqrt(Y)\",\n       x = NULL,\n       caption = str_c(\"N = 500; bandwidth = \", round(density(y$y_.5)$bw, 4)))\n\nplot_.25 <- y |> \n  ggplot(aes(x = y_.25)) +\n  geom_density() + \n  scale_x_continuous(limits = c(-4.5, 4), breaks = c(-4, -2, 0, 2, 4)) +\n  labs(title = \"p = .25\",\n       x = NULL,\n       caption = str_c(\"N = 500; bandwidth = \", round(density(y$y_.25)$bw, 4)))\n\nplot_0 <- y |> \n  ggplot(aes(x = y_0)) +\n  geom_density() + \n  scale_x_continuous(limits = c(-15, 4), breaks = c(-15, -10. -5, 0)) +\n  labs(title = \"p = 0; log(Y)\",\n       x = NULL,\n       caption = str_c(\"N = 500; bandwidth = \", round(density(y$y_0)$bw, 4)))\n\n\n(plot_raw + plot_.5) / (plot_.25 + plot_0)\n```\n\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n## Transformations: Dealing with Heteroscedasticity\n\n- Transforming $Y$ *down the ladder* can correct problems with increasing spread of errors as $Y$ increases (most common problem).  \n\n- Transforming $Y$ *up the ladder* corrects decreasing spread. \n\n- The problems of unequal spread and skewness commonly occur together and can be corrected together. Therefore, transforming $Y$ down the ladder can correct both issues simultaneously.\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nlibrary(car) # needed for model_assumptions\nlibrary(psych) # needed for model_assumptions\nlibrary(gvlma) # needed for model_assumptions\n\npath_data <- \"data_lecture\"\ndata <- read_csv(here::here(path_data, \"9_transformations_fps.csv\"), \n                 show_col_types = FALSE) |> \n   mutate(sex_c = if_else(sex == \"female\", -.5, .5)) |> \n   # remove outliers to fit same model as last two units \n   filter(!subid %in% c(\"0125\", \"2112\"))\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/model_assumptions.R?raw=true\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- lm(fps ~ bac + ta + sex_c, data = data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_assumptions(m, Type = \"normal\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_assumptions(m, Type = \"constant\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSuggested power transformation:  0.2370356 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::ncvTest(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 13.2232, Df = 1, p = 0.00027651\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngvlma(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fps ~ bac + ta + sex_c, data = data)\n\nCoefficients:\n(Intercept)          bac           ta        sex_c  \n    28.7027    -254.5894       0.1231     -15.8550  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = m) \n\n                        Value p-value                   Decision\nGlobal Stat        9.39689053 0.05191    Assumptions acceptable.\nSkewness           3.60145982 0.05773    Assumptions acceptable.\nKurtosis           0.30834234 0.57870    Assumptions acceptable.\nLink Function      0.00002503 0.99601    Assumptions acceptable.\nHeteroscedasticity 5.48706334 0.01916 Assumptions NOT satisfied!\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n## Box Cox Transformation Function\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  select(bac, ta, sex_c, fps) |> \n  psych::describe() |> \n  select(-c(trimmed, mad, se))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      vars  n   mean     sd median    min    max  range  skew kurtosis\nbac      1 94   0.06   0.04   0.06   0.00   0.14   0.14 -0.09    -1.08\nta       2 94 145.91 104.80 119.00  10.00 445.00 435.00  0.91     0.03\nsex_c    3 94   0.01   0.50   0.50  -0.50   0.50   1.00 -0.04    -2.02\nfps      4 94  32.19  32.77  19.46 -26.07 136.82 162.89  0.95     0.33\n```\n\n\n:::\n:::\n\n\n\n\nWe are going to first add a constant so all response values are > 0\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  mutate(fps_27 = fps + 27)\n\nm_2 <- lm(fps_27 ~ bac + ta + sex_c, data = data)\n```\n:::\n\n\n\n\n-----\n\nNext we will pull the best lambda value from a plot of log-likelihood values by lambda power transformations of response variable.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::boxCox(m_2)\n\nround(car::boxCox(m_2)$x[which.max(car::boxCox(m_2)$y)],2)\n```\n\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.55\n```\n\n\n:::\n:::\n\n\n\n\n\n-----\n\nLastly, we will use the best lambda value to conduct our power transformation and re-evaluate our model assumptions. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  mutate(fps_bc = car::bcPower(fps_27, .55))\n\nm_3 <- lm(fps_bc ~ bac + ta + sex_c, data = data)\n```\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSuggested power transformation:  -0.5446104 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncar::ncvTest(m_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 6.005664, Df = 1, p = 0.01426\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ngvlma(m_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fps_bc ~ bac + ta + sex_c, data = data)\n\nCoefficients:\n(Intercept)          bac           ta        sex_c  \n   14.21548    -37.52098      0.01793     -2.70290  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = m_3) \n\n                       Value p-value                   Decision\nGlobal Stat        12.759981 0.01251 Assumptions NOT satisfied!\nSkewness            1.588199 0.20758    Assumptions acceptable.\nKurtosis            5.520612 0.01879 Assumptions NOT satisfied!\nLink Function       0.004907 0.94416    Assumptions acceptable.\nHeteroscedasticity  5.646263 0.01749 Assumptions NOT satisfied!\n```\n\n\n:::\n:::\n\n\n\n\n**Transformations often don't help!**\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_3 |> \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  14.2      1.03        13.8  6.26e-24\n2 bac         -37.5     11.5         -3.25 1.62e- 3\n3 ta            0.0179   0.00436      4.11 8.62e- 5\n4 sex_c        -2.70     0.910       -2.97 3.82e- 3\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\nWhite (1980) Heteroscedasticity-corrected SEs and Tests\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrected_ses <- sqrt(diag(hccm(m)))\n\nbroom::tidy(m) |> \n  select(term, estimate) |> \n  add_column(std.error = corrected_ses) |> \n  mutate(statistic = estimate/std.error,\n         p.value = 2*(pt(abs(statistic), df=m_2$df.residual, lower.tail=FALSE)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)   28.7      6.91        4.15 0.0000744\n2 bac         -255.      71.3        -3.57 0.000575 \n3 ta             0.123    0.0320      3.85 0.000224 \n4 sex_c        -15.9      5.87       -2.70 0.00826  \n```\n\n\n:::\n:::\n\n\n\n\n*Maybe* better choicer was untransformed Y (original model) with corrected SEs?    \n \n*Maybe* the problem wasn’t bad enough to do anything?\n\n-----\n\n## Transformations: Dealing with Non-linearity\n\nPower transformations can make simple monotone relationships more linear (Fig A).  Polynomial regression (or other transformations, e.g. logit) is often needed for more complex relationships (Figs, B & C).\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](figures/monotone_relationship.png)\n:::\n:::\n\n\n\n\n\n## Transformations: Mosteller and Tukey’s bulging rule\n\nSimple monotone relationships can be corrected by transforming $X$ or $Y$.     \n\n- $X$ is typical if only one $XY$ relationship is problematic.    \n\n- If all $X$s have similar non-linear relationship, transform $Y$.    \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](figures/mosteller_tukey.png)\n:::\n:::\n\n\n\n\n-----\n\n<span style=\"color: red;\">Question: What 2 transformations would make this relationship linear?</span> \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n<span style=\"color: blue;\">Move $X$ down the ladder (e.g., $X^.5$)</span>  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_nonlinear  |> \n  ggplot(aes(x = sqrt(X), y = Y)) +\n  geom_point(alpha = .4)\n```\n\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n\n\n\n<span style=\"color: blue;\">Move $Y$ up the ladder (e.g., $Y^2$)</span>  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_nonlinear  |> \n  ggplot(aes(x = X, y = Y^2)) +\n  geom_point(alpha = .4)\n```\n\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n## General Transformations\n\n- In some fields, certain power transformations (sqrt, log, inverse) are common.\n\n- If we have a choice between transformations that perform roughly equally well, we may prefer one transformation to another because of interpretability:\n\n    - The log transformation has a convenient multiplicative interpretation (e.g., increasing  log2 (X) by 1 doubles X; increasing log10 (X) by 1 multiples X by 10).\n\n- Transformations are a big source of research dfs. Should be pre-registered.  You may know what your DV typically *needs* from prior data. Worst case, report with and without transformations and justify.\n\n-----\n\n## 5K Race Times\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_5k <- read_csv(here::here(path_data, \"9_transformations_5k.csv\"),\n                    show_col_types = FALSE) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 80\nColumns: 4\n$ subid <chr> \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\"…\n$ time  <dbl> 24.91, 21.82, 21.54, 23.03, 25.35, 22.84, 30.16, 27.00, 16.42, 2…\n$ age   <dbl> 29, 25, 27, 25, 37, 31, 43, 44, 46, 53, 58, 30, 27, 36, 32, 45, …\n$ miles <dbl> 24.99984, 30.80905, 52.04042, 66.20958, 26.60005, 48.21255, 12.3…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm_5k <- lm(time ~ age + miles, data = data_5k)\n\nbroom::tidy(m_5k)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   25.0      1.80       13.9  1.07e-22\n2 age            0.172    0.0333      5.17 1.77e- 6\n3 miles         -0.210    0.0246     -8.53 9.54e-13\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_assumptions(m_5k, Type = \"normal\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_assumptions(m_5k, Type = \"constant\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSuggested power transformation:  0.4894249 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::ncvTest(m_5k)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 0.8077899, Df = 1, p = 0.36877\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_assumptions(m_5k, Type='linear')\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n\n\n\n\n-----\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngvlma(m_5k)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = time ~ age + miles, data = data_5k)\n\nCoefficients:\n(Intercept)          age        miles  \n    24.9804       0.1724      -0.2097  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = m_5k) \n\n                      Value   p-value                   Decision\nGlobal Stat        13.01039 0.0112252 Assumptions NOT satisfied!\nSkewness            0.01435 0.9046389    Assumptions acceptable.\nKurtosis            0.07603 0.7827462    Assumptions acceptable.\nLink Function      12.82570 0.0003419 Assumptions NOT satisfied!\nHeteroscedasticity  0.09430 0.7587759    Assumptions acceptable.\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\nLet's try transforming miles using `log2()`, a binary logarithm (base 2).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_5k <- data_5k |> \n  mutate(log_miles = log2(miles))\n\nm_5k_tran <- lm(time ~ age + log_miles, data = data_5k)\n\nbroom::tidy(m_5k_tran)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   42.5      3.25       13.1  2.88e-21\n2 age            0.170    0.0320      5.32 9.97e- 7\n3 log_miles     -4.98     0.538      -9.26 3.73e-14\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_assumptions(m_5k_tran, Type='linear')\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngvlma(m_5k_tran)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = time ~ age + log_miles, data = data_5k)\n\nCoefficients:\n(Intercept)          age    log_miles  \n     42.519        0.170       -4.983  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = m_5k_tran) \n\n                     Value p-value                Decision\nGlobal Stat        1.83180  0.7667 Assumptions acceptable.\nSkewness           0.15584  0.6930 Assumptions acceptable.\nKurtosis           0.06402  0.8003 Assumptions acceptable.\nLink Function      1.58986  0.2073 Assumptions acceptable.\nHeteroscedasticity 0.02209  0.8819 Assumptions acceptable.\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n## Displaying Transformed Results With Fake Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_fake <- tibble(x = 3 * rchisq(200, df=3),\n                    x_sr = sqrt(x),\n                    y = 3 * x_sr + rnorm(200,mean=0,sd = 1))\n\nm_raw = lm(y ~ x, data = data_fake)\nbroom::tidy(m_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    3.67     0.148       24.9 7.86e-63\n2 x              0.519    0.0147      35.3 2.66e-87\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_fake |> \n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = .4) +\n  geom_abline(intercept = coef(m_raw)[1], slope = coef(m_raw)[2], color = \"red\")\n```\n\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-48-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_sr = lm(y ~ x_sr, data = data_fake)\nbroom::tidy(m_sr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)   -0.151    0.175     -0.863 3.89e-  1\n2 x_sr           3.06     0.0624    49.1   9.18e-113\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_fake |> \n  ggplot(aes(x = x_sr, y = y)) +\n  geom_point(alpha = .4) +\n  geom_abline(intercept = coef(m_sr)[1], slope = coef(m_sr)[2], color = \"red\")\n```\n\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-50-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\nYou can display results from linear model but provide scale for raw $X$ instead of Sqrt($X$) or in addition to Sqrt($X$) on another axis.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- tibble(x_sr = seq(min(data_fake$x_sr),max(data_fake$x_sr), by=.01))\ny_pred = predict(m_sr, newdata = preds)\n\nggplot() +\n  geom_point(aes(x = data_fake$x_sr, y = data_fake$y), alpha = .4) +\n  geom_line(aes(x = preds$x_sr, y = y_pred)) +\n  ylab(\"Y\") +\n  scale_x_continuous(name = \"SQRT(X)\", sec.axis = sec_axis(~.^2, name = \"Raw X\"))\n```\n\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-51-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n-----\n\nYou can display results from linear model in Raw $X$ Units and use `predict()` to get the $Y$s based on transformed $X$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- tibble(x_sr = sqrt(seq(min(data_fake$x),max(data_fake$x), by=.1)))\ny_pred = predict(m_sr, newdata = preds)\n\nggplot() +\n  geom_point(aes(x = data_fake$x, y = data_fake$y), alpha = .4) +\n  geom_line(aes(x = seq(min(data_fake$x),max(data_fake$x), by=.1), y = y_pred)) +\n  ylab(\"Y\") +\n  xlab(\"X\")\n```\n\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-52-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "09_transformations_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}