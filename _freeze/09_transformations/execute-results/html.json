{
  "hash": "9b295883e4ed494dd0a113dba90b57ae",
  "result": {
    "engine": "knitr",
    "markdown": "--- \noutput: html_document \neditor_options:  \n  chunk_output_type: console\n--- \n\n\n\n \n\n# Dealing with Messy Data III: Transformations\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Transformations: The Family of Power and Roots\n\n- The GLM makes **strong assumptions** about the structure of data, assumptions which often fail to hold in practice.\n\n- One solution is to abandon the GLM for more complicated models (generalized linear models; weighted least squares; robust regression).\n\n- Another solution is to transform the data (either the $X$s or $Y$) so that they conform more closely to the assumptions.  \n\n- A particularly useful group of transformations is the *family* of powers and roots: \n\n    **$X$ → $X^p$**\n\n    - If p is negative, then the transformation is an inverse power: $X^{-1} = \\frac{1}{X}$, and $X^{−2} = \\frac{1}{X^2}$\n    - If p is a fraction, then the transformation represents a root: $X^{\\frac{1}{2}} = \\sqrt{X}$, and $X^{-\\frac{1}{2}} = \\frac{1}{\\sqrt{X}}$\n    \n    \n-----\n\n- The Box-Cox family of transformations provides a comparable but more convenient form (in some cases*).\n\n    **$X$ → $X^{(p)} \\equiv \\frac{X^p- 1}{p}$**  \n    \n- Since $X^{(p)}$ is a linear function of $X^p$, the 2 transformations have the same essential effect on the data.\n\n    - Dividing by p preserves the direction of $X$, which otherwise would be reversed when p is negative.  \n    - This function also matches level and slope of curve at $X=1$.\n    \n-----\n    \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![The Box-Cox family of modified power transformations, $X^{(p)}= (X^p - 1)/p$, for values of $p = -1, 0, 1, 2, 3$. When $p = 0, X^{(p)} = log_e X$.](09_transformations_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n- The power transformation $X^{(0)}$ is useless, but the very useful log transformation is a kind of *zeroth* power:\n                   \n    lim\n    $p$ → $0$   $\\frac{X^p - 1}{p} = \\text{log}_eX$\n                   \n    where $e \\approx 2.718$ is the base of the natural logarithms. Thus, we will take $X^{(0)} \\equiv log(X)$.\n\n- It is generally more convenient to use logs to the base 10 or base 2, which are more easily interpreted than logs to the base e.\n\n- Changing bases is equivalent to multiplying your variable by a constant. No effect on significance tests.\n\n\n-----\n\n- Descending the *ladder* of powers and roots from $p = 1$ (i.e., no transformation) towards $p = -2$ **compresses the large values of X and spreads out the small ones**.\n\n- Ascending the ladder of powers from $p = 1$ towards $p = 3$ has the **opposite effect**.\n\n-----\n\n- Power transformations are sensible only when all of the values of $X$ are positive:\n\n    - Some of the transformations, such as log ($p= 0$) and square root ($p= .5$), are undefined for negative or zero values of $X$.\n\n    - Power transformations are not monotone (i.e., they change to order of scores) when there are both positive and negative values among the data.\n\n    - We can add a positive constant (called a *start*) to each data value to make all of the values positive: \n\n      $X$ → $(X + s)^{(p)}$\n    \n-----\n\n- Power transformations are effective only when the ratio of the biggest data values to the smallest ones is sufficiently large; if this ratio is close to 1, then power transformations are nearly linear.  For example:  \n\n    - Power transformations will work well if range of $X = 1 – 100$.\n  \n    - Power transformations will have little effect if range of $X = 1000 – 1100$\n    \n- Using a negative start can often increase the ratio of highest/lowest score.\n\n- Using reasonable starts, if necessary, an adequate power transformation can usually be found in the range $−2 \\le p \\le 3$.\n\n-----\n\n- Power transformations of $Y$ (or sometimes $X$) can correct problems with normality of errors.\n\n- Power transformations of $Y$ (or sometimes $X$) can stabilize the variance of the errors.\n\n- Power transformations of $X$ (or sometimes $Y$) can make many nonlinear relationships more nearly linear.\n\n- You can experiment with Box-Cox transformations of $X$ or $Y$ in R using `bcPower()` in the `car` package.\n\n- In many fields, $X^p$ rather than $X^{(p)}$ may be preferred. Particularly, if $p \\ge 0$. This is simply done algebraically.\n\n-----\n\n## Transformations: Dealing with Skew\n\n- Transforming $Y$ *down the ladder* can correct positive skew in the errors (most common problem).  \n\n- Transforming $Y$ *up the ladder* corrects negative skew in the errors.\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nset.seed(102030)\ny <- tibble(y_raw = rchisq(n=500, df=1),\n            y_.5 = car::bcPower(y_raw, .5),\n            y_.25 = car::bcPower(y_raw, .25),\n            y_0 = car::bcPower(y_raw, 0))    \n\nplot_raw <- y |> \n  ggplot(aes(x = y_raw)) +\n  geom_density() + \n  scale_x_continuous(limits = c(-.5, 12), breaks = c(0, 2, 4, 6, 8, 10)) +\n  labs(title = \"Raw Y\",\n       x = NULL,\n       caption = str_c(\"N = 500; bandwidth = \", round(density(y$y_raw)$bw, 4)))\n\nplot_.5 <- y |> \n  ggplot(aes(x = y_.5)) +\n  geom_density() + \n  scale_x_continuous(limits = c(-3, 5), breaks = c(-2, 0, 2, 4)) +\n  labs(title = \"p = .5; sqrt(Y)\",\n       x = NULL,\n       caption = str_c(\"N = 500; bandwidth = \", round(density(y$y_.5)$bw, 4)))\n\nplot_.25 <- y |> \n  ggplot(aes(x = y_.25)) +\n  geom_density() + \n  scale_x_continuous(limits = c(-4.5, 4), breaks = c(-4, -2, 0, 2, 4)) +\n  labs(title = \"p = .25\",\n       x = NULL,\n       caption = str_c(\"N = 500; bandwidth = \", round(density(y$y_.25)$bw, 4)))\n\nplot_0 <- y |> \n  ggplot(aes(x = y_0)) +\n  geom_density() + \n  scale_x_continuous(limits = c(-15, 4), breaks = c(-15, -10. -5, 0)) +\n  labs(title = \"p = 0; log(Y)\",\n       x = NULL,\n       caption = str_c(\"N = 500; bandwidth = \", round(density(y$y_0)$bw, 4)))\n\n\n(plot_raw + plot_.5) / (plot_.25 + plot_0)\n```\n\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n## Transformations: Dealing with Heteroscedasticity\n\n- Transforming $Y$ *down the ladder* can correct problems with increasing spread of errors as $Y$ increases (most common problem).  \n\n- Transforming $Y$ *up the ladder* corrects decreasing spread. \n\n- The problems of unequal spread and skewness commonly occur together and can be corrected together. Therefore, transforming $Y$ down the ladder can correct both issues simultaneously.\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(car) # needed for model_assumptions\nlibrary(psych) # needed for model_assumptions\nlibrary(gvlma) # needed for model_assumptions\n\npath_data <- \"data_lecture\"\n\ndata <- read_csv(here::here(path_data, \"7_three_predictors_fps.csv\"), \n                 show_col_types = FALSE) |> \n   mutate(sex_c = if_else(sex == \"female\", -.5, .5)) |> \n   # remove outliers to fit same model as last two units \n   filter(!subid %in% c(\"0125\", \"2112\"))\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/model_assumptions.R?raw=true\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- lm(fps ~ bac + ta + sex_c, data = data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_assumptions(m, Type = \"normal\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_assumptions(m, Type = \"constant\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSuggested power transformation:  0.2555876 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::ncvTest(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 21.89294, Df = 1, p = 0.0000028829\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngvlma(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fps ~ bac + ta + sex_c, data = data)\n\nCoefficients:\n(Intercept)          bac           ta        sex_c  \n    26.5528    -228.8721       0.1256     -15.4874  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = m) \n\n                    Value  p-value                   Decision\nGlobal Stat        9.8263 0.043458 Assumptions NOT satisfied!\nSkewness           0.2921 0.588886    Assumptions acceptable.\nKurtosis           1.0393 0.307987    Assumptions acceptable.\nLink Function      0.1898 0.663091    Assumptions acceptable.\nHeteroscedasticity 8.3051 0.003953 Assumptions NOT satisfied!\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n## Box Cox Transformation Function\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  select(bac, ta, sex_c, fps) |> \n  psych::describe() |> \n  select(-c(trimmed, mad, se))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      vars  n   mean     sd median    min    max  range  skew kurtosis\nbac      1 94   0.06   0.04   0.06   0.00   0.14   0.14 -0.09    -1.08\nta       2 94 145.91 104.80 119.00  10.00 445.00 435.00  0.91     0.03\nsex_c    3 94  -0.01   0.50  -0.50  -0.50   0.50   1.00  0.04    -2.02\nfps      4 94  32.19  32.77  19.46 -26.07 136.82 162.89  0.95     0.33\n```\n\n\n:::\n:::\n\n\n\n\nWe are going to first add a constant so all response values are > 0\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  mutate(fps_27 = fps + 27)\n\nm_2 <- lm(fps_27 ~ bac + ta + sex_c, data = data)\n```\n:::\n\n\n\n\n-----\n\nNext we will pull the best lambda value from a plot of log-likelihood values by lambda power transformations of response variable.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::boxCox(m_2)\n\nround(car::boxCox(m_2)$x[which.max(car::boxCox(m_2)$y)],2)\n```\n\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.59\n```\n\n\n:::\n:::\n\n\n\n\n\n-----\n\nLastly, we will use the best lambda value to conduct our power transformation and re-evaluate our model assumptions. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  mutate(fps_bc = car::bcPower(fps_27, .59))\n\nm_3 <- lm(fps_bc ~ bac + ta + sex_c, data = data)\n```\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_transformations_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSuggested power transformation:  -0.7589885 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncar::ncvTest(m_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 18.07838, Df = 1, p = 0.000021199\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ngvlma(m_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fps_bc ~ bac + ta + sex_c, data = data)\n\nCoefficients:\n(Intercept)          bac           ta        sex_c  \n   15.46968    -39.84730      0.02186     -2.54285  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = m_3) \n\n                      Value     p-value                   Decision\nGlobal Stat        33.41750 0.000000981 Assumptions NOT satisfied!\nSkewness            6.39244 0.011460724 Assumptions NOT satisfied!\nKurtosis           19.36246 0.000010811 Assumptions NOT satisfied!\nLink Function       0.03714 0.847180760    Assumptions acceptable.\nHeteroscedasticity  7.62546 0.005755008 Assumptions NOT satisfied!\n```\n\n\n:::\n:::\n\n\n\n\n**Transformations often don't help!**\n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_3 |> \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  15.5      1.22        12.7  1.08e-21\n2 bac         -39.8     13.7         -2.90 4.70e- 3\n3 ta            0.0219   0.00518      4.22 5.79e- 5\n4 sex_c        -2.54     1.08        -2.35 2.10e- 2\n```\n\n\n:::\n:::\n\n\n\n\n-----\n\nWhite (1980) Heteroscedasticity-corrected SEs and Tests\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrected_ses <- sqrt(diag(hccm(m)))\n\nbroom::tidy(m) |> \n  select(term, estimate) |> \n  add_column(std.error = corrected_ses) |> \n  mutate(statistic = estimate/std.error,\n         p.value = 2*(pt(abs(statistic), df=m_2$df.residual, lower.tail=FALSE)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)   26.6      6.90        3.85 0.000220 \n2 bac         -229.      72.1        -3.18 0.00204  \n3 ta             0.126    0.0304      4.13 0.0000799\n4 sex_c        -15.5      5.70       -2.72 0.00791  \n```\n\n\n:::\n:::\n\n\n\n\n*Maybe* better choicer was untransformed Y (original model) with corrected SEs?    \n \n*Maybe* the problem wasn’t bad enough to do anything?\n\n-----\n\n## Transformations: Dealing with Non-linearity\n\n\n",
    "supporting": [
      "09_transformations_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}