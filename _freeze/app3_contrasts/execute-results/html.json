{
  "hash": "1af2f65c65142abc9e566e80423becc3",
  "result": {
    "engine": "knitr",
    "markdown": "# Monte Carlo Simulation of Contrast Approaches {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(broom)\n```\n:::\n\n\n\n\n### 3 Groups with No Group Differences (Type I Errors) \n\nSet up simulation characteristics for Null Findings\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate N experiments\nn_experiments <- 20000\n\n# group means\nm_1 <- 10\nm_2 <- 10\nm_3 <- 10\n\nsd <- 20 # sd for y\nn <- 50 # group size\n\n# set up x as factor\nx <-  factor(c(rep(\"a\", n), rep(\"b\", n), rep(\"c\", n)))  \n\nset.seed(1234567)\n```\n:::\n\n\n\n\n--------------------------------------------------------------------------------\n\n**1. POCs - all focal (separate research questions)**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsimulate_poc <- function(i) {\n  # vector of y for three groups\n  y <- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  \n  # fit model\n  results <- lm(y ~ x) |> \n    tidy()\n  \n  # extract and organize key results\n  tibble(sim = i,\n         sig_c1 = results$p.value[2] < 0.05,\n         sig_c2 = results$p.value[3] < 0.05,\n         sig_any = any(results$p.value[2:3] < 0.05))\n}\n\ncontrasts(x)<- matrix(c(2, -1, -1,\n                         0,  1, -1), \n                       ncol = 2,\n                       dimnames = list(levels(x),\n                                       c(\"a_v_bc\", \"b_v_c\")))\ntype1_poc <- map(1:n_experiments, simulate_poc) |> \n  list_rbind()\n```\n:::\n\n\n\n\nResults (to make clear what function returns)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype1_poc |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n    sim sig_c1 sig_c2 sig_any\n  <int> <lgl>  <lgl>  <lgl>  \n1     1 FALSE  FALSE  FALSE  \n2     2 FALSE  FALSE  FALSE  \n3     3 TRUE   FALSE  TRUE   \n4     4 FALSE  FALSE  FALSE  \n5     5 FALSE  FALSE  FALSE  \n6     6 FALSE  FALSE  FALSE  \n```\n\n\n:::\n:::\n\n\n\n\nTest wise type I error for each contrast is 5%\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(type1_poc$sig_c1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0491\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(type1_poc$sig_c2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0545\n```\n\n\n:::\n:::\n\n\n\n\nThe results across contrasts are independent because they come from different families\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(type1_poc$sig_c1, type1_poc$sig_c2) |> round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01\n```\n\n\n:::\n:::\n\n\n\n\nTo be clear, the family-wise type I error across the set is 10% BUT often not considered in same family so not important?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(type1_poc$sig_any)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1002\n```\n\n\n:::\n:::\n\n\n\n\n--------------------------------------------------------------------------------\n\n**2. All (3) pairwise contrasts (no protection).** \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsimulate_uncorrected <- function(i) {\n  # vector of y for three groups\n  y <- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  \n  # fit first model\n  contrasts(x) <- contr.treatment(levels(x), base = 3) \n  results_3 <- lm(y ~ x) |> \n    tidy()\n \n  # fit second model \n  contrasts(x) <- contr.treatment(levels(x), base = 1) \n  results_1 <- lm(y ~ x) |> \n    tidy()\n \n  # extract and organize key results \n  tibble(sim = i,\n         sig_d1 = results_3$p.value[2] < 0.05,\n         sig_d2 = results_3$p.value[3] < 0.05,\n         sig_d3 = results_1$p.value[2] < 0.05,\n         sig_any = any(c(results_3$p.value[2:3], results_1$p.value[2]) < 0.05))\n}\n\ntype1_pair <- map(1:n_experiments, simulate_uncorrected) |> \n  list_rbind()\n```\n:::\n\n\n\n\nTest-wise Type I for each contrast is 5%\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(type1_pair$sig_d1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0508\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(type1_pair$sig_d2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.051\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(type1_pair$sig_d3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0529\n```\n\n\n:::\n:::\n\n\n\n\nBut these are from same family (results of contrasts are related)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(type1_pair$sig_d1, type1_pair$sig_d2) |> round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.15\n```\n\n\n:::\n\n```{.r .cell-code}\ncor(type1_pair$sig_d1, type1_pair$sig_d3) |> round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.16\n```\n\n\n:::\n\n```{.r .cell-code}\ncor(type1_pair$sig_d2, type1_pair$sig_d3) |> round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.15\n```\n\n\n:::\n:::\n\n\n\n\nFamily-wise error rate is higher (but not 15% because contrasts are dependent/related)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(type1_pair$sig_any)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.12425\n```\n\n\n:::\n:::\n\n\n\n\n--------------------------------------------------------------------------------\n\n**3. Fisher LSD with 3 pairwise comparisons**\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsimulate_fisher <- function(i) {\n  y <- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  contrasts(x) <- contr.treatment(levels(x), base = 3) \n  results_3 <- lm(y ~ x) |> \n    tidy()\n  \n  contrasts(x) <- contr.treatment(levels(x), base = 1) \n  results_1 <- lm(y ~ x) |> \n    tidy()\n  \n  sig_omnibus <- anova(lm(y ~ x))$`Pr(>F)`[1] < 0.05\n  \n  # extract and organize key results \n  tibble(sim = i,\n         sig_d1 = sig_omnibus && results_3$p.value[2] < 0.05,\n         sig_d2 = sig_omnibus && results_3$p.value[3] < 0.05,\n         sig_d3 = sig_omnibus && results_1$p.value[2] < 0.05,\n         sig_any = sig_omnibus && any(c(results_3$p.value[2:3], results_1$p.value[2]) < 0.05))\n}\n\ntype1_fish <- map(1:n_experiments, simulate_fisher) |> \n  list_rbind()\n```\n:::\n\n\n\n\nTest-wise Type I for each contrast is < 5% (too conservative!)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(type1_fish$sig_d1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02365\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(type1_fish$sig_d2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.024\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(type1_fish$sig_d3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0228\n```\n\n\n:::\n:::\n\n\n\n\nThese are from same family (results of contrasts are even more related)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(type1_fish$sig_d1, type1_fish$sig_d2) |> round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.32\n```\n\n\n:::\n\n```{.r .cell-code}\ncor(type1_fish$sig_d1, type1_fish$sig_d3) |> round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.32\n```\n\n\n:::\n\n```{.r .cell-code}\ncor(type1_fish$sig_d2, type1_fish$sig_d3) |> round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.29\n```\n\n\n:::\n:::\n\n\n\n\nFamily-wise error rate is controlled at 5% \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(type1_fish$sig_any)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0474\n```\n\n\n:::\n:::\n\n\n\n\n--------------------------------------------------------------------------------\n\n**4. Holm-Bonferroni correction with 3 pairwise comparisons**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_hb <- function(i) {\n  y <- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  contrasts(x) <- contr.treatment(levels(x), base = 3) \n  mod_1 <- lm(y ~ x)\n  results_1 <- broom::tidy(mod_1)\n  \n  contrasts(x) <- contr.treatment(levels(x), base = 1) \n  mod_2 <- lm(y ~ x)\n  results_2 <- broom::tidy(mod_2)\n  \n  significant <- any(p.adjust(c(results_1$p.value[2:3], results_2$p.value[2]), method = \"holm\") < 0.05)\n\n  return(if_else(significant, 1, 0))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntype_1 <- map_int(1:n_experiments, simulate_hb)\n```\n:::\n\n\n\n\nAverage type I error is 0.04525\n    \n--------------------------------------------------------------------------------\n\n### 3 Groups with One Group Difference (Type II Errors)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_1 <- 10\nm_2 <- 10\nm_3 <- 20\n```\n:::\n\n\n\n\n--------------------------------------------------------------------------------\n\n**1. Fisher LSD with 3 pairwise comparisons**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_fisher <- function(i) {\n  y <- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  contrasts(x) <- contr.treatment(levels(x), base = 3) \n  mod_1 <- lm(y ~ x)\n  results_1 <- broom::tidy(mod_1)\n  omnibus <- anova(mod_1)$`Pr(>F)`[1]\n  \n  contrasts(x) <- contr.treatment(levels(x), base = 1) \n  mod_2 <- lm(y ~ x)\n  results_2 <- broom::tidy(mod_2)\n  \n  significant <- omnibus < .05 && ((results_1$p.value[2] < 0.05) || \n                                     (results_1$p.value[3] || results_2$p.value[2] < 0.05))\n\n  return(if_else(significant, 0, 1))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntype_2 <- map_int(1:n_experiments, simulate_fisher)\n```\n:::\n\n\n\n\nAverage type II error is 0.2765\n\n--------------------------------------------------------------------------------\n\n**2. Holm-Bonferroni correction with 3 pairwise comparisons**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_hb <- function(i) {\n  y <- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  contrasts(x) <- contr.treatment(levels(x), base = 3) \n  mod_1 <- lm(y ~ x)\n  results_1 <- broom::tidy(mod_1)\n  \n  contrasts(x) <- contr.treatment(levels(x), base = 1) \n  mod_2 <- lm(y ~ x)\n  results_2 <- broom::tidy(mod_2)\n\n  \n  significant <- any(p.adjust(c(results_1$p.value[2:3], results_2$p.value[2]), method = \"holm\") < 0.05)\n\n  return(if_else(significant, 0, 1))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntype_2 <- map_int(1:n_experiments, simulate_hb)\n```\n:::\n\n\n\n\nAverage type II error is 0.29885\n\n--------------------------------------------------------------------------------\n\n### 3 Groups with All Groups Different (Type II Errors)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_1 <- 10\nm_2 <- 20\nm_3 <- 30\n```\n:::\n\n\n\n\n\n**1. Fisher LSD with 3 pairwise comparisons**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype_2 <- map_int(1:n_experiments, simulate_fisher)\n```\n:::\n\n\n\n\nAverage type II error is 0.00425    \n\n\n**2. Holm-Bonferroni correction with 3 pairwise comparisons**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype_2 <- map_int(1:n_experiments, simulate_hb)\n```\n:::\n\n\n\n\nAverage type II error is 0.0045\n  \n:::{.fragment}\n::: {.callout-important}\n# Question\n\nWhat would family-wise error rate be if we conducted only 2 dummy contrasts?\n:::\n:::\n\n:::{.fragment}\n[$\\le .10$, but they would definitely be considered in the same family (related questions) and most people won't tolerate this.]{style=\"color:blue;\"}\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}