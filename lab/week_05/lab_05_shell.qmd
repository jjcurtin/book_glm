---
title: "Lab 5 Shell" 
author: "TAs" 
date: "`r lubridate::today()`"
format: 
  html:
    toc: true 
    toc_depth: 4
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

## Housekeeping

Thank you all for your valuable feedback/comments on hw3:D! Based on your answers, we have decided to make following changes to our workflow in future lab sections:

-   At the beginning of each lab, we'll take a few minutes to answer questions about lecture content.

-   We'll now include some simple content-related exercises during lab (in addition to coding)!

-   Some of you suggested releasing the TA script before lab. After some serious discussions between John and the TAs, we were hesitant to do so. We still think it's best practice to write out code by hand and to debug when errors occur. We do understand your concerns about falling behind during lab when some lines of codes don't work. So alternatively, we have decided to implement minor checkpoints throughout each lab where we will stop and make sure everyone is caught up. Of course, we can help you debug outside of these points, too. :^)

## Questions about the application exam or other material?

### Conventions for decimals ("sig. Figs") when reporting statistics

b and F values:

-   Always include the digit(s) preceding the decimal
-   If the number is less than one, report 0.xxx (e.g., 0.852)
-   Otherwise, report two decimal places after the decimal (e.g., 2.85)

p values:

-   Because p values are bounded by 0 and 1, *do not* report the digit before the decimal place
-   Report 3 digits after the decimal
-   Although you can just report the most stringent level of significance which the p value falls under (e.g., p = .003 --> p < .005), it is good practice to report exact p values to the 3rd decimal place, for transparency of your results...
- ...Except for p values smaller than .001, just report p < .001!

## Concept Question Exercise

What is our measurement of the total prediction error associated with a given model? In the context of testing statistical models, what does it mean to "reduce error"?

> You answer here.

## Exercise Week!

### Exercise 1: Calculating Parameter Estimates

Abdul is running a study to see if listening to classical music before going to sleep leads to more restful sleep. He assigns one group of participants to listen to classical music before bed and another group to listen to no music before bed. He then asks participants to report how restful their sleep was each night.

Abdul runs a simple regression analysis (`sleep` ~ `group_c`) and reports the following results:
$b_0 = 3.01, \text{SE} = .08, b_1 = 1.15, \text{SE} = .16, F(1, 197) = 53.01, p < .001, \eta_p^2 = .21.$


#### a. Note above that Abdul centered the `group` variable (-.5/no music, .5/music). What would the value of $b_0$ and $b_1$, and the SE for $b_1$ be if `group` had been dummy coded (0/no music, 1/music)?

$b_0 = $   
$b_1 = $ 
$b_1 \text{ SE} = $


#### b. What would the value of $b_0$ and $b_1$, and the SE for $b_1$ be if `group` had been coded as 1 (no music) and 0 (music)?

$b_0 = $
$b_1 = $ 
$b_1 \text{ SE} = $

#### c. What would the value of $b_0$ and $b_1$, and the SE for $b_0$ and $b_1$ be if `group` had been coded as -1 (no music) and 1 (music)?

$b_0 = $   
$b_0 \text{ SE} = $  
$b_1 = $  
$b_1 \text{ SE} = $

Note that the df numerator and denominator do not change and so $F$ and $p$ do not change. $\eta_p^2$ does not change either. The fact that $F$ and $t$ do not change illustrates why the new SE for $b_1$ is half of the old SE. Remember that $t = b_1/\text{SE}_{b_1}$. If the new $b_1$ is half of the old $b_1$, then the new SE for $b_1$ needs to be half of the old SE for the $t$ to remain the same.

#### d. Using the original values provided above, calculate the $t$-value for $b_1$.

t =





#### e. What was the sample size in this study?

$n = $

`CHECKPOINT`


### Exercise 2: Model Predictions

For this exercise, we are going to be using a dataset called `Prestige` that is part of the `car` package. To use these data, we do not need load the library, but you will need to have the package installed in Quarto. Note that because of this, we won't be assigning our `path_data` object here. 

```{r}
#| message: false
#| warning: false

options(conflicts.policy = "depends.ok") 
#install.packages("car")
library(tidyverse)
library(broom)
library(skimr)

theme_set(theme_classic()) 
```

**How do we get the documentation for the Prestige dataset?**
```{r}
#| eval: false


```

**How do we load data that are included in an R package?** 
```{r}


```


#### a. The variables `education` and `income` were calculated based on averages from the year 1971 in Canada. The average income in Canada in 1970 was estimated at $5,000 exactly. Conduct a test to determine if the average income in 1971 is significantly different from the average income in 1970. At this point, let's ignore all the other variables in the file. 

Calculate sum of squared errors for our compact model using average income in 1970.

```{r}
d <- d |> 
  mutate(squ_err_c= )

(sse_c <- d |> 
  summarise(sse_c = ) |> 
  pull(sse_c))
```

Calculate sum of squared errors for our augmented model using average income in 1971.

```{r}
d <- d |> 
  mutate(squ_err_a = )

(sse_a <- d |> 
  summarise(sse_a = ) |> 
  pull(sse_a))
```

Let's now practice defining a function to calculate the sum of squared errors.

```{r}
# define a function to calculate sse



# fit our 1 parameter (mean-only) model


```


Let's now define `n`, `n_param_a`, and `n_param_c`. We will manually calculate the F-statistic and p-value.

```{r}
n <- 
n_param_a <- 
n_param_c <- 

(f_stat <- )


df_n <- 
df_d <- 

pf()
```


**Was the average income in 1971 significantly different from the average income in 1970?**



#### b. Now you want to know if there is a relationship between `income` and `education`. Note that `education` is a quantitative (continuous) variable. Specifically, you hypothesize that individuals with more years of education have higher income.

First, let's mean-center `education` to prepare our dataset for analysis. Call this variable `edu_c`.

```{r}


```

Second, fit the model with our centered variable `edu_c`.

```{r}


```

$b_0$ = the predicted income for an individual who has an average number of years in education.

$b_1$ = the increase in `income` for every one unit increase in `edu_c`.

Third, fit the model with our uncentered variable `education`. How does this compare with our previous model `m_edu_c`?

```{r}


```

$b_0$ = the predicted income for an individual who has 0 years in education.

$b_1$ = the increase in `income` for every one unit increase in `edu_c`.


#### c. Now we want to test if the average income for people with average education is different from $5000.

```{r}
coeffs <-
  
coeffs
```

We can calculate `t` using the formula: (B - B_Null)/SE_B

```{r}
t <- 

t
```

Next, we need to find our df. 

```{r}
# If there are no missing data, we can use this: 


# Better method:

```

Calculate p-value. 

```{r}
pt <-   
```

> Write answer here. 


#### d. Calculate PRE for `edu_c`.

Define a function called "pre()" that takes the values of "compact" and "augmented".

```{r}
pre <- function(compact, augmented) {
  sse_c <- sse(compact)
  sse_a <- sse(augmented)
  (sse_c - sse_a)/sse_c
}

pre(compact = ,
    augmented = )
```

> Write answer here. 


`CHECKPOINT`


#### e. Now let's switch to a dichotomous predictor! Now you want to know if there is a relationship between `income` and job `type` (blue collar + white collar vs. professional). Specifically, you hypothesize that professional jobs will have higher income than blue and white collar jobs.

First, let's inspect what the levels of `type` variable are. 

```{r}

```

Second, recode `type` into a 2-level predictor: collar (blue + white) vs. prof.

```{r}
d <- d |> 
  mutate(type2 = )




table(d$type2)
```

Notice that the class of the variable `type2` changes after using the function `case_match`.

```{r}
class(d$type)
class(d$type2)
```

Let's recode `type2` so that `collar` is 1 and `prof` is 0. Call this variable `type_collar`.

```{r}
d <- d |> 
  mutate(type_collar = )
```

Now, let's try recoding `type2` so that `prof` is 1 and `collar` is 0. Call this variable `type_prof`.

```{r}
d <- d |> 
  mutate(type_prof = )
```

Finally, recode `type2` so that `collar` is -.5 and `prof` is .5. Call this variable `type_c`.

```{r}
d <- d |> 
  mutate(type_c = )
```


#### f. Fit a linear model in which `income` is regressed on `type_collar`. What do the estimates for $b_0$ and $b_1$ represent? Provide a conceptual interpretation for each parameter estimate.

```{r}
m_collar <- lm()

tidy(m_collar)
```

$b_0$ = the predicted income for an individual who works a professional job.

$b_1$ = the income difference between professional workers and collar workers.


#### g. Fit a linear model in which income is regressed on `type_prof`. What do the estimates for $b_0$ and $b_1$ represent? Provide a conceptual interpretation for each parameter estimate.

```{r}
m_prof <- lm()

tidy(m_prof)
```

$b_0$ = the predicted income for an individual who works a collar job.

$b_1$ = the income difference between collar workers and professional workers.


#### h. Fit a linear model in which income is regressed on `type_c`. What do the estimates for $b_0$ and $b_1$ represent? Provide a conceptual interpretation for each parameter estimate.

```{r}
m_c <- lm() 

tidy(m_c)
```

$b_0$ = the predicted income for an individual who works a theoretical half-collar, half-professional job.

$b_1$ = the difference in income between collar and professional jobs.


`CHECKPOINT`

#### i. Calculate PRE for `type_c`.

Previously, we defined a function called "pre()" that takes the value of "compact" and "augmented".

```{r}
pre <- function(compact, augmented) {
  sse_c <- sse(compact)
  sse_a <- sse(augmented)
  (sse_c - sse_a)/sse_c
}

pre(compact = ,
    augmented = )
```

> Write answer here. 

`CHECKPOINT`


### Exercise 3: Graphing

#### a. Create a quick and dirty plot of the relationship between `income` and `type_c`. 

```{r}


```

#### b. In just three steps, set up a new dataframe called `d_plot`. This dataframe should contain predicted values for the outcome variable, SE, lower and upper confidence intervals, centered numeric values for collar and professional workers, and character values that can serve as labels for collar and professional workers.

```{r}
d_new <-
  

  
preds <-

  


d_plot <-
  
```


#### c. Build a bar graph in ggplot using the dataframe `d_plot`.
 
Your plot should include:   
      
- bars representing the dichotomous `type_c` variable.
- error bars.
- raw data points.
- publication quality labels
- no legend

First, make it clear what each level of `type_c` represents in the dataframe `d`. 
```{r}
d <- d |> 
  mutate(type_c_fac = factor(type_c, 
                             levels = c(-0.5, 0.5),
                             labels = c("collar", "prof")))
```

```{r}
d_plot |> 
  
```


