---
title: "Lab 8 Student Shell" 
author: "TAs" 
date: "`r lubridate::today()`"
format: 
  html:
    toc: true 
    toc_depth: 4
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

## Set up for the week!

First, let's set up our script. If you have created your own functions script, this is a great place to source that in. 

```{r}
#| message: false
#| warning: false

options(conflicts.policy = "depends.ok") 
library(tidyverse)
library(skimr)
library(broom)

path_data <- "lab/data"

theme_set(theme_classic()) 
```

## Finishing up Week 7 exercises (2+ predictor models & figures) 

We're going to continue using some spectacularly sPoOkY data this lab. As a reminder, it's on Halloween consumer behavior. 

Imagine a hypothetical study by a local newspaper. Earlier this year, 79 community members responded to a survey about how they have celebrated Halloween in the past and how they plan to celebrate Halloween this (coming) October.   

The survey included many items, including the following:    

`costume`: In the past, you have often celebrated Halloween by wearing a costume.    

`decorate`: In the past, you have often celebrated Halloween by decorating your home.       

`plan_buy_costume`: For Halloween this year, it is likely that you will buy some costumes.    

`shopping_early`: For Halloween this year, it is likely that you will go shopping before September.    

The participants responded using a Likert scale: -2 = strongly disagree, -1 = mildly disagree, 0 = neither agree nor disagree, 1 = mildly agree, and 2 = strongly agree.

### Analyses

You are a small-scale Halloween retailer. To prepare for the early Halloween market (pre-September), you hope to gain some insights on what the market will look like using these data.

Let's load in these data. We've already cleaned this dataset for you, but we will come back to these data later on for an in-depth overview of data wrangling and cleaning.
```{r}
d <- read_csv(here::here(path_data, "lab_08_data.csv"),
              show_col_types = FALSE) |> 
  glimpse()
```

Practice viewing correlations, distributions, and scatterplots all in one step using `GGally::ggpairs()`.

```{r}

```

**Which 2 variables are most weakly correlated?**    
     

**Most strongly correlated?**   


#### Quick Overview: Regression with 1 predictor

Celebrating by wearing a costume predicts shopping before September.

```{r}
m_costume <- 

```

Celebrating by decorating predicts shopping before September. 

```{r}
m_decorate <- 

```

### Exercise Time!

#### Regression with 2 predictors   

We will start with the interpretation of 2 predictor models. 

You wonder if celebrating by wearing a costume predicts shopping before September when statistically controlling for celebrating by decorating one's home.    

i.e., Do people who often celebrate by wearing a costume tend to shop early for Halloween, after accounting for how often they celebrate by decorating their home.     
 
**Run a model to see if `costume` predicts shopping before September (`shop_early`), when controlling for decorating.**
```{r}
m_1 <- 

```

In a group of 2-3, discuss how you would interpret $b_0$, $b_1$, and $b_2$. 

**1a. What's the interpretation of b_0?**    


**1b. What's the interpretation of b_1?**  


**1c. What's the interpretation of b_2?**    
   

**How would the model comparison (using anova) differ if you wanted to test the effect of `decorate`, controlling for the costume predictor?**

```{r}

```


**How much of the variance in `shop_early` is uniquely explained by each of the two predictors?**

If you didn't source in your functions elsewhere, remember to run this!
```{r}
sse <- function(model) {
  sum(residuals(model)^2)
}

delta_r2 <- function(compact, augmented) {
  glance(augmented)$r.squared - glance(compact)$r.squared
}
```

$\Delta R^2$ for `costume`
```{r}

```

$\Delta R^2$ for `decorate`
```{r}

```

Both are extremely low.    

### Plotting

In a group of 2-3, practice creating a plot showing the effect of `costume` on `shop_early` when controlling for `decorate` (i.e., m_1).

Since `costume` is the focal predictor, we will set `decorate` to 0 for our predictions. You could also choose to set `decorate` to another meaningful and interpretable value. 

```{r}
d_new <- 

preds <- 

ggplot() 
```

Class Exercise: Conceptual Questions 
**Identify $b_0$ and $b_1$ in the figure.**

**Interpret $b_0$ and $b_1$ in the figure.**

$b_0$: 

$b_1$: 

**How would the interpretation of $b_0$ and $b_1$ change if you fit a  new model where the Likert scale for `costume` was the following: 0 = strongly disagree, 1 = mildly disagree, 2 = neither agree nor disagree, 3 = mildly agree, and 4 = strongly agree.**

$b_0$: 

$b_1$: 


**End of exercise!**

`CHECKPOINT`


#### Regression with 3 Predictors

As a Halloween retailer, you want to know if people who actually plan to purchase costumes are more likely to shop for Halloween early on (before September), when controlling for the degree to which they celebrate Halloween by wearing costumes and by decorating their home.   

**What is the focal predictor?**     
`plan_buy_costume`     

**Fit the new model.**
```{r}
m_2 <- 
```

**What is the interpretation of the intercept for `m_2`?**    
   

**What is the interpretation of the coefficient for `plan_buy_costume` and what does the coefficient tell us?**   
 

**After removing the variance explained by `costume` and `decorate`, how much of the residual variance in `shop_early` does `plan_buy_costume` account for?**   


```{r}
sse_a <- sum(residuals(m_2)^2)
sse_c <- sum(residuals(lm(shop_early ~ costume + decorate, data = d))^2)

(sse_c - sse_a)/sse_c

sse<- function(model){
  sum(residuals(model)^2)
}

pre <- function(m_comp, m_alt){
  (sse(m_comp) - sse(m_alt))/sse(m_comp)
}


```

### VIF in a 3 predictor model

Let's revisit the correlation between the variables. 
```{r}
d |> 
  select(-id) |> 
  GGally::ggpairs()
```

Let's see how much variance in `plan_buy_costume` is accounted for by `costume` and `decorate`
```{r}
m_plan_buy_costume <- 


```

In fact, `costume` and `decorate` accounts for 6% of the variance in `plan_buy_costume`!   

As a reminder, when variables in the model are very highly correlated, this is called *multicollinearity*. When multicollinearity occurs, it inflates standard errors and changes the magnitude of regression coefficients.    

We can directly test the multicollinearity of each predictor in our model using the `vif()` function in the `car` package.
```{r}

```

VIF stands for **variance inflation factor**. A conventional cutoff for vif is 5, such that if you have a VIF value >= 5 for your focal predictor, then multicollinearity is a problem.    

Good-to-know knowledge:   
$VIF_j = 1 / (1â€“R_j^2)$     
$R_j^2$: percent variance in predictor j that is explained by all other predictors.    

**What level of $R_j^2$ is problematic, given the conventional cutoff for vif = 5?**    
When $R_j^2$ > 0.8

### Plotting

Create a plot showing the effect of `plan_buy_costume` on `shop_early` when controlling for `costume` and `decorate` (i.e., `m_2`).    

Since `plan_buy_costume` is the focal predictor, we will just set the other covariates to 0 for our predictions. We could also set these covariates to another meaningful, interpretable value.
```{r}
#Using raw data points. When using the raw data points, the variance of `shop_early` comes from `costume`, `decorate`, `plan_buy_costume` and noise. 
d_new_2 <- 

preds_2 <- 

ggplot()
```

```{r}
#Using residualized data points. When using residualized data points, the variance of `shop_early` comes from `plan_buy_costume` and noise only.
d_new_3 <- 

res = 

#We are adding noise back in when adding residuals(m_2)
res <- res |> mutate()

view(res)

preds_3 <- 

ggplot()
```

Class Exercise: Conceptual Questions
**Identify $b_0$ and $b_1$ in the figure.**

**Interpret $b_0$ and $b_1$ in the figure.**
$b_0$: 

$b_1$: 

**How would the interpretation of $b_0$ and $b_1$ change if the Likert scale for `plan_buy_costume` was the following: 0 = strongly disagree, 1 = mildly disagree, 2 = neither agree nor disagree, 3 = mildly agree, and 4 = strongly agree.**

$b_0$: 

$b_1$: 
