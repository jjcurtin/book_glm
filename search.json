[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to the General Linear Model",
    "section": "",
    "text": "Course Syllabus",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#course-designations-and-attributes",
    "href": "index.html#course-designations-and-attributes",
    "title": "Introduction to the General Linear Model",
    "section": "Course Designations And Attributes",
    "text": "Course Designations And Attributes\n\nCourse Website: https://jjcurtin.github.io/book_glm/\nCredits: 4\nLevel: Advanced\nBreadth: Social Science\nL&S Credit Type: Counts as LAS credit (L&S)\nInstructional Mode: All face-to-face\nHow Credit Hours are met by the Course: Four and ½ hours of classroom or direct faculty/instructor instruction and a minimum of eight hours of out of class student work each week over approximately 14 weeks.\nRequisites: None",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#meeting-time-and-location",
    "href": "index.html#meeting-time-and-location",
    "title": "Introduction to the General Linear Model",
    "section": "Meeting Time And Location",
    "text": "Meeting Time And Location\n\nLecture: Monday and Wednesday, 2:30-3:45 pm; Psychology 103\nLabs:\n\nFriday 9:00-11:00 am (section 301, room 228; Punturieri)\nFriday 1:30-3:30 pm (section 302, room 228; Yu)\nFriday 9:00-11:00 am (section 303, room 311i; Dong)",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "Introduction to the General Linear Model",
    "section": "Instructor",
    "text": "Instructor\n\nJohn J. Curtin, Ph.D.\nOffice hours: Room 326, Wednesdays, 3:45 - 4:45 pm or by appt.",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#teaching-assistants",
    "href": "index.html#teaching-assistants",
    "title": "Introduction to the General Linear Model",
    "section": "Teaching Assistants",
    "text": "Teaching Assistants\n\nLiChen Dong; Office hours: Room 626, Mondays, 11 - 12 pm\nClaire Punturieri; Office hours: Room 325, Thursdays, 8:30 - 9:30 am\nCoco Yu; Office hours: Room 325, Tuesdays, 1 - 2 pm",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#communications",
    "href": "index.html#communications",
    "title": "Introduction to the General Linear Model",
    "section": "Communications",
    "text": "Communications\nAll course communications will occur in the course’s Slack workspace. You should have received an invitation to join the workspace. If you have difficulty joining, please let me know immediately. The TAs and I will respond to all Slack messages within 1 business day (and often much quicker). Please plan accordingly (e.g., weekend messages may not receive a response until Monday). For general questions about class, coding assignments, etc., please post the question to the appropriate public channel. If you have the question, you are probably not alone. For issues relevant only to you (e.g., class absences, accommodations, etc.), you can send a direct message in Slack to me and the TAs. If you DM only me, I will share the DM with the TAs unless you request otherwise. Therefore, it is generally best if you include all three TAs on the DM when you start the thread. In general, we prefer that all course communication occur within Slack rather than by email so that it is centralized in one location.",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Introduction to the General Linear Model",
    "section": "Course Description",
    "text": "Course Description\nOne-sample t-test, independent-samples t-test, simple and multiple regression, effect size indicators, analysis of variance (ANOVA), analysis of covariance (ANCOVA), case analysis, model assumptions, transformations, and the generalized linear model",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#course-goals",
    "href": "index.html#course-goals",
    "title": "Introduction to the General Linear Model",
    "section": "Course Goals",
    "text": "Course Goals\nThe goal of this course is to familiarize you with a statistical data analysis procedure called the general linear model. We will spend most of the semester on the use of the general linear model as a tool for analyzing data from psychological experiments. We will give special attention to the interpretation of model parameter estimates, models with quantitative and categorical predictors, and the interpretation of interaction effects in the general linear model. We will be using the statistics software R (http://www.r-project.org/). Please know that extensive work outside the classroom is required in order to succeed in this class. You are encouraged to participate actively in the class, both the lecture and the lab session.",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#course-learning-outcomes",
    "href": "index.html#course-learning-outcomes",
    "title": "Introduction to the General Linear Model",
    "section": "Course Learning Outcomes",
    "text": "Course Learning Outcomes\nBy the end of the course, the students should master the following data-analytic techniques and skills:\n\nInferences about a single mean (t-test)\nThe analysis of single and multiple dichotomous/categorical predictors\nThe analysis of single and multiple quantitative predictors\nThe analysis of interactions among predictors\nThe analysis of contrasts among levels of categorical predictors\nThe use of centering predictors in interactive models\nAssessment and remediation techniques for case analysis and model assumptions\nLogistic regression as exemplar of the generalized linear model\nGenerating publication-level graphs",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#course-requirements-and-grades",
    "href": "index.html#course-requirements-and-grades",
    "title": "Introduction to the General Linear Model",
    "section": "Course Requirements And Grades",
    "text": "Course Requirements And Grades\nCourse requirements include regular attendance, active participation in class discussion, and completion of all exams and application assignments.\nThere will be two closed-book concepts exams completed in class to assess conceptual knowledge and three application exams completed outside of class to assess your ability to implement your conceptual knowledge with real data (each of these 5 exams counts for 15% of your total grade). The first concepts exam is scheduled for Wednesday, 10/23. The second concepts exam is scheduled during the exam period on Wednesday, December 18 from 8:15 - 9:45 am (room TBD). Please plan your end of semester travel accordingly. The application exams will be assigned at the end of weeks 5 (Friday 10/4), 10 (Friday 11/8), and 15 (Wednesday 12/11).\nThere will also be approximately weekly application assignments, which will involve hands-on application of the material similar to (but shorter than) the application exams. They are assigned Fridays at 5 pm and are due the following Friday at 8:30 am. These application assignments are graded on a pass/fail basis, and together constitute 20% of your total grade.\nFinally, 5% of your grade will be determined by your attendance and participation in lecture and lab.\nFinal letter grades are based on total course percentages as follows:\n\nA: 93 or above\nAB: 88 - 92\nB: 83 - 87\nBC: 78 - 82\nC: 70 - 77\nD: 60-69\nF: &lt; 60",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#required-texts",
    "href": "index.html#required-texts",
    "title": "Introduction to the General Linear Model",
    "section": "Required Texts",
    "text": "Required Texts\nJudd, C.M., McClelland, G. H., & Ryan, C. (2017). Data Analysis: A Model- Comparison Approach. 3rd Edition. New York, US: Routledge. ISBN: 9780805833881.",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#additional-required-readings",
    "href": "index.html#additional-required-readings",
    "title": "Introduction to the General Linear Model",
    "section": "Additional Required Readings",
    "text": "Additional Required Readings\nAdditional required readings will be provided as pdfs on the course website. The readings are pulled from various texts and primary sources. Supplemental readings and recommended reference texts are also provided on the course website and the end of this document. You are expected to read only the required readings. You will not be tested on the other readings.",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#required-software",
    "href": "index.html#required-software",
    "title": "Introduction to the General Linear Model",
    "section": "Required Software",
    "text": "Required Software\nThis course will contain a significant applied component. As such, access to statistical analysis software is required. In the context of this course, we will rely heavily on R. R is freely available and is rapidly becoming the standard for statistical analysis in many disciplines.\nA secondary goal of the course will be to provide you with introductory data wrangling skills in R within the Tidyverse ecosystem of packages. The Tidyverse is “an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.” It is arguably the dominant approach for data science in R today.",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#course-schedule",
    "href": "index.html#course-schedule",
    "title": "Introduction to the General Linear Model",
    "section": "Course Schedule",
    "text": "Course Schedule\nThis schedule is provisional so that we may adjust our rate of progress as necessary to ensure maximal mastery of the material. See course website for the most up to date version of the assigned readings and topics.\n\nIntroduction to inferential statistics (1 day)\n\n\nintroduction to the course\nthe GLM framework\ndata exploration in R (descriptive statistics, visual displays) (lab only)\n\n\nSampling Distributions (1 day)\n\n\nstandard deviation, standard error of the mean\ntheory of null hypothesis significance testing\n\n\nInferences about a single mean (one-sample t test) (1 day)\n\n\nthe null model (\\(Y = b_{0}\\))\nsum of squares, number of estimated parameters, residuals, etc.\nthe basic model (\\(Y = b_{0}\\))\nstatistical inference (comparison of basic model with null model, computation of t, interpretation of p)\nwriting up the results (text, graphs, tables) of a one-sample t test\n\n\nInferences about a single quantitative predictor (simple regression) (2 days)\n\n\nthe model : \\(Y = b_0 + b_{1}X_{1}\\) when \\(X_{1}\\) is quantitative\ncomputation of residuals, meaning of residuals\ngraphic representation: intercept, slope, residuals\nstatistical inference (comparison of the new model with the basic model, computation of t and F, interpretation of p)\nproportion of variance explained, computation of \\(R^{2}\\), interpretation of \\(R^{2}\\), effect sizes\nrunning a simple regression in R and interpreting the R output\nwriting up the results (text, graphs, tables) of a simple regression analysis\n\n\nInferences about a single dichotomous predictor (independent-samples t test) (1 day)\n\n\nthe model: \\(Y = b_{0} + b_{1}X_{1}\\) when \\(X_{1}\\) is dichotomous\ncomputation of residuals, meaning of residuals (= within-group variance)\ngraphic representation: intercept, slope, residuals; comparison with bar graph\nstatistical inference (comparison of the new model with the basic model, computation of t and F, interpretation of p)\nrunning an independent-samples t test in R (using the lm() function in R) and interpreting the R output\nwriting up the results (text, graphs, tables) of an independent-samples t test\n\n\nInferences about two (or more) predictors (multiple regression without interaction) (4 days)\n\n\nthe model: \\(Y = b_{0} + b_{1}X_{1} + b_{2}X_{2}\\) when \\(X_{1}\\) is dichotomous and \\(X_{2}\\) is quantitative\nthe model: \\(Y = b_{0} + b_{1}X_{1} + b_{2}X_{2}\\) when \\(X_{1}\\) and \\(X_{2}\\) are both quantitative\ncomputation of residuals, meaning of residuals\ngraphic representation: two lines, intercepts, slopes, residuals\nstatistical inference (model comparison, interpretation of the effect of one variable on DV while controlling for the effects of another variable)\ncomputation of partial r, interpretation of partial r\ndifferent theoretical predictions that can be answered by multiple regression analyses that do not contain interactions\nmodels with 3, 4, 5, etc. predictors\nissues of collinearity, variance inflation, tolerance\ndata fishing, overfitting, hierarchical vs. stepwise vs. simultaneous models\nraw vs. standardized coefficients, partial r\nwriting up the results of a multiple regression analysis\n\n\nDealing with messy data I – case analysis (1 day)\n\n\nthe different ways of being an outlier\noutlier statistics: levers \\(h_{ij}\\), studentized deleted residuals, Cook’s D\ndealing with outliers\n\n\nDealing with messy data II – model assumptions (1 day)\n\n\nthe 5 assumptions of the GLM: exact X, independence, normality, constant variance, and linearity\ndata exploration in R (visual displays: residual plots, normal quantile plots, density plots, spread-level plots, etc.)\nstatistical indicators: ncv test, gvlma test\nfirst remedies: heteroscedasticity-corrected standard errors, weighted least squares\n\n\nDealing with messy data III – transformations (1 day)\n\n\nHow to address violations of GLM model assumptions: power transformations, root transformations, how to find the best transformations\nhow to analyze proportions and correlations as data\n\n\nInferences about two predictors and their interaction (= moderation) (1 day)\n\n\ncentering variables: mean deviation form, contrast codes\nthe model: \\(Y = b_{0} + b_{1}X_{1}c + b_{2}X_{2}c + b_{3}(X_{1}c * X_{2}c\\)) when \\(X_{1}\\) is dichotomous, \\(X_{2}\\) is quantitative and both predictors are centered]\ngraphic representation: different slopes for different folks, \\(b_{3}\\) tests the difference between the two slopes\nwhat happens if variables are not centered?\ninterpretation of an interaction\nwriting up the results of a multiple regression analysis with an interaction\n\n\nInferences about two quantitative predictors and their interaction (1 day)\n\n\nthe model: \\(Y = b_{0} + b_{1}X_{1}c + b_{2}X_{2}c + b_{3}(X_{1}c * X_{2}c\\)) when \\(X_{1}\\) and \\(X_{2}\\) are both quantitative\ninterpretation of an interaction between two quantitative predictors\nthe pitfalls of dichotomization II: imaginary interaction effects\n\n\nInferences about two dichotomous predictors and their interaction (= 2 x 2 ANOVA) (1 day)\n\n\nthe model: \\(Y = b_{0} + b_{1}X_{1}c + b_{2}X_{2}c + b_{3}(X_{1}c * X_{2}c\\)) when \\(X_{1}\\) and \\(X_{2}\\) are both dichotomous\ndifference between main effects and simple effects\ninterpretation of interactions in 2 x 2 ANOVAs (Rosnow & Rosenthal)\ncomparison of the GLM terminology and the ANOVA terminology\nthe pitfalls of dichotomization I: loss of power, biased estimates\nwriting up the results of a 2 x 2 ANOVA\n\n\nInferences about three predictors and one interaction (= ANCOVA) (1 day)\n\n\nthe model: \\(Y = b_{0} + b_{1}X_{1}c + b_{2}X_{2}c + b_{3}(X_{1}c * X_{2}c) + b_{4}X_{3}\\) when \\(X_{1}\\) and \\(X_{2}\\) are both dichotomous and \\(X_{3}\\) is quantitative\ninterpretation of \\(b_{3}\\)\ngeneralization to other models (e.g., the covariate is dichotomous, one of the predictors is quantitative)\nappropriate and “inappropriate” uses of ANCOVA\nwriting up the results of an ANCOVA\n\n\nStatistical power and power analysis (2 day)\n\n\ntype I and type II errors\nfactors determining statistical power\nhow to compute power\npositive predictive value\nReadings: Button et al. (2013). Cohen (1992).\n\n\nInferences about categorical predictors with three or more levels (2 days)\n\n\northogonal and non-orthogonal contrasts\ncomparing several experimental groups to one reference group (dummy codes)\ntest-wise error rate vs. family-wise error rate\nFisher LSD Protected Testing for two or three planned comparisons\nHolm-Bonferroni Adjustment for four or more planned comparisons\nScheffé Approach for unplanned comparisons\nReadings: Abelson & Prentice (1997). Guggenmos et al. (2018).",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#recommended-general-texts-for-data-analysis-and-research-methodology",
    "href": "index.html#recommended-general-texts-for-data-analysis-and-research-methodology",
    "title": "Introduction to the General Linear Model",
    "section": "Recommended General Texts For Data Analysis And Research Methodology",
    "text": "Recommended General Texts For Data Analysis And Research Methodology\n\nAbelson, R. P. (1995). Statistics as Principled Argument. Hillsdale, NJ: Lawrence Erlbaum Associates.\nAiken, L. S., & West, S. G. (1991). Multiple Regression: Testing and Interpreting Interactions. Newbury Park, CA.: Sage.\nChambers, J (2008). Software for Data Analysis: Programming with R. New York: Springer Science Business Media.\nCook, T. D., & Campbell, D. T. (1979). Quasi-Experimentation - Design and Analysis Issues for Field Settings. Boston, MA: Houghton Mifflin Company.\nCohen, J., Cohen, P., West, S. G., & Aiken,, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences (3rd. Ed.). Mahwah, NJ: Lawrence Erlbaum Associates.\nDalgaard, P. (2008) Introductory Statistics with R (2nd edition). New York: Springer Science Business Media.\nFox, J. (2015). Applied Regression, Generalized Linear Models, and Related Methods, Third Edition. Sage Publications.\nFox, J., & Weisberg, S. (2010). An R Companion to Applied Regression (3rd Edition). Sage Publications.\nHayes, A. F. (2013). Introduction to mediation, moderation, and conditional process analysis; A regression-based approach (3rd edition). NY, US: Guilford Press.\nHealy, K. (2019). Data Visualization A Practical Introduction. Princeton, NJ: Princeton University Press\nHoyle, R. H., Harris, M. J., & Judd, C. M. (2006). Research Methods in Social Relations (8th edition). Belmont, CA, US: Allyn & Bacon.\nJudd, C. M., & Kenny, D. A. (1981). Estimating the Effects of Social Interventions. New York, NY: Cambridge University Press.\nKline, R. B. (2016). Principles and practice of structural equation modeling (5th edition). New York, US: The Guilford Press\nKutner, M., Nachtscheim, C., & Neter, J (2004). Applied Linear Regression Models, Fourth edition, McGraw-Hill.\nRaudenbush, S. W., & Bryk, A. S. (2002). Hierarchical Linear Models. Applications and Data Analysis Methods (2nd ed.). Newbury Park, CA: Sage.\nReis, H. T., & Judd, C. M. (2014). Handbook of Research Methods in Social and Personality Social Psychology (2nd ed.). New York, NY: Cambridge University Press.\nSnijders, T. A. B., & Bosker, R. J. (2012). Multilevel Analysis: An Introduction to Basic and Advanced Multilevel Modeling (2nd ed.). London, UK: Sage Publishers.\nTabachnick, B. G., & Fidell, L. S. (2018). Using Multivariate Statistics (7th edition). New York, NY: Pearson.\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (2nd edition). Sebastopol, CA: O’Reilly Media",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#ethics-of-being-a-student-in-the-department-of-psychology",
    "href": "index.html#ethics-of-being-a-student-in-the-department-of-psychology",
    "title": "Introduction to the General Linear Model",
    "section": "Ethics of Being a Student in the Department of Psychology",
    "text": "Ethics of Being a Student in the Department of Psychology\nThe members of the faculty of the Department of Psychology at UW-Madison uphold the highest ethical standards of teaching and research. They expect their students to uphold the same standards of ethical conduct. By registering for this course, you are implicitly agreeing to conduct yourself with the utmost integrity throughout the semester. In the Department of Psychology, acts of academic misconduct are taken very seriously. Such acts diminish the educational experience for all involved – students who commit the acts, classmates who would never consider engaging in such behaviors, and instructors. Academic misconduct includes, but is not limited to, cheating on assignments and exams, stealing exams, sabotaging the work of classmates, submitting fraudulent data, plagiarizing the work of classmates or published and/or online sources, acquiring previously written papers and submitting them (altered or unaltered) for course assignments, collaborating with classmates when such collaboration is not authorized, and assisting fellow students in acts of misconduct. Students who have knowledge that classmates have engaged in academic misconduct should report this to the instructor.",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#academic-integrity",
    "href": "index.html#academic-integrity",
    "title": "Introduction to the General Linear Model",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nBy enrolling in this course, each student assumes the responsibilities of an active participant in UW-Madison’s community of scholars in which everyone’s academic work and behavior are held to the highest academic integrity standards. Academic misconduct compromises the integrity of the university. Cheating, fabrication, plagiarism, unauthorized collaboration, and helping others commit these acts are examples of academic misconduct, which can result in disciplinary action. This includes but is not limited to failure on the assignment/course, disciplinary probation, or suspension. Substantial or repeated cases of misconduct will be forwarded to the Office of Student Conduct & Community Standards for additional review. For more information, refer to https://conduct.students.wisc.edu/academic-misconduct/",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#chatgpt-and-other-llms",
    "href": "index.html#chatgpt-and-other-llms",
    "title": "Introduction to the General Linear Model",
    "section": "ChatGPT and other LLMs",
    "text": "ChatGPT and other LLMs\nI suspect you have all seen discussions of all that ChatGPT and other LLMs can do by now and their impact on teaching and assessment. I believe that AI like ChatGPT will eventually become an incredible tool for data scientists and programmers. As such, I view these advances with excitement. Of course, I don’t plan to assign a grade to ChatGPT so I want to make sure that we are clear on when you can and when you cannot use it.\nGiven that I expect AI like ChatGPT and other LLMs to become a useful tool in our workflow as professionals, now is the time to start to learn how they can help. Therefore, you are free to use them for coding assistance during any of our application assignments AND the application exams. Code from ChatGPT is unlikely to be sufficient in either context (and my testing suggests it can be flat out wrong in some instances!) but I suspect that it will still be useful.\nIn contrast, you cannot use ChatGPT or other LLMs/AI to answer the conceptual questions on the conceptual exams. Those questions are designed to assess your working knowledge about concepts and best practices. That information must be in YOUR head and I want to be 100% clear that use of ChatGPT/AI (or any other sources other than what is in your head) to answer those questions will be considered cheating and handled as such if detected. There will be a zero tolerance policy for such cheating and it will be considered academic misconduct and disciplined as such. ## Accommodations Policies McBurney Disability Resource Center syllabus statement: “The University of Wisconsin- Madison supports the right of all enrolled students to a full and equal educational opportunity. The Americans with Disabilities Act (ADA), Wisconsin State Statute (36.12), and UW-Madison policy (Faculty Document 1071) require that students with disabilities be reasonably accommodated in instruction and campus life. Reasonable accommodations for students with disabilities is a shared faculty and student responsibility. Students are expected to inform faculty [me] of their need for instructional accommodations by the end of the third week of the semester, or as soon as possible after a disability has been incurred or recognized. Faculty [I], will work either directly with the student [you] or in coordination with the McBurney Center to identify and provide reasonable instructional accommodations. Disability information, including instructional accommodations as part of a student’s educational record, is confidential and protected under FERPA.” http://mcburney.wisc.edu/facstaffother/faculty/syllabus.php\nUW-Madison students who have experienced sexual misconduct (which can include sexual harassment, sexual assault, dating violence and/or stalking) also have the right to request academic accommodations. This right is afforded them under Federal legislation (Title IX). Information about services and resources (including information about how to request accommodations) is available through Survivor Services, a part of University Health Services: https://www.uhs.wisc.edu/survivor-services/.",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#diversity-inclusion",
    "href": "index.html#diversity-inclusion",
    "title": "Introduction to the General Linear Model",
    "section": "Diversity & Inclusion",
    "text": "Diversity & Inclusion\nInstitutional statement on diversity: “Diversity is a source of strength, creativity, and innovation for UW-Madison. We value the contributions of each person and respect the profound ways their identity, culture, background, experience, status, abilities, and opinion enrich the university community. We commit ourselves to the pursuit of excellence in teaching, research, outreach, and diversity as inextricably linked goals.\nThe University of Wisconsin-Madison fulfills its public mission by creating a welcoming and inclusive community for people from every background – people who as students, faculty, and staff serve Wisconsin and the world.” https://diversity.wisc.edu/",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#complaints",
    "href": "index.html#complaints",
    "title": "Introduction to the General Linear Model",
    "section": "Complaints",
    "text": "Complaints\nOccasionally, a student may have a complaint about a TA or course instructor. If that happens, you should feel free to discuss the matter directly with the TA or instructor. If the complaint is about the TA and you do not feel comfortable discussing it with the individual, you should discuss it with the course instructor. Complaints about mistakes in grading should be resolved with the TA and/or instructor in the great majority of cases. If the complaint is about the instructor (other than ordinary grading questions) and you do not feel comfortable discussing it with the individual, make an appointment to speak to the Associate Chair for Graduate Studies, Professor Shawn Green, cshawn.green@wisc.edu. If you have concerns about climate or bias in this class, or if you wish to report an incident of bias or hate that has occurred in class, you may contact the Chair of the Department, Professor Allyson Bennett (allyson.j.bennett@wisc.edu) or the Chair of the Psychology Department Climate & Diversity Committee, Martha Alibali (martha.alibali@wisc.edu). You may also use the University’s bias incident reporting system, which you can reach at the following link: https://doso.students.wisc.edu/services/bias-reporting-process/.",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "index.html#concerns-about-sexual-misconduct",
    "href": "index.html#concerns-about-sexual-misconduct",
    "title": "Introduction to the General Linear Model",
    "section": "Concerns About Sexual Misconduct",
    "text": "Concerns About Sexual Misconduct\nAll students deserve to be safe and respected at UW-Madison. Unfortunately, we know that sexual and relationship violence do happen here. Free, confidential resources are available on and off campus for students impacted by sexual assault, sexual harassment, dating violence, and stalking (regardless of when the violence occurred). You don’t have to label your experience to seek help. Friends of survivors can reach out for support too. A list of resources can be found at https://www.uhs.wisc.edu/survivor-resources/ If you wish to speak to someone in the Department of Psychology about your concerns, you may contact the Chair of the Department, Professor Allyson Bennett (allyson.j.bennett@wisc.edu) or the Associate Chair of Graduate Studies, Professor Shawn Green (cshawn.green@wisc.edu). Please note that all of these individuals are Responsible Employees (https://compliance.wisc.edu/titleix/mandatory-reporting/#responsible-employees).",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "web2_slide_decks.html",
    "href": "web2_slide_decks.html",
    "title": "Slide Decks",
    "section": "",
    "text": "Unit 1: Overview\nUnit 2: Sampling Distributions, Parameters, and Parameter Estimates\nUnit 3: Inferences about a Single Mean (1 Parameter Models)\nUnit 4: Inferences about a Single Quantitative Predictor\nUnit 5: Inferences about a Single Dichotomous Predictor\nUnit 6: Inferences about two predictors\nUnit 7: Case analysis\nUnit 8: Model assumptions\nUnit 9: Transformations\nUnit 10: Interactive models with two quantitative predictors\nUnit 11: Interactive models with quantitative and dichotomous predictors\nUnit 12: Interactive models with two dichotomous predictors\nUnit 13: Categorical Predictors w/ &gt; 2 levels\nUnit 14: The Generalized Linear Model\n[Unit 15: Power Analyses and Statistical Validity(https://jjcurtin.quarto.pub/15_power/)",
    "crumbs": [
      "Slide Decks"
    ]
  },
  {
    "objectID": "web3_required_readings.html",
    "href": "web3_required_readings.html",
    "title": "Readings",
    "section": "",
    "text": "Unit 1: Overview",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "web3_required_readings.html#unit-1-overview",
    "href": "web3_required_readings.html#unit-1-overview",
    "title": "Readings",
    "section": "",
    "text": "Required\n\nJudd et a., Chapter 1, Introduction to Data Analysis\n\n\n\nSupplemental\n\nNone",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "web3_required_readings.html#unit-2-sampling-distributions",
    "href": "web3_required_readings.html#unit-2-sampling-distributions",
    "title": "Readings",
    "section": "Unit 2: Sampling Distributions",
    "text": "Unit 2: Sampling Distributions\n\nRequired\n\nJudd et al. Chapter 2, Definitions of Error and Parameter Estimates\nJudd et al. Chapter 3, Models of Error and Sampling Distributions\n\n\n\nSupplemental\n\nToothacker, L. E., & Miller, L. (1986) Sampling Distributions. In Introductory Statistics for the Behavioral Sciences.",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "web3_required_readings.html#unit-3-one-parameter-model",
    "href": "web3_required_readings.html#unit-3-one-parameter-model",
    "title": "Readings",
    "section": "Unit 3: One Parameter Model",
    "text": "Unit 3: One Parameter Model\n\nRequired\n\nJudd et al. Chapter 4. Simple Models: Statistical Inferences about Parameter Values\n\n\n\nSupplemental\n\nNone",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "web3_required_readings.html#unit-4-one-quantitative-predictor",
    "href": "web3_required_readings.html#unit-4-one-quantitative-predictor",
    "title": "Readings",
    "section": "Unit 4: One Quantitative Predictor",
    "text": "Unit 4: One Quantitative Predictor\n\nRequired\n\nJudd, C. M., McClelland, G. H., & Ryan, C. S. (2017). Chapter 5. Simple regression: Estimating models with a single continuous predictor. In Data Analysis: A Model Comparison Approach\n\n\n\nSupplemental\n\nNamboodiri, K. (1984). Matrix algebra: An introduction (Quantitative Applications in the Social Sciences). Sage Publications.",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "web3_required_readings.html#unit-5-one-dichotomous-predictor",
    "href": "web3_required_readings.html#unit-5-one-dichotomous-predictor",
    "title": "Readings",
    "section": "Unit 5: One Dichotomous Predictor",
    "text": "Unit 5: One Dichotomous Predictor\n\nRequired\n\nJudd, C. M., McClelland, G. H., & Ryan, C. S. (2017). Chapter 8. One-Way ANOVA (pp. 168-178). In Data Analysis: A Model Comparison Approach.\n\n\n\nSupplemental\n\nNone",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "web3_required_readings.html#unit-6-two-predictors",
    "href": "web3_required_readings.html#unit-6-two-predictors",
    "title": "Readings",
    "section": "Unit 6: Two Predictors",
    "text": "Unit 6: Two Predictors\n\nRequired\n\nJudd, C. M., McClelland, G. H., & Ryan, C. S. (2017). Chapter 6. Multiple regression: Models with multiple continuous predictors. In Data Analysis: A Model Comparison Approach. pp. 103-116.\n\n\n\nSupplemental\n\nFritz, C. O., Morris, P. E., & Richler, J. J. (2012). Effect size estimates: Current use, calculations, and interpretation. Journal of Exp. Psychology: General, 141, 2-18.",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "web3_required_readings.html#unit-7-case-analysis",
    "href": "web3_required_readings.html#unit-7-case-analysis",
    "title": "Readings",
    "section": "Unit 7: Case Analysis",
    "text": "Unit 7: Case Analysis\n\nRequired\n\nJudd, C. M., McClelland, G. H., & Ryan, C. S. (2017). Chapter 13. Outliers and Ill-Mannered Error. In Data Analysis: A Model Comparison Approach. pp. 314-327.\n\n\n\nSupplemental\n\nFox, J. (1991). Regression diagnostics. SAGE Series (#79): Quantitative Applications in the Social Science.\nTabachnick, B. G., & Fidel, L. S. (2018). Cleaning up your act: Screening data prior to analysis. In Using Multivariate Statistics.",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "web3_required_readings.html#unit-8-model-assumptions",
    "href": "web3_required_readings.html#unit-8-model-assumptions",
    "title": "Readings",
    "section": "Unit 8: Model Assumptions",
    "text": "Unit 8: Model Assumptions\n\nRequired\n\nJudd, C. M., McClelland, G. H., & Ryan, C. S. (2017). Chapter 13. Outliers and Ill-Mannered Error. In Data Analysis: A Model Comparison Approach. pp. 327-338.\n\n\n\nSupplemental\n\nFox, J. (1991). Regression diagnostics. SAGE Series (#79): Quantitative Applications in the Social Science.",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "web3_required_readings.html#unit-9-transformations",
    "href": "web3_required_readings.html#unit-9-transformations",
    "title": "Readings",
    "section": "Unit 9: Transformations",
    "text": "Unit 9: Transformations\n\nRequired\n\nFox, J. (2008). Transforming Data (Chapter 4).\n\n\n\nSupplemental",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "web4_application_assignments.html",
    "href": "web4_application_assignments.html",
    "title": "Application Assignments",
    "section": "",
    "text": "Week 01: Due Wednesday, 9/11 at 1:30 pm",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-01-due-wednesday-911-at-130-pm",
    "href": "web4_application_assignments.html#week-01-due-wednesday-911-at-130-pm",
    "title": "Application Assignments",
    "section": "",
    "text": "instructions\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-02-due-wednesday-0918-at-130-pm",
    "href": "web4_application_assignments.html#week-02-due-wednesday-0918-at-130-pm",
    "title": "Application Assignments",
    "section": "Week 02: Due Wednesday, 09/18 at 1:30 pm",
    "text": "Week 02: Due Wednesday, 09/18 at 1:30 pm\n\nshell\ndata\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-03-due-friday-0927-at-830-am",
    "href": "web4_application_assignments.html#week-03-due-friday-0927-at-830-am",
    "title": "Application Assignments",
    "section": "Week 03: Due Friday, 09/27 at 8:30 am",
    "text": "Week 03: Due Friday, 09/27 at 8:30 am\n\nggplot cheatsheet\nshell\ndata\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-04-due-friday-1004-at-830-am",
    "href": "web4_application_assignments.html#week-04-due-friday-1004-at-830-am",
    "title": "Application Assignments",
    "section": "Week 04: Due Friday, 10/04 at 8:30 am",
    "text": "Week 04: Due Friday, 10/04 at 8:30 am\n\nshell\ndata\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-05-no-application-assignment.-application-exam-week",
    "href": "web4_application_assignments.html#week-05-no-application-assignment.-application-exam-week",
    "title": "Application Assignments",
    "section": "Week 05: No application assignment. Application exam week!",
    "text": "Week 05: No application assignment. Application exam week!",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-06-due-friday-1018-at-830-am",
    "href": "web4_application_assignments.html#week-06-due-friday-1018-at-830-am",
    "title": "Application Assignments",
    "section": "Week 06: Due Friday, 10/18 at 8:30 am",
    "text": "Week 06: Due Friday, 10/18 at 8:30 am\n\nshell\ndata\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-07-due-friday-1025-at-830-am",
    "href": "web4_application_assignments.html#week-07-due-friday-1025-at-830-am",
    "title": "Application Assignments",
    "section": "Week 07: Due Friday, 10/25 at 8:30 am",
    "text": "Week 07: Due Friday, 10/25 at 8:30 am\n\nshell\niq data\nbrain data\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-08-due-friday-1101-at-830-am",
    "href": "web4_application_assignments.html#week-08-due-friday-1101-at-830-am",
    "title": "Application Assignments",
    "section": "Week 08: Due Friday, 11/01 at 8:30 am",
    "text": "Week 08: Due Friday, 11/01 at 8:30 am\n\nshell\ndata\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-09-due-friday-1108-at-830-am",
    "href": "web4_application_assignments.html#week-09-due-friday-1108-at-830-am",
    "title": "Application Assignments",
    "section": "Week 09: Due Friday, 11/08 at 8:30 am",
    "text": "Week 09: Due Friday, 11/08 at 8:30 am\n\nshell\ndata\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-10-no-application-assignnment.-application-exam-week",
    "href": "web4_application_assignments.html#week-10-no-application-assignnment.-application-exam-week",
    "title": "Application Assignments",
    "section": "Week 10: No application assignnment. Application exam week!",
    "text": "Week 10: No application assignnment. Application exam week!",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-11-due-friday-1122-at-830-am",
    "href": "web4_application_assignments.html#week-11-due-friday-1122-at-830-am",
    "title": "Application Assignments",
    "section": "Week 11: Due Friday, 11/22 at 8:30 am",
    "text": "Week 11: Due Friday, 11/22 at 8:30 am\n\nshell\ndata\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-12-due-friday-1129-at-830-am",
    "href": "web4_application_assignments.html#week-12-due-friday-1129-at-830-am",
    "title": "Application Assignments",
    "section": "Week 12: Due Friday 11/29 at 8:30 am",
    "text": "Week 12: Due Friday 11/29 at 8:30 am\n\nshell\ndata\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-13-no-application-assignment.-thanksgiving-break",
    "href": "web4_application_assignments.html#week-13-no-application-assignment.-thanksgiving-break",
    "title": "Application Assignments",
    "section": "Week 13: No application assignment. Thanksgiving Break",
    "text": "Week 13: No application assignment. Thanksgiving Break",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-14-due-friday-1213-at-830-am",
    "href": "web4_application_assignments.html#week-14-due-friday-1213-at-830-am",
    "title": "Application Assignments",
    "section": "Week 14: Due Friday 12/13 at 8:30 am",
    "text": "Week 14: Due Friday 12/13 at 8:30 am\n\nshell\ndata1\ndata2\nkey: html; qmd",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web4_application_assignments.html#week-15-no-application-assignment.-application-exam-week",
    "href": "web4_application_assignments.html#week-15-no-application-assignment.-application-exam-week",
    "title": "Application Assignments",
    "section": "Week 15: No application assignment. Application exam week!",
    "text": "Week 15: No application assignment. Application exam week!",
    "crumbs": [
      "Application Assignments"
    ]
  },
  {
    "objectID": "web5_labs.html",
    "href": "web5_labs.html",
    "title": "Lab Materials",
    "section": "",
    "text": "Week 1: 09/06",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-1-0906",
    "href": "web5_labs.html#week-1-0906",
    "title": "Lab Materials",
    "section": "",
    "text": "Installing R, R Studio, & Quarto\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-2-0913",
    "href": "web5_labs.html#week-2-0913",
    "title": "Lab Materials",
    "section": "Week 2: 09/13",
    "text": "Week 2: 09/13\n\nLab 02 data\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-3-0920",
    "href": "web5_labs.html#week-3-0920",
    "title": "Lab Materials",
    "section": "Week 3: 09/20",
    "text": "Week 3: 09/20\n\nLab 03 data\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-4-0927",
    "href": "web5_labs.html#week-4-0927",
    "title": "Lab Materials",
    "section": "Week 4: 09/27",
    "text": "Week 4: 09/27\n\nLab 04 quantitative data\nLab 04 dichotomous data\nStudent shell\nTA notebook: qmd; html\nVideo recording of lab",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-5-1004",
    "href": "web5_labs.html#week-5-1004",
    "title": "Lab Materials",
    "section": "Week 5: 10/04",
    "text": "Week 5: 10/04\n\nNo data file (using built-in data from R)\nStudent shell\nTA notebook: qmd; html\nVideo recording of lab",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-6-1011",
    "href": "web5_labs.html#week-6-1011",
    "title": "Lab Materials",
    "section": "Week 6: 10/11",
    "text": "Week 6: 10/11\n\ndata\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-7-1018",
    "href": "web5_labs.html#week-7-1018",
    "title": "Lab Materials",
    "section": "Week 7: 10/18",
    "text": "Week 7: 10/18\n\ndata\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-8-1025",
    "href": "web5_labs.html#week-8-1025",
    "title": "Lab Materials",
    "section": "Week 8: 10/25",
    "text": "Week 8: 10/25\n\ndata\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-9-1101",
    "href": "web5_labs.html#week-9-1101",
    "title": "Lab Materials",
    "section": "Week 9: 11/01",
    "text": "Week 9: 11/01\n\ndata\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-10-1108",
    "href": "web5_labs.html#week-10-1108",
    "title": "Lab Materials",
    "section": "Week 10: 11/08",
    "text": "Week 10: 11/08\n\ndata\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-11-1115",
    "href": "web5_labs.html#week-11-1115",
    "title": "Lab Materials",
    "section": "Week 11: 11/15",
    "text": "Week 11: 11/15\n\ndata\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-12-1122",
    "href": "web5_labs.html#week-12-1122",
    "title": "Lab Materials",
    "section": "Week 12: 11/22",
    "text": "Week 12: 11/22\n\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web5_labs.html#week-14-126",
    "href": "web5_labs.html#week-14-126",
    "title": "Lab Materials",
    "section": "Week 14: 12/6",
    "text": "Week 14: 12/6\n\ndata\nStudent shell\nTA notebook: qmd; html",
    "crumbs": [
      "Lab Materials"
    ]
  },
  {
    "objectID": "web6_exams.html",
    "href": "web6_exams.html",
    "title": "Exams",
    "section": "",
    "text": "Application Exam 1",
    "crumbs": [
      "Exams"
    ]
  },
  {
    "objectID": "web6_exams.html#application-exam-1",
    "href": "web6_exams.html#application-exam-1",
    "title": "Exams",
    "section": "",
    "text": "data\nexam shell",
    "crumbs": [
      "Exams"
    ]
  },
  {
    "objectID": "web6_exams.html#application-exam-2",
    "href": "web6_exams.html#application-exam-2",
    "title": "Exams",
    "section": "Application Exam 2",
    "text": "Application Exam 2\n\ndata\nexam shell",
    "crumbs": [
      "Exams"
    ]
  },
  {
    "objectID": "web6_exams.html#application-exam-3",
    "href": "web6_exams.html#application-exam-3",
    "title": "Exams",
    "section": "Application Exam 3",
    "text": "Application Exam 3\n\ndata1\ndata2\nexam shell",
    "crumbs": [
      "Exams"
    ]
  },
  {
    "objectID": "web6_exams.html#concepts-exam-1",
    "href": "web6_exams.html#concepts-exam-1",
    "title": "Exams",
    "section": "Concepts Exam 1",
    "text": "Concepts Exam 1",
    "crumbs": [
      "Exams"
    ]
  },
  {
    "objectID": "web6_exams.html#concepts-exam-2",
    "href": "web6_exams.html#concepts-exam-2",
    "title": "Exams",
    "section": "Concepts Exam 2",
    "text": "Concepts Exam 2",
    "crumbs": [
      "Exams"
    ]
  },
  {
    "objectID": "web7_videos.html",
    "href": "web7_videos.html",
    "title": "Video Recordings from Lab and Lecture",
    "section": "",
    "text": "Lab",
    "crumbs": [
      "Video Recordings from Lab and Lecture"
    ]
  },
  {
    "objectID": "web7_videos.html#lab",
    "href": "web7_videos.html#lab",
    "title": "Video Recordings from Lab and Lecture",
    "section": "",
    "text": "Week 4\nWeek 5\nWeek 6\nWeek 7 - part I\nWeek 7 - part II\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\nWeek 14",
    "crumbs": [
      "Video Recordings from Lab and Lecture"
    ]
  },
  {
    "objectID": "app1_exam_review.html",
    "href": "app1_exam_review.html",
    "title": "Exam Concepts",
    "section": "",
    "text": "Exam 1",
    "crumbs": [
      "Appendices",
      "Exam Concepts"
    ]
  },
  {
    "objectID": "app1_exam_review.html#exam-1",
    "href": "app1_exam_review.html#exam-1",
    "title": "Exam Concepts",
    "section": "",
    "text": "Unit 1 - Overview\n\nWhat are the four levels of the General Linear model\nHow do the number of \\(X\\) variables differ across these levels?\nNumber of \\(Y\\) variables differ across these levels?\nExamples of special case analyses across these levels?\n\n\n\nUnit 2 - Sampling Distributions\n\npopulations vs. samples\nparameters vs. parameter estimates\nWhat is sampling error?\nThe logic and procedure for null hypothesis signficance testing\nConnecting NHST to sampling distributions\nRaw score distribitions vs. sampling distributions\nThe Central Limit Theorem\nWhat is an unbiased estimator?\nWhat is the standard error for a parameter estimate and how does that connect to sampling distributions\nWhat factors affect the standard error of the mean\nHow does the one-sample z-test connect sampling distributions and standard errors.\nWhat is the difference between the one-sample z-test and the one sample t-test\n\n\n\nUnit 3 - One parameter models\n\nWhat are the three uses of models\nWhat is the equation for a one parameter model for \\(Y_i\\) and for \\(\\hat{Y}_i\\)\nWhat is an error or residual in the context of a model. Define it in terms of \\(Y_i\\) and \\(\\hat{Y}_i\\)\nWhat are two reasonable methods for estimating total model error\nWhat are three important properties of parameter estimates? Define each\nWhy do we prefer the sum of squared errors over the sum of absolute errors?\nWhat is the interpretation of \\(b_0\\) if we estimate it by minimizing the sum of squared errors vs. the sum of absolute errors?\nParameter estimates in our models miminize what?\nHow do we use a t-test the null hypothesis that \\(b_0\\) is zero in a one parameter model? Connect this to the sampling distribution of \\(b_0\\)\nHow do we use an F-test and model comparison to test the null hypothesis that \\(b_0\\) is zero in a one parameter model? How do we use sum of squared errors in this comparison? What is the compact and augmented model used to test the null about \\(b_0\\) = 0. How would you change these models if you had a null hypothesis about some value other than 0?\nWhat is a confidence interval for a parameter estimate? Connect the confidence interval to the standard error of that parameter estimate\nHow can we use a confidence interval to test the null hypothesis that \\(b_0\\) (or any parameter estimate) is zero?\nThe test of \\(b_0\\) in a one parameter model is equivalent to what special case analysis?\nWhat is the formula for the t-test to test the null hypothesis that \\(b_0\\) (or any parameter estimate) is zero? How would you modify this formula to test a null hypothesis about a value other than 0.\n\n\n\nUnit 4 - Two parameter models\n\nWhat is the equation for a two parameter model for \\(Y_i\\) and for \\(\\hat{Y}_i\\)\nWhat is the interpretation of \\(b_0\\) and \\(b_1\\) in a two parameter model?\nIdentify \\(b_0\\) and \\(b_1\\) on a line plot of the data\nHow are \\(b_0\\) and \\(b_1\\) estimated in a two parameter model?\nCompare the interpretation of \\(b_0\\) in a one vs. two parameter model\nHow do we test null hypotheses about \\(b_0\\) and \\(b_1\\) in a two parameter model using a t-test? Connect this to the sampling distribution of \\(b_0\\) and \\(b_1\\)A\nHow do we test null hypotheses about \\(b_0\\) and \\(b_1\\) in a two parameter model using an F-test and model comparison? What are the associated compact and augmented models for each test?\nWhat are the degrees of freedom equal to for the t-test and F-test\nWhat would the SSE be for two parameter model that perfectly predicts \\(Y\\). What would it be if there was no relationship between \\(X\\) and \\(Y\\)?\nWhat is the impact of mean-centering \\(X\\) on the interpretation of \\(b_0\\) and \\(b_1\\) in a two parameter model?\nWhat is the formula for the confidence interval for a parameter estimate in a two parameter model? Connect the confidence interval to the standard error of that parameter estimate\nWhat is \\(R^2\\) and how is it calculated in a two parameter model using SSE or using variances of \\(Y_i\\), \\(\\hat{Y}_i\\), and \\(e_i\\)?\nWhat this the relationship between \\(R^2\\) and \\(r_xy\\) in the two parameter model?\n\n\n\nUnit 5 - One Dichotomous Predictor\n\nHow do we handle dichotomous categorical variables in linear models?\nWhat are the two coding schemes we learned for coding regressors (\\(X\\)s) for dichtomous categorical predictors\nHow do we interpret the parameter estimates for each coding scheme?\nHow would values or interpretations of \\(b_0\\) and \\(b_1\\) change if we used other coding schemes (e.g., -1 vs. 1, 2 vs. 0)?\nWhat are the typical consequences of dichotomizing a quantitative predictor? Should we generally do this or avoid it?\nHow does the t-test or model comparison approach work for testing parameter estimates in a model with a dichotomous predictor?\nIdentify \\(b_0\\) and \\(b_1\\) on a line plot of the data\n\n\n\nUnit 6 - Models with Two or More Predictors\n\nWhat is the equation for a model with two predictors for \\(Y_i\\) and for \\(\\hat{Y}_i\\)? What is the general form for \\(k\\) predictors?\nWhat is the interpretation of \\(b_0\\), \\(b_1\\), and \\(b_2\\) in a model with two predictors?\nWhat are the five benefits of using multiple predictors in a model?\nWhat factors affect the standard error of a parameter estimate in a model with multiple predictors? (You do not need to know the exact formula for this but you do need to know all the components and the direction of their impact on the SE)\nWhat is \\(R^2_j\\)?\nWhat is the problem of multicolinearity?\nHow do you identify if multicolinarity is a problem in a model?\nWhat are the appropriate compact and augmented models for testing any parameter estimate in a model with multiple predictors?\nWhat is the relationship between the SE for a parameter estimate and power to test the null hypothesis about that parameter estimate? Connect this to your understanding of the sampling distribution for a parameter estimate\nWhat is the relationship between the SE for a parameter estimate and the precision of the parameter estimate? Connect this to your understanding of the confidence interval and the sampling distribution for a parameter estimate.\nWhat are the total, direct, and indirect/spurious effects of \\(X\\)s in a two predictor model? How do you calculate each? What models do you use to calculate each?\nWhat are the three variance based effect size estimates for models with two or more predictors?\n\nDefine them in terms of the variances of \\(Y_i\\), \\(\\hat{Y}_i\\), and \\(e_i\\)\nDefine them in terms of sums of squares and models/model comparisons\nWhat is the interpreation of each?\nLink them to the areas of the Venn diagrams\nCalculate them from sums of squares in Venn diagrams\nHow are they similar and different from each other?\nWhen are each generally used?\n\nIdentify \\(b_0\\), \\(b_1\\), and \\(b_2\\) on a line plot of the data from a two predictor model with a dichotomous and quantitative predictor",
    "crumbs": [
      "Appendices",
      "Exam Concepts"
    ]
  },
  {
    "objectID": "app1_exam_review.html#exam-2",
    "href": "app1_exam_review.html#exam-2",
    "title": "Exam Concepts",
    "section": "Exam 2",
    "text": "Exam 2\n\nUnit 7 - Case Analysis\n\nWhat is case analysis and why do we do it?\nWhat are the three primary characteristics of observations that we focus on in case analysis?\nWhen doing univariate and bivariate exploratory data analysis, what plots and summary statistics do we typically review; Which plots are good for which types of variables?\nLeverage\n\nWhat is it\nWhat metric do we use to identify points with high leverage\nWhat is the impact of leverage on our models?\n\nRegression Outliers\n\nWhat are they?\nWhat three metrics do we use to identify regression outliers and which one do we prefer?\nWhat are the two potential impacts of regression outliers on our models?\n\nInfluential Observartions\n\nWhat are they?\nWhat metrics do we use to identify influential observations and how are they different from each other?\nWhat is an added variable plot? What do we plot on the x and y axes this plot?\nWhat are the two potential impacts of influential observations on our models?\n\nIdentify points with high leverage, regression outliers, and influential points on a scatterplot?\nWhat is the Covratio?\nWhat are three options for how to handle regression outliers and influential points?\n\n\n\nUnit 8 - Model Assumptions\n\nWhat are the five assumptions of the general linear model?\nWhat are the consequences of violating each assumption?\nWhat are the implications of the unreliable X assumption for the use of covariates?\nWhat is a quantile-quantile (quantile comparison) plot and what do we use it for?\nWhat is a spread-location plot and what do we use it for?\nWhat options exist to address problems with non-constant (heterogeneity) variance of residuals?\nWhat is a Component + Residual plot and what do we use it for? What do we plot on the x and y axes of this plot?\n\n\n\nUnit 9 - Transformations\n\nWhat are power transformations and why do we use them?\nWhat are the benefits of the Box-Cox transformation vs. a simple power transformation?\nWhat happens to scores as we ascend and descend the ladder of power transformations?\nWhat is a start and when do we need to use one (two uses)?\nHow can we use power transformations to address skewed residuals?\nHow can we use power transformations to address non-constant variance of residuals?\nIs it more common to transform y or x to adddress skew and non-constant variance problems? What about linearity problems (when y and when)\nWhat type of lineary problems can power transformations address and what types can it not fix?\nWhat is the Mosteller and Tukey’s bulging rule? What transformations do we use for linearity issues in each quadrant?\n\n\n\nUnit 10-12 - Interactions\n\nWhat is an interaction?\nHow do you create a regressor to test for an interaction between predictors?\nHow do you interpret the parameter estimates for a model with an interaction between two predictors? How does this change if the predictors are both quant, both dichotomous, or one of each?\nWhich parameter estimates will change (and which won’t) as you change the scaling of \\(X\\)s in a model with an interaction.\nHow can you use the model formula (with parameter estimates) to describe how the magnitude of the effect of one X will change depending on a second X? Again, know how to do this for models with two quant predictors, two dichotomous predictors, and one of each.\nCalculate how any parameter estimate in a model will change if a specific \\(X\\) was re-scaled in some way (e.g., mean centered or centered on some other value). Know this for both quant predictors and dichotomous predictors.\nWhen do you mean center a quant \\(X\\) in an interactive model When do you center on some value other than the mean\nWhen do you use centered (contrast) codes vs. dummy codes for a dichotomous \\(X\\) in an interactive model?\nLink parameter estimates from an interactive model to a plot of the model. Know how to do this for models with two quant predictors, two dichotomous predictors, and one of each.\nWhat are main an simple effects in a model with an interaction? How do you obtain them? How do you interpret them? How is this different for models with two quant predictors, two dichotomous predictors, and one of each?\nHow do you test for an interaction using a t-test or model comparison? How do you test for main and simple effects in these models?\nwhat is a cell mean, marginal mean, and grand mean in a model with two dichotomous predictors?\nLink the parameter estimates from an interactive model with two dichotomous predictors to table of means. Be able to go both directions such that you could write out the model formula (including parameter estimates) for a model from a table of means either when using centered (contrast) codes or dummy codes.\nQuantify the magnitude of main effects, simple effects and an interaction between two dichotomous predictors using a table of means.\n\n\n\nUnit 13 - Categorical Predictors with More than Two Levels\n\nWhy can we not simple assign sequential numbers to levels of a categorical predictor?\nHow do you calculate dummy coded regressors for categorical variables with 3 or more levels (including what codes are assigned to each regressor)?\nHow do you interpret the parameter estimates for dummy coded regressors?\nHow do you calculate contrast coded regressors for categorical variables with 3 or more levels (including what codes are assigned to each regressor)? Know how to do this for 3 and 4 level categorical variables given a description of the planned contrasts.\nHow do you interpret the parameter estimates for contrast coded regressors?\nBe able to calculate predicted means for any level given a model formula that used either dummy or contrast codes\nWhy are pairwise contrasts using dummy coded regressors in a linear model superior to pairwise t-tests using between subjects/two group t-tests?\nHow can you get the test of the third pairwise contrast when using dummy coded regressors for a 3 level categorical predictor?\nWhat is the value of testing for a main effect of a categorical variable? When will you do this?\nWhat model comparison will provide a test of the main effect of a categorical predictor when other predictors are also in the model\nWhen will \\(\\Delta R^2\\) sum to the full \\(R^2\\) for a model with a categorical predictor? When will they not?\nWhat is test-wise and family-wise error rates?\n\nWhen and how do we protect against inflation of family-wise Type I error rates when doing multiple comparisons among levels of a categorical predictor? How is this similar or different when using planned orthogonal contrasts vs. planned pairwise conntrasts vs. unplanned contrasts?\nHow and when should we use Fisher LSD approach\nHow and when should we use Holm-Bonferroni approach\nHow is the Holm-Bonferroni approach superior to the Bonferroni approach?\nHow and when should we use Scheffe test approach\nWhat is the Bonferroni inequality\n\n\n\nUnit 14 - The Generalized Linear Model\n\nWhen might you use the generalized linear model?\n\nWhen would you specifically use a generalized linear model with the logit link function and binomial distribution? What special case analysis is this?\nWhen would you use a generalized linear model with the log link function and poisson distribution?\n\n\nBe able to calculate odds or probability from the other. Be able to calculate log-odds from a model.\nWhat is an odds ratio and how do you interpret it for a quantitative predictor or regressor for a categorical predictor?\nWhat do we use the odds ratio as the preferred effect size in logistic regression?\nBe able to compare two simple (one X) logistic plots (in probability units) and tell which has bigger/smaller \\(b_0\\) and \\(b_1\\)\nWhat are the three approaches to testing parameter estimates in logistic regression? Which is preferred and why?\nHow do we handle categorical predictors and multiple predictors in logistic regression?\n\n\n\nUnit 15 - Power Analysis and Statistical Validity\n\nUnderstand the confusion matrix and its use with talking about statistical validity. Be able to label the four cells of the confusion matrix.\nWhat the difference between Type I and Type II errors?\nWhat are the factors that affect power in the linear model? How do they affect power? Be able to discuss these relationships with respect to the sampling distribution for a parameter estimate\nWhat are the two approaches to power analyses. When and why do you do each of them\nWhat problems are associated with low power studies?\nWhat is positive predictive value and why does it matter?\nWhy are sample effect size estimates often incorrect (too large) when calculated in studies with low power\nWhat is the problem of vibration of effects?\nWhat is publication bias and why is it worse for low power studies?\nWhat are the 7 important study characteristics that should be pre-registered?",
    "crumbs": [
      "Appendices",
      "Exam Concepts"
    ]
  },
  {
    "objectID": "app3_contrasts.html",
    "href": "app3_contrasts.html",
    "title": "Monte Carlo Simulation of Contrast Approaches",
    "section": "",
    "text": "3 Groups with No Group Differences (Type I Errors)\nSet up simulation characteristics for Null Findings.\nThis will allow us to determine Type I error rates because any signficant effect is a type I error given we have set the population effect to 0\n\n\nCode\n# simulate N experiments\nn_experiments &lt;- 20000\n\n# group means\nm_1 &lt;- 10\nm_2 &lt;- 10\nm_3 &lt;- 10\n\nsd &lt;- 20 # sd for y\nn &lt;- 50 # group size\n\n# set up x as factor\nx &lt;-  factor(c(rep(\"a\", n), rep(\"b\", n), rep(\"c\", n)))  \n\nset.seed(1234567)\n\n\n\n1. POCs - all focal (separate research questions)\n\n\nCode\nsimulate_poc &lt;- function(i) {\n  # vector of y for three groups\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  \n contrasts(x)&lt;- matrix(c(2, -1, -1,\n                         0,  1, -1), \n                       ncol = 2,\n                       dimnames = list(levels(x),\n                                       c(\"a_v_bc\", \"b_v_c\")))\n\n  # fit model\n  results &lt;- lm(y ~ x) |&gt; \n    tidy()\n  \n  # extract and organize key results\n  tibble(sim = i,\n         sig_c1 = results$p.value[2] &lt; 0.05,\n         sig_c2 = results$p.value[3] &lt; 0.05,\n         sig_any = any(results$p.value[2:3] &lt; 0.05))\n}\n\ntype1_poc &lt;- map(1:n_experiments, simulate_poc) |&gt; \n  list_rbind()\n\n\nResults (to make clear what function returns)\n\n\nCode\ntype1_poc |&gt; head()\n\n\n# A tibble: 6 × 4\n    sim sig_c1 sig_c2 sig_any\n  &lt;int&gt; &lt;lgl&gt;  &lt;lgl&gt;  &lt;lgl&gt;  \n1     1 FALSE  FALSE  FALSE  \n2     2 FALSE  FALSE  FALSE  \n3     3 TRUE   FALSE  TRUE   \n4     4 FALSE  FALSE  FALSE  \n5     5 FALSE  FALSE  FALSE  \n6     6 FALSE  FALSE  FALSE  \n\n\nTest wise type I error for each contrast is 5%\n\n\nCode\nmean(type1_poc$sig_c1)\n\n\n[1] 0.0491\n\n\nCode\nmean(type1_poc$sig_c2)\n\n\n[1] 0.0545\n\n\nThe results across contrasts are independent because they come from different families\n\n\nCode\ncor(type1_poc$sig_c1, type1_poc$sig_c2) |&gt; round(2)\n\n\n[1] 0.01\n\n\nTo be clear, the family-wise type I error across the set is 10% BUT often not considered in same family so not important?\n\n\nCode\nmean(type1_poc$sig_any)\n\n\n[1] 0.1002\n\n\n\n2. Dummy contrasts from one model (3 levels; no protection).\n\n\nCode\nsimulate_dummy &lt;- function(i) {\n  # vector of y for three groups\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  \n  # fit first model\n  contrasts(x) &lt;- contr.treatment(levels(x), base = 3) \n  results &lt;- lm(y ~ x) |&gt; \n    tidy()\n \n  # extract and organize key results \n  tibble(sim = i,\n         sig_d1 = results$p.value[2] &lt; 0.05,\n         sig_d2 = results$p.value[3] &lt; 0.05,\n         sig_any = any(c(results$p.value[2:3]) &lt; 0.05))\n}\n\ntype1_dummy &lt;- map(1:n_experiments, simulate_dummy) |&gt; \n  list_rbind()\n\n\nTest-wise Type I for each contrast is 5%\n\n\nCode\nmean(type1_dummy$sig_d1)\n\n\n[1] 0.0508\n\n\nCode\nmean(type1_dummy$sig_d2)\n\n\n[1] 0.051\n\n\nBut these are from same family (results of contrasts are related)\n\n\nCode\ncor(type1_dummy$sig_d1, type1_dummy$sig_d2) |&gt; round(2)\n\n\n[1] 0.15\n\n\nTherefore, family-wise error rate is higher (but not 10% because contrasts are dependent/related)\n\n\nCode\nmean(type1_dummy$sig_any)\n\n\n[1] 0.0919\n\n\n\n3. All (3) pairwise contrasts (no protection).\n\n\nCode\nsimulate_pair &lt;- function(i) {\n  # vector of y for three groups\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  \n  # fit first model\n  contrasts(x) &lt;- contr.treatment(levels(x), base = 3) \n  results_3 &lt;- lm(y ~ x) |&gt; \n    tidy()\n \n  # fit second model \n  contrasts(x) &lt;- contr.treatment(levels(x), base = 1) \n  results_1 &lt;- lm(y ~ x) |&gt; \n    tidy()\n \n  # extract and organize key results \n  tibble(sim = i,\n         sig_d1 = results_3$p.value[2] &lt; 0.05,\n         sig_d2 = results_3$p.value[3] &lt; 0.05,\n         sig_d3 = results_1$p.value[2] &lt; 0.05,\n         sig_any = any(c(results_3$p.value[2:3], results_1$p.value[2]) &lt; 0.05))\n}\n\ntype1_pair &lt;- map(1:n_experiments, simulate_pair) |&gt; \n  list_rbind()\n\n\nTest-wise Type I for each contrast is 5%\n\n\nCode\nmean(type1_pair$sig_d1)\n\n\n[1] 0.0501\n\n\nCode\nmean(type1_pair$sig_d2)\n\n\n[1] 0.0498\n\n\nCode\nmean(type1_pair$sig_d3)\n\n\n[1] 0.0497\n\n\nBut these are from same family (results of contrasts are related)\n\n\nCode\ncor(type1_pair$sig_d1, type1_pair$sig_d2) |&gt; round(2)\n\n\n[1] 0.14\n\n\nCode\ncor(type1_pair$sig_d1, type1_pair$sig_d3) |&gt; round(2)\n\n\n[1] 0.14\n\n\nCode\ncor(type1_pair$sig_d2, type1_pair$sig_d3) |&gt; round(2)\n\n\n[1] 0.12\n\n\nFamily-wise error rate is higher (but not 15% because contrasts are dependent/related)\n\n\nCode\nmean(type1_pair$sig_any)\n\n\n[1] 0.12315\n\n\n\n4. Fisher LSD with 3 pairwise comparisons\n\n\nCode\nsimulate_fisher &lt;- function(i) {\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  contrasts(x) &lt;- contr.treatment(levels(x), base = 3) \n  results_3 &lt;- lm(y ~ x) |&gt; \n    tidy()\n  \n  contrasts(x) &lt;- contr.treatment(levels(x), base = 1) \n  results_1 &lt;- lm(y ~ x) |&gt; \n    tidy()\n  \n  sig_omnibus &lt;- anova(lm(y ~ x))$`Pr(&gt;F)`[1] &lt; 0.05\n  \n  # extract and organize key results \n  tibble(sim = i,\n         sig_d1 = sig_omnibus && results_3$p.value[2] &lt; 0.05,\n         sig_d2 = sig_omnibus && results_3$p.value[3] &lt; 0.05,\n         sig_d3 = sig_omnibus && results_1$p.value[2] &lt; 0.05,\n         sig_any = sig_omnibus && any(c(results_3$p.value[2:3], results_1$p.value[2]) &lt; 0.05))\n}\n\ntype1_fish &lt;- map(1:n_experiments, simulate_fisher) |&gt; \n  list_rbind()\n\n\nTest-wise Type I for each contrast is &lt; 5% (too conservative!)\n\n\nCode\nmean(type1_fish$sig_d1)\n\n\n[1] 0.02485\n\n\nCode\nmean(type1_fish$sig_d2)\n\n\n[1] 0.02475\n\n\nCode\nmean(type1_fish$sig_d3)\n\n\n[1] 0.02555\n\n\nThese are from same family (results of contrasts are even more related)\n\n\nCode\ncor(type1_fish$sig_d1, type1_fish$sig_d2) |&gt; round(2)\n\n\n[1] 0.3\n\n\nCode\ncor(type1_fish$sig_d1, type1_fish$sig_d3) |&gt; round(2)\n\n\n[1] 0.31\n\n\nCode\ncor(type1_fish$sig_d2, type1_fish$sig_d3) |&gt; round(2)\n\n\n[1] 0.3\n\n\nFamily-wise error rate is controlled at 5%\n\n\nCode\nmean(type1_fish$sig_any)\n\n\n[1] 0.0509\n\n\n\n5. Holm-Bonferroni correction with 3 pairwise comparisons\n\n\nCode\nsimulate_hb &lt;- function(i) {\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  contrasts(x) &lt;- contr.treatment(levels(x), base = 3) \n  results_3 &lt;- lm(y ~ x) |&gt; \n    tidy()\n  \n  contrasts(x) &lt;- contr.treatment(levels(x), base = 1) \n  results_1 &lt;- lm(y ~ x) |&gt; \n    tidy()\n  \n  p_contrasts &lt;- p.adjust(c(results_3$p.value[2:3], results_1$p.value[2]), method = \"holm\")\n    \n  tibble(sim = i,\n         sig_d1 = p_contrasts[1] &lt; 0.05,\n         sig_d2 = p_contrasts[2] &lt; 0.05,\n         sig_d3 = p_contrasts[3] &lt; 0.05,\n         sig_any = any(p_contrasts &lt; 0.05))\n}\n\ntype1_hb &lt;- map(1:n_experiments, simulate_hb) |&gt; \n  list_rbind()\n\n\nTest-wise Type I is well under 5% (too conservative!)\n\n\nCode\nmean(type1_hb$sig_d1)\n\n\n[1] 0.01865\n\n\nCode\nmean(type1_hb$sig_d2)\n\n\n[1] 0.01765\n\n\nCode\nmean(type1_hb$sig_d3)\n\n\n[1] 0.01845\n\n\nThese are from same family (results of contrasts are related)\n\n\nCode\ncor(type1_hb$sig_d1, type1_hb$sig_d2) |&gt; round(2)\n\n\n[1] 0.19\n\n\nCode\ncor(type1_hb$sig_d1, type1_hb$sig_d3) |&gt; round(2)\n\n\n[1] 0.18\n\n\nCode\ncor(type1_hb$sig_d2, type1_hb$sig_d3) |&gt; round(2)\n\n\n[1] 0.2\n\n\nFamily-wise error rate is controlled at 5%\n\n\nCode\nmean(type1_hb$sig_any)\n\n\n[1] 0.04365\n\n\n\n\n\n3 Groups with One Group Difference (Type II Errors)\nNow lets consider Type II errors. This is too often neglected in these discussions. However it is also complicated because there are LOTS of different ways that the population effects could be set up and its not necessarily true that the same method would be more powerful across these settings. You should consider these simulations as only a start to comparing the power of these methods.\nHere we update the pattern of means such that one group is different from the other two but the other two group means are equal\n\n\nCode\nm_1 &lt;- 10\nm_2 &lt;- 10\nm_3 &lt;- 20\n\n\n\n1. Dummy contrasts from one model (3 levels; no protection).\nThis pattern of means is well-suited to using dummy codes with the third group as reference.\nThat said, if we only tested these two contrasts, we couldnt conclude anything about differences between groups 1 and 2.\n\n\nCode\nsimulate_dummy_2 &lt;- function(i) {\n  # vector of y for three groups\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  \n  # fit first model\n  contrasts(x) &lt;- contr.treatment(levels(x), base = 3) \n  results &lt;- lm(y ~ x) |&gt; \n    tidy()\n \n  # extract and organize key results \n  tibble(sim = i,\n         sig_d1 = results$p.value[2] &lt; 0.05,\n         sig_d2 = results$p.value[3] &lt; 0.05,\n         sig_both = all(c(results$p.value[2:3]) &lt; 0.05))\n}\n\ntype2_dummy &lt;- map(1:n_experiments, simulate_dummy_2) |&gt; \n  list_rbind()\n\n\nHere is power for the two contrasts that should be significant and for finding both significant.\nPower is low (70%) for the individual tests but what we would expect given the effect size and sample size. What we care about is relative power across the approaches.\nBut again, we should also note that this method doesnt inform us about differences between group 1 and 2\n\n\nCode\nmean(type2_dummy$sig_d1)\n\n\n[1] 0.70465\n\n\nCode\nmean(type2_dummy$sig_d2)\n\n\n[1] 0.7037\n\n\nCode\nmean(type2_dummy$sig_both)\n\n\n[1] 0.56145\n\n\n2. Fisher LSD with 3 pairwise comparisons\nIf we wanted all three contrasts, we could use Fisher LSD.\n\n\nCode\nsimulate_fish_2 &lt;- function(i) {\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  contrasts(x) &lt;- contr.treatment(levels(x), base = 3) \n  \n  results_3 &lt;- lm(y ~ x) |&gt; \n    tidy()\n  \n  sig_omnibus &lt;- anova(lm(y ~ x))$`Pr(&gt;F)`[1] &lt; 0.05\n\n  tibble(sim = i,\n         sig_d1 = sig_omnibus && results_3$p.value[2] &lt; 0.05,\n         sig_d2 = sig_omnibus && results_3$p.value[3] &lt; 0.05,\n         sig_both = sig_omnibus && all(c(results_3$p.value[2:3]) &lt; 0.05))\n}\n\ntype2_fish &lt;- map(1:n_experiments, simulate_fish_2) |&gt; \n  list_rbind()\n\n\nPower is lower for the two individual contrasts (63-64%) but we get the third contrasts to show that G1 and G2 are not difference (with 5% false alarm rate).\n\n\nCode\nmean(type2_fish$sig_d1)\n\n\n[1] 0.6385\n\n\nCode\nmean(type2_fish$sig_d2)\n\n\n[1] 0.6322\n\n\nCode\nmean(type2_fish$sig_both)\n\n\n[1] 0.5464\n\n\n\n2. Holm-Bonferroni correction with 3 pairwise comparisons\n\n\nCode\nsimulate_hb_2 &lt;- function(i) {\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  contrasts(x) &lt;- contr.treatment(levels(x), base = 3) \n  results_3 &lt;- lm(y ~ x) |&gt; \n    tidy()\n  \n  contrasts(x) &lt;- contr.treatment(levels(x), base = 1) \n  results_1 &lt;- lm(y ~ x) |&gt; \n    tidy()\n\n  p_contrasts &lt;- p.adjust(c(results_3$p.value[2:3], results_1$p.value[2]), method = \"holm\")\n    \n  tibble(sim = i,\n         sig_d1 = p_contrasts[1] &lt; 0.05,\n         sig_d2 = p_contrasts[2] &lt; 0.05,\n         sig_both = all(p_contrasts[1:2] &lt; 0.05))\n} \n\ntype2_hb &lt;- map(1:n_experiments, simulate_hb_2) |&gt; \n  list_rbind()\n\n\nHB is worse still on power for the individual contrasts (55-56%)\n\n\nCode\nmean(type2_hb$sig_d1)\n\n\n[1] 0.56085\n\n\nCode\nmean(type2_hb$sig_d2)\n\n\n[1] 0.5684\n\n\nCode\nmean(type2_hb$sig_both)\n\n\n[1] 0.4326\n\n\n\n4. POCs - Assuming we were right about the pattern of means\nPOCs don’t fit perfectly to this setting. However, if in this instance our theory predicts only group three different from groups 1 and 2, we could test only that contrast or we might test the second contrast to demonstrate it was NOT significant.\n\n\nCode\nsimulate_poc_2 &lt;- function(i) {\n  # vector of y for three groups\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  \n contrasts(x)&lt;- matrix(c(-1, -1, 2,\n                          1, -1, 0), \n                       ncol = 2,\n                       dimnames = list(levels(x),\n                                       c(\"a_v_bc\", \"b_v_c\")))\n\n  # fit model\n  results &lt;- lm(y ~ x) |&gt; \n    tidy()\n  \n  # extract and organize key results\n  tibble(sim = i,\n         sig_c1 = results$p.value[2] &lt; 0.05)\n}\n\ntype2_poc &lt;- map(1:n_experiments, simulate_poc_2) |&gt; \n  list_rbind()\n\n\nHere we only care about the power for the first effect. Clearly, the best power (~81%) if this is sufficient. We would likely want the second contrast to be non-significant to demonstrate that the effect is specific to group 3. This would false alarm at 5%.\n\n\nCode\nmean(type2_poc$sig_c1)\n\n\n[1] 0.81675\n\n\n\n\n\n3 Groups with All Groups Different (Type II Errors)\n\n\nCode\nm_1 &lt;- 10\nm_2 &lt;- 20\nm_3 &lt;- 30\n\n\n1. Dummy contrasts from one model (3 levels; no protection).\nThis approach doesn’t make sense because we want to test all three contrasts (assuming our theory correctly predicted all groups different)\n2. Fisher LSD with 3 pairwise comparisons\nIf we wanted all three contrasts, we could use Fisher LSD.\n\n\nCode\nsimulate_fish_3 &lt;- function(i) {\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  \n  contrasts(x) &lt;- contr.treatment(levels(x), base = 3) \n  results_3 &lt;- lm(y ~ x) |&gt; \n    tidy()\n\n  contrasts(x) &lt;- contr.treatment(levels(x), base = 1) \n  results_1 &lt;- lm(y ~ x) |&gt; \n    tidy()\n  \n  sig_omnibus &lt;- anova(lm(y ~ x))$`Pr(&gt;F)`[1] &lt; 0.05\n  \n  tibble(sim = i,\n         sig_d1 = sig_omnibus && results_3$p.value[2] &lt; 0.05,\n         sig_d2 = sig_omnibus && results_3$p.value[3] &lt; 0.05,\n         sig_d3 = sig_omnibus && results_1$p.value[2] &lt; 0.05,\n         sig_all = sig_omnibus && all(c(results_3$p.value[2:3], results_1$p.value[2]) &lt; 0.05))\n}\n\ntype2_fish_3 &lt;- map(1:n_experiments, simulate_fish_3) |&gt; \n  list_rbind()\n\n\nPower is much better for G1 vs G3 (~99%) because its a bigger mean difference than for the other two (w/ ~ 70% power). But again, its about relative power now. We need to compare to other methods.\n\n\nCode\nmean(type2_fish_3$sig_d1)\n\n\n[1] 0.99605\n\n\nCode\nmean(type2_fish_3$sig_d2)\n\n\n[1] 0.69935\n\n\nCode\nmean(type2_fish_3$sig_d3)\n\n\n[1] 0.69805\n\n\nCode\nmean(type2_fish_3$sig_all)\n\n\n[1] 0.4333\n\n\n\n2. Holm-Bonferroni correction with 3 pairwise comparisons\n\n\nCode\nsimulate_hb_3 &lt;- function(i) {\n  y &lt;- c(rnorm(n, m_1, sd), rnorm(n, m_2, sd), rnorm(n, m_3, sd))\n  contrasts(x) &lt;- contr.treatment(levels(x), base = 3) \n  results_3 &lt;- lm(y ~ x) |&gt; \n    tidy()\n  \n  contrasts(x) &lt;- contr.treatment(levels(x), base = 1) \n  results_1 &lt;- lm(y ~ x) |&gt; \n    tidy()\n\n  p_contrasts &lt;- p.adjust(c(results_3$p.value[2:3], results_1$p.value[2]), method = \"holm\")\n    \n  tibble(sim = i,\n         sig_d1 = p_contrasts[1] &lt; 0.05,\n         sig_d2 = p_contrasts[2] &lt; 0.05,\n         sig_d3 = p_contrasts[3] &lt; 0.05,\n         sig_all = all(p_contrasts[1:3] &lt; 0.05))\n} \n\ntype2_hb_3 &lt;- map(1:n_experiments, simulate_hb_3) |&gt; \n  list_rbind()\n\n\nHB is a bit worse power for the the smaller individual contrasts (66-67%)\n\n\nCode\nmean(type2_hb_3$sig_d1)\n\n\n[1] 0.99555\n\n\nCode\nmean(type2_hb_3$sig_d2)\n\n\n[1] 0.6619\n\n\nCode\nmean(type2_hb_3$sig_d3)\n\n\n[1] 0.66925\n\n\nCode\nmean(type2_hb_3$sig_all)\n\n\n[1] 0.4247\n\n\n\n4. POCs - Assuming we were right about the pattern of means\nAgain, not clear exactly how to use POCs in this setting if we expect all groups to be different\n\n\nWhat about with 4 levels?\nHavent done this year but we will see that Type 1 control falls apart for all pairwise with fisher LSD because there are two many pairwise contrasts. Without, that most wouldnt tolerate it. HB will still handle 4 levels with go type 1 control. Power will be lower still though because there will be bigger adjustments to all p-values. POCs can really shine here but ONLY if the pattern of means works. Otherwise, HB is the best bet.",
    "crumbs": [
      "Appendices",
      "Monte Carlo Simulation of Contrast Approaches"
    ]
  },
  {
    "objectID": "app4_logistic_se.html",
    "href": "app4_logistic_se.html",
    "title": "1  Exploring SEs for Logistic Regression",
    "section": "",
    "text": "1.1 Setup\nCode\n# packages\noptions(conflicts.policy = \"depends.ok\")\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(furrr)\n\n\nLoading required package: future\n\n\nCode\n# source  \ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\", \n                     sha1 = \"a58e57da996d1b70bb9a5b58241325d6fd78890f\")\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/my_skim.R?raw=true\",\n                     sha1 = \"839a13530805f9d28f407483a18b7e3368389fe7\")\n\n\n# options\ntheme_set(theme_classic())",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploring SEs for Logistic Regression</span>"
    ]
  },
  {
    "objectID": "app4_logistic_se.html#functions",
    "href": "app4_logistic_se.html#functions",
    "title": "1  Exploring SEs for Logistic Regression",
    "section": "1.2 Functions",
    "text": "1.2 Functions\n\n\nCode\nmake_data &lt;- function(n, b0, b1){\n  x &lt;- runif(n, -10, 10) \n  z &lt;- b0 + b1 * x\n  p &lt;- 1 / (1 + exp(-z))\n  y &lt;- rbinom(n, 1, p)\n  tibble(y = y, x = x)  \n}\n\n\n\n\nCode\nget_preds &lt;- function(sim, n, b0, b1){\n  d &lt;- make_data(n, b0, b1)\n  m &lt;- glm(y ~ x, data = d, family = binomial) \n  preds &lt;- tibble(x = c(-8, -3, 0, 3, 8))\n  preds &lt;- preds |&gt; \n    bind_cols(predict(m, newdata = preds,\n                      type = \"link\",\n                      se.fit = TRUE)) |&gt; \n    select(x, se_lo = se.fit, fit_lo = fit)\n  preds |&gt; \n    bind_cols(predict(m, newdata = preds, \n                      type = \"response\",\n                      se.fit = TRUE),\n           sim = sim) |&gt;\n    select(sim, x, fit_lo, fit_pr = fit, se_lo, se_pr = se.fit)\n}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploring SEs for Logistic Regression</span>"
    ]
  },
  {
    "objectID": "app4_logistic_se.html#simulate-sampling-distribution",
    "href": "app4_logistic_se.html#simulate-sampling-distribution",
    "title": "1  Exploring SEs for Logistic Regression",
    "section": "1.3 Simulate sampling distribution",
    "text": "1.3 Simulate sampling distribution\nSettings\n\n\nCode\n# set n high to have robust models (and to handle uncertainty about z vs. t)\nn &lt;- 1000 \nb0 &lt;- 0\nb1 &lt;- 0.5 \nn_sims &lt;- 50000\n\n\nsimulate predictions to create sampling distribution\n\n\nCode\ncl &lt;- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE))\ndoParallel::registerDoParallel(cl)\nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n\npreds &lt;- 1:n_sims |&gt; \n  future_map(\\(sim) get_preds(sim, n, b0, b1),\n             .options = furrr_options(seed = 2468)) |&gt;\n  list_rbind()\n\nplan(sequential)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploring SEs for Logistic Regression</span>"
    ]
  },
  {
    "objectID": "app4_logistic_se.html#add-post-simulation-calcs-to-preds",
    "href": "app4_logistic_se.html#add-post-simulation-calcs-to-preds",
    "title": "1  Exploring SEs for Logistic Regression",
    "section": "1.4 Add post simulation calcs to preds",
    "text": "1.4 Add post simulation calcs to preds\nTransform log-odds to pr and get CIs for log-odds, pr from log-odds, and native pr\n\n\nCode\npreds &lt;- preds |&gt; \n  mutate(upr_lo = fit_lo + 1.96 * se_lo,\n         lwr_lo = fit_lo - 1.96 * se_lo,\n         fit_lo_pr = plogis(fit_lo),\n         upr_lo_pr = plogis(upr_lo),\n         lwr_lo_pr = plogis(lwr_lo),\n         upr_pr = fit_pr + 1.96 * se_pr,\n         lwr_pr = fit_pr - 1.96 * se_pr) \n\n\nCalc true values and join with preds\n\n\nCode\ntrue_values &lt;- tibble(x = c(-8, -3, 0, 3, 8)) |&gt; \n  mutate(true_lo = b0 + b1 * x,\n         true_pr = plogis(true_lo))\n\npreds &lt;- preds |&gt; \n  left_join(true_values, by = \"x\") |&gt; \n  relocate(sim, x, true_lo, true_pr, \n           fit_lo, lwr_lo, upr_lo, \n           fit_lo_pr, lwr_lo_pr, upr_lo_pr,\n           fit_pr, lwr_pr, upr_pr)\n\n\nCalculate true SE (sd of sampling distribution for fits across simulations)\n\n\nCode\nse_true &lt;- preds |&gt; \n  group_by(x) |&gt;\n  summarise(se_lo_true = sd(fit_lo), \n            se_pr_true = sd(fit_pr),\n            .groups = \"drop\")\n\n\nReview preds\n\n\nCode\npreds |&gt; head(10)\n\n\n# A tibble: 10 × 15\n     sim     x true_lo true_pr  fit_lo lwr_lo  upr_lo fit_lo_pr lwr_lo_pr\n   &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1     1    -8    -4    0.0180 -3.82   -4.30  -3.34      0.0215   0.0133 \n 2     1    -3    -1.5  0.182  -1.51   -1.76  -1.25      0.181    0.147  \n 3     1     0     0    0.5    -0.118  -0.304  0.0674    0.470    0.425  \n 4     1     3     1.5  0.818   1.27    1.03   1.51      0.781    0.737  \n 5     1     8     4    0.982   3.58    3.12   4.04      0.973    0.958  \n 6     2    -8    -4    0.0180 -4.35   -4.91  -3.79      0.0128   0.00732\n 7     2    -3    -1.5  0.182  -1.62   -1.91  -1.33      0.165    0.129  \n 8     2     0     0    0.5     0.0119 -0.200  0.224     0.503    0.450  \n 9     2     3     1.5  0.818   1.65    1.36   1.93      0.838    0.796  \n10     2     8     4    0.982   4.37    3.81   4.93      0.988    0.978  \n# ℹ 6 more variables: upr_lo_pr &lt;dbl&gt;, fit_pr &lt;dbl&gt;, lwr_pr &lt;dbl&gt;,\n#   upr_pr &lt;dbl&gt;, se_lo &lt;dbl&gt;, se_pr &lt;dbl&gt;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploring SEs for Logistic Regression</span>"
    ]
  },
  {
    "objectID": "app4_logistic_se.html#visual-sampling-distributions-for-predictions",
    "href": "app4_logistic_se.html#visual-sampling-distributions-for-predictions",
    "title": "1  Exploring SEs for Logistic Regression",
    "section": "1.5 Visual sampling distributions for predictions",
    "text": "1.5 Visual sampling distributions for predictions\nFor log-odds\n\n\nCode\npreds |&gt; \n  ggplot(aes(x = fit_lo, fill = fct(as.character(x)))) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Sampling Distribution of Log-Odds\",\n       x = \"Log-Odds\",\n       y = \"Density\") + \n  scale_fill_discrete(name = \"X\")\n\n\n\n\n\n\n\n\n\nFor pr from log-odds\n\n\nCode\npreds |&gt; \n  ggplot(aes(x = fit_lo_pr, fill = fct(as.character(x)))) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Sampling Distribution of Pr from Log-Odds\",\n       x = \"Pr\",\n       y = \"Density\") + \n  scale_fill_discrete(name = \"X\")\n\n\n\n\n\n\n\n\n\nFor pr\n\n\nCode\npreds |&gt; \n  ggplot(aes(x = fit_pr, fill = fct(as.character(x)))) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Sampling Distribution of Pr\",\n       x = \"Pr\",\n       y = \"Density\") + \n  scale_fill_discrete(name = \"X\")\n\n\n\n\n\n\n\n\n\nLook more closely at edge of X. Its mostly but not completely symetric. This is why a symetric confidence interval will NOT work optimally for pr.\n\n\nCode\npreds |&gt; \n  filter(x == -8) |&gt; \n  ggplot(aes(x = fit_pr)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Sampling Distribution of Pr for X = -8\",\n       x = \"Pr\",\n       y = \"Density\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploring SEs for Logistic Regression</span>"
    ]
  },
  {
    "objectID": "app4_logistic_se.html#review-min-and-max-values-for-probability-based-cis",
    "href": "app4_logistic_se.html#review-min-and-max-values-for-probability-based-cis",
    "title": "1  Exploring SEs for Logistic Regression",
    "section": "1.6 Review min and max values for probability based CIs",
    "text": "1.6 Review min and max values for probability based CIs\nCIs for probability are NOT equivalent when formed from log-odds vs. pr. This is because the transformation from log-odds to pr is non-linear (after adding/subtracting SE).\nIn this example, the CI boundaries for probability are never &lt; 0 or greater than 1 even when calculated directly as probability + 1.96 SE. But that may not be always true. Also clear that +- 1.96 SE is not appropriate for a probability CI given its not symetric and therefore clearly not always normal.\n\n\nCode\npreds |&gt; \n  group_by(x) |&gt; \n  summarise(min_lwr_lo_pr = min(lwr_lo_pr),\n            min_lwr_pr = min(lwr_pr),\n            max_upr_lo_pr = max(upr_lo_pr),\n            max_upr_pr = max(upr_pr),\n            .groups = \"drop\")\n\n\n# A tibble: 5 × 5\n      x min_lwr_lo_pr min_lwr_pr max_upr_lo_pr max_upr_pr\n  &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1    -8       0.00234    0.00134        0.0657     0.0623\n2    -3       0.0746     0.0705         0.343      0.341 \n3     0       0.338      0.336          0.656      0.657 \n4     3       0.686      0.688          0.925      0.929 \n5     8       0.936      0.939          0.998      0.999",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploring SEs for Logistic Regression</span>"
    ]
  },
  {
    "objectID": "app4_logistic_se.html#check-model-ses-from-predict-for-lo-and-pr",
    "href": "app4_logistic_se.html#check-model-ses-from-predict-for-lo-and-pr",
    "title": "1  Exploring SEs for Logistic Regression",
    "section": "1.7 Check model SEs (from predict) for lo and pr",
    "text": "1.7 Check model SEs (from predict) for lo and pr\nNow fit a single model and use predict() to se.fit for lo and pr\n\n\nCode\nd &lt;- make_data(n, b0, b1)\nm &lt;- glm(y ~ x, data = d, family = binomial) \nsample_preds &lt;- tibble(x = c(-8, -3, 0, 3, 8))\nsample_preds &lt;- sample_preds |&gt; \n  bind_cols(predict(m, newdata = sample_preds, \n                        type = \"link\",\n                        se.fit = TRUE)) |&gt; \n  select(x, se_lo_mod = se.fit)\nsample_preds &lt;- sample_preds |&gt; \n  bind_cols(predict(m, newdata = sample_preds, \n                        type = \"response\",\n                        se.fit = TRUE)) |&gt; \n  select(x, se_lo_mod, se_pr_mod = se.fit)\n\n\nNow compare model SEs to true SEs\n\n\nCode\nse &lt;- se_true |&gt; \n  full_join(sample_preds, by = \"x\") |&gt; \n  mutate(diff_lo = se_lo_true - se_lo_mod,\n         diff_pr = se_pr_true - se_pr_mod) |&gt; \n  relocate(x, \n           se_lo_true, se_lo_mod, diff_lo, \n           se_pr_true, se_pr_mod, diff_pr)\nse\n\n\n# A tibble: 5 × 7\n      x se_lo_true se_lo_mod diff_lo se_pr_true se_pr_mod   diff_pr\n  &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1    -8      0.266    0.244  0.0211     0.00463   0.00524 -0.000601\n2    -3      0.137    0.130  0.00724    0.0202    0.0201   0.000100\n3     0      0.102    0.0983 0.00350    0.0254    0.0246   0.000813\n4     3      0.137    0.127  0.00954    0.0202    0.0203  -0.000164\n5     8      0.265    0.240  0.0244     0.00462   0.00541 -0.000782",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploring SEs for Logistic Regression</span>"
    ]
  },
  {
    "objectID": "app4_logistic_se.html#check-cis",
    "href": "app4_logistic_se.html#check-cis",
    "title": "1  Exploring SEs for Logistic Regression",
    "section": "1.8 Check CIs",
    "text": "1.8 Check CIs\nFor LO GOOD!\n\n\nCode\npreds |&gt; \n  mutate(value_in_ci = if_else(lwr_lo &lt;= true_lo & \n                               upr_lo &gt;= true_lo, \n                               1, 0)) |&gt; \n pull(value_in_ci) |&gt; \n mean()\n\n\n[1] 0.949692\n\n\nFor PR from LO GOOD!\n\n\nCode\npreds |&gt; \n  mutate(value_in_ci = if_else(lwr_lo_pr &lt;= true_pr & \n                               upr_lo_pr &gt;= true_pr, \n                               1, 0)) |&gt; \n pull(value_in_ci) |&gt; \n mean()\n\n\n[1] 0.949692\n\n\nFor PR from LO Not perfect. This is why we should use CIs for probability formed from log odds predictions!\n\n\nCode\npreds |&gt; \n  mutate(value_in_ci = if_else(lwr_pr &lt;= true_pr & \n                               upr_pr &gt;= true_pr, \n                               1, 0)) |&gt; \n pull(value_in_ci) |&gt; \n mean()\n\n\n[1] 0.941612\n\n\nAs expected the CI coverage is worse for the edge of the X range\n\n\nCode\npreds |&gt; \n  filter(x == -8) |&gt;\n  mutate(value_in_ci = if_else(lwr_pr &lt;= true_pr & \n                               upr_pr &gt;= true_pr, \n                               1, 0)) |&gt; \n pull(value_in_ci) |&gt; \n mean()\n\n\n[1] 0.93338",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploring SEs for Logistic Regression</span>"
    ]
  },
  {
    "objectID": "app5_noise.html",
    "href": "app5_noise.html",
    "title": "Simulate Noise Added to \\(X\\) vs. \\(Y\\)",
    "section": "",
    "text": "The problem\nLinear models assume that there is no noise in the measurement of \\(X\\). In contrast, noise in \\(Y\\) is permitted (and modeled) by the inclusion of an error term (the residuals) into the model.\nIf there is noise in \\(X\\) in a simple (one predictor) model, we will underestimate the effect of \\(X\\). In models with more than one \\(X\\), we may either underestimate or overestimate the unique effect of an \\(X\\) controlling for \\(X2\\) if we add noise to \\(X2\\), depending on the pattern of relationships among the \\(X\\)s and \\(Y\\)\nLets understand this a bit better. We can start by setting up a context to simulate estimating the effect of \\(X\\) by repeatedly sampling \\(X\\) and \\(Y\\) from the population so that we can look at the sampling distribution for \\(b_x\\). We will consider three conditions",
    "crumbs": [
      "Appendices",
      "Simulate Noise Added to $X$ vs. $Y$"
    ]
  },
  {
    "objectID": "app5_noise.html#the-problem",
    "href": "app5_noise.html#the-problem",
    "title": "Simulate Noise Added to \\(X\\) vs. \\(Y\\)",
    "section": "",
    "text": "A baseline model with \\(X\\) and \\(Y\\)\nThe addition of noise to \\(Y\\)\nThe addition of noise to \\(X\\)",
    "crumbs": [
      "Appendices",
      "Simulate Noise Added to $X$ vs. $Y$"
    ]
  },
  {
    "objectID": "app5_noise.html#set-up-simulation-characteristics",
    "href": "app5_noise.html#set-up-simulation-characteristics",
    "title": "Simulate Noise Added to \\(X\\) vs. \\(Y\\)",
    "section": "Set up simulation characteristics",
    "text": "Set up simulation characteristics\nWe set up these (mostly arbitrary) characteristics for our simulation\n\n20000 simulations\nsample size of 200\nPopulation effect for \\(X\\) of \\(\\beta_x\\) = 10\n\n\n\nCode\nn_experiments &lt;- 20000\nn &lt;- 200\nBeta &lt;- 3 \n\nset.seed(1234567)",
    "crumbs": [
      "Appendices",
      "Simulate Noise Added to $X$ vs. $Y$"
    ]
  },
  {
    "objectID": "app5_noise.html#set-up-some-functions-to-support-simulation",
    "href": "app5_noise.html#set-up-some-functions-to-support-simulation",
    "title": "Simulate Noise Added to \\(X\\) vs. \\(Y\\)",
    "section": "Set up some functions to support simulation",
    "text": "Set up some functions to support simulation\nThis function draws a sample of data using the characteristics set by the function arguments\n\n\nCode\nget_data &lt;- function(n, Beta, noise_x = 0, noise_y = 0){\n  x &lt;- rnorm(n, 0, 10)\n  y &lt;- 0 + Beta * x + rnorm(n, 0, 10) \n\n  # add noise to our measurement of either X or Y  \n  if (noise_x != 0) {\n    x &lt;- x + rnorm(n, 0, noise_x)\n  }\n  if (noise_y != 0) {\n    y &lt;- y + rnorm(n, 0, noise_y)\n  }\n  \n  tibble(x, y) \n}\n\n\nThis function draws a sample using earlier function and then fits model and returns statistics for the effect of \\(X\\)\n\n\nCode\nget_b &lt;- function(n, Beta, noise_x = 0, noise_y = 0){\n  \n  get_data(n, Beta, noise_x, noise_y) |&gt; \n  lm(y ~ x, data = _) |&gt; \n    tidy() |&gt; \n    filter(term == \"x\") \n}",
    "crumbs": [
      "Appendices",
      "Simulate Noise Added to $X$ vs. $Y$"
    ]
  },
  {
    "objectID": "app5_noise.html#simulations",
    "href": "app5_noise.html#simulations",
    "title": "Simulate Noise Added to \\(X\\) vs. \\(Y\\)",
    "section": "Simulations",
    "text": "Simulations\nLets run simulations for our three contexts\n\nbaseline model\nadd noise to y\nadd noise to x\n\n\n\nCode\nnoise_none &lt;- 1:n_experiments |&gt; \n  map(\\(i) get_b(n, Beta)) |&gt;\n  list_rbind()\n\nnoise_y &lt;- 1:n_experiments |&gt; \n  map(\\(i) get_b(n, Beta, noise_y = 10)) |&gt;\n  list_rbind()\n\nnoise_x &lt;- 1:n_experiments |&gt; \n  map(\\(i) get_b(n, Beta, noise_x = 10)) |&gt;\n  list_rbind()\n\n\nAnd lets look at the parameter estimate and (SE) for \\(X\\) from the three simulations\n\nNoise in \\(Y\\) has no effect on \\(b_x\\) but it does increase the associated standard error\nNoise in \\(X\\) introduces bias into \\(b_x\\). It now underestimates the true \\(\\beta\\) = 3. This noise, also increase the associated standard error.\n\n\n\nCode\nresults_base &lt;- noise_none |&gt; \n  summarise(mean_b = mean(estimate),\n            se_b = sd(estimate)) |&gt;\n  mutate(context = \"baseline\")\nresults_y &lt;- noise_y |&gt; \n  summarise(mean_b = mean(estimate),\n            se_b = sd(estimate)) |&gt;\n  mutate(context = \"noise y\")\nresults_x &lt;- noise_x |&gt; \n  summarise(mean_b = mean(estimate),\n            se_b = sd(estimate)) |&gt;\n  mutate(context = \"noise x\")\n\nresults_base |&gt; \n  bind_rows(results_y) |&gt; \n  bind_rows(results_x) |&gt; \n  relocate(context)\n\n\n# A tibble: 3 × 3\n  context  mean_b   se_b\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 baseline   3.00 0.0714\n2 noise y    3.00 0.101 \n3 noise x    1.50 0.119",
    "crumbs": [
      "Appendices",
      "Simulate Noise Added to $X$ vs. $Y$"
    ]
  },
  {
    "objectID": "app5_noise.html#simple-demonstration-with-a-single-sample",
    "href": "app5_noise.html#simple-demonstration-with-a-single-sample",
    "title": "Simulate Noise Added to \\(X\\) vs. \\(Y\\)",
    "section": "Simple demonstration with a single sample",
    "text": "Simple demonstration with a single sample\nLets dive into the problem a little deeper with a single sample\nFirst, lets draw a sample and fit the model. As we see, the parameter estimate is approximately 3, as expected.\n\n\nCode\nd_base &lt;- get_data(n, Beta)\n\nlm(y ~ x, data = d_base) |&gt; \n  tidy() |&gt; \n  filter(term == \"x\")\n\n\n# A tibble: 1 × 5\n  term  estimate std.error statistic  p.value\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 x         2.94    0.0728      40.4 1.20e-97\n\n\nNow lets see what happens when we add noise to \\(Y\\). As seen, the parameter estimate is still approximately 3\n\n\nCode\nd_y &lt;- get_data(n, Beta, noise_y = 10)\n\nlm(y ~ x, data = d_y) |&gt; \n  tidy() |&gt; \n  filter(term == \"x\")\n\n\n# A tibble: 1 × 5\n  term  estimate std.error statistic  p.value\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 x         2.96     0.104      28.5 4.65e-72\n\n\nNow lets see what happens when we add noise to \\(X\\). The parameter estimate is much smaller! It underestimates the effect of \\(X\\)\n\n\nCode\nd_x &lt;- get_data(n, Beta, noise_x = 10)\n\nlm(y ~ x, data = d_x) |&gt; \n  tidy() |&gt; \n  filter(term == \"x\")\n\n\n# A tibble: 1 × 5\n  term  estimate std.error statistic  p.value\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 x         1.49     0.119      12.5 8.98e-27\n\n\nLets also visualize all three of these models to understand them better. Hopefully, this helps your intution regarding why noise in X decreases our estimate of its effect.\n\n\nCode\np_base &lt;- d_base |&gt; \n  ggplot(aes(x = x, y = y)) +\n    geom_point() +\n    stat_smooth(method = \"lm\", \n                formula = y ~ x, \n                geom = \"smooth\") +\n  xlim(-50, 50) +\n  ylim(-100, 100) +\n  ggtitle(\"baseline\")\n\np_y &lt;- d_y |&gt; \n  ggplot(aes(x = x, y = y)) +\n    geom_point() +                                      \n    stat_smooth(method = \"lm\", \n                formula = y ~ x, \n                geom = \"smooth\") +\n  xlim(-50, 50) +\n  ylim(-100, 100) + \n  ggtitle(\"y noise\")\n\np_x &lt;- d_x |&gt; \n  ggplot(aes(x = x, y = y)) +\n    geom_point() +\n    stat_smooth(method = \"lm\", \n                formula = y ~ x, \n                geom = \"smooth\") +\n  xlim(-50, 50) +\n  ylim(-100, 100) +\n  ggtitle(\"x noise\")\n\np_base + p_y + p_x\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).",
    "crumbs": [
      "Appendices",
      "Simulate Noise Added to $X$ vs. $Y$"
    ]
  }
]