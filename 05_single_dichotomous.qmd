--- 
output: html_document 
editor_options:  
  chunk_output_type: console
--- 
 

# Inferences about a Single Dichotomous Predictor

```{r}
#| echo: false

options(scipen = 999) # turns off scientfic notation
```


## Categorical Variables in GLM

1. One dichotomous predictor coded with one regressor (*this unit*).   

2. Learn models with multiple regressors in later units:

  - One-way between subject ANOVA (One predictor, multiple regressors) 
  - Multiple predictors and regressors
	  - *Additive:*  ANCOVA, General Additive Models
	  - *Interactive:* Factorial ANOVA, Attitude Treatment Interactions, General Interactive Models    

3. Repeated measures & mixed model designs
  
-----

## Dichotomous Predictor
  
<span style="color: red;">Question: Consider a regression model with one dichotomous predictor and the typical continuous DV. What other statistical test is this regression equivalent to?</span>

-----

<span style="color: blue;">An independent samples (between subjects) t-test comparing the two groups that are represented by the two levels of the predictor on the mean of the DV.</span>


-----

## Coding Dichotomous Predictors

<span style="color: red;">Question: How do we handle analysis of dichotomous predictors in regression?</span>

-----

<span style="color: blue;">Very simple! We will assign two “arbitrary” values to a regressor $X$ to represent the two levels (groups) in the dichotomous predictor variable.</span>

There are 2 coding schemes that we will need to learn:    

1. Dummy coding (reference/control group)
2. Contrast coding (for now, unit weighted, centered coefficients).   

We also need to learn distinction between weighted vs. unweighted means (optional).   


-----

## Dummy Coding

**Dummy coding with a dichotomous variable:**.  
Dummy coding involves assigning 1’s and 0’s to the regressor in a specific pattern.  For the two level simple case, assign a 0 to the control/reference group and a 1 to the target or experimental group.  (Doesn’t *really* matter which is which; <span style="color: red;">but what would change?  What about -1 vs. 1</span>)

-----

## Our Running Example

```{r}
#| message: false

library(tidyverse)
library(patchwork)

theme_set(theme_classic()) 

path_data <- "data_lecture" 

data <- read_csv(here::here(path_data, "5_single_dichotomous_bg_fps.csv"),
                 show_col_types = FALSE) |> 
  glimpse()
```

-----

```{r}
data |> 
  pivot_longer(where(is.numeric), names_to = "var") |> 
  group_by(var) |> 
  summarise(n = n(),
            mean = mean(value),
            sd = sd(value),
            min = min(value),
            max = max(value))
```

-----

```{r}
data |> 
  group_by(bg_2) |> 
  count()
```


-----

## Dichotomous Beverage Group


```{r}
m_d <- lm(fps ~ bg_2, data = data)

m_d |> 
  broom::tidy()
```

```{r}
#| echo: false

data_q <- read_csv(here::here(path_data, "4_single_quantitative_bac_fps.csv"),
                 show_col_types = FALSE) 
```

```{r}
m_q <- lm(fps ~ bac, data = data_q)

m_q |> 
  broom::tidy()
```


<span style="color: red;">Question: What is different about the NHST of the *alcohol* effect with bg_2 vs BAC and why?</span>   

-----

## >SSE leads to >SEs and <Power

<span style="color: blue;">p-value is worse (bigger) for bg_2 than BAC. Taking a quantitative variable and dichotomizing (or trichotomizing, etc.) throws away potentially valuable information in  your predictor variable. The dichotomous variable will generally be a worse predictor. This will produce a model with more error (> SSE) and less power (> p-values) to test hypotheses.</span>   


<span style="color: blue;">Don’t dichotomize unless there is a **REALLY** good reason. GLM can accommodate quantitative variables anywhere you would have previously used a categorical variable.</span>  


$\text{SE}_{b_0}=\sqrt{\frac{\text{SSE}}{N-P}}*\sqrt{\frac{1}{N}+\frac{(\overline{X})^2}{(N-1)*S_x^2}}$  

$\text{SE}_{b_1}=\frac{s_y}{s_x}*\sqrt{\frac{1-R^2}{N-P}}$


-----

## Dichotomous Beverage Group (cont.)

```{r}
#| code-fold: true

m_d |> 
  broom::tidy()
```

<span style="color: red;">Question: What is the interpretation of $b_1$ (bg_2) in this model?</span>

-----

<span style="color: blue;">Still change in $Y$ for one unit change in $X$.</span>   

<span style="color: blue;">However, a one unit change in $X$ moves from the no-alcohol group (coded 0) to alcohol group (coded 1).  Therefore $b_1$ is now the predicted change in $Y$ between no-alcohol and alcohol groups. This is simply the difference in the mean of the two groups!</span>

-----

<span style="color: red;">Question: Where is $b_1$ (bg_2 effect) on this graph?</span>   

```{r}
#| code-fold: true

plot_d <- data |> 
  ggplot(aes(x = bg_2, y = fps)) +
  geom_point(alpha = .6, size = 2) +
  geom_abline(aes(intercept = coef(m_d)[1],
                  slope = coef(m_d)[2]),
                  linewidth = 1) 

plot_d
```

-----

<span style="color: blue;">It is the slope of the line (as before). The line goes through the mean of FPS scores for each of the two groups.</span>   

```{r}
#| code-fold: true
labels <- tibble(means = c(round(mean(subset(data, bg_2 == 0)$fps), 2), 
                           round(mean(subset(data, bg_2 == 1)$fps), 2)),
                 vars = c("bg_1", "bg_2"))
plot_d +
  annotate("text", x = -.15, y = labels$means[1], label = labels$means[1], 
           size = 6, color = "blue") +
  annotate("text", x = 1.1, y = labels$means[2], label = labels$means[2], 
           size = 6, color = "blue") +
  annotate("text", x = 0, y = -140, label = "No Alcohol", 
           size = 5, color = "blue") +
   annotate("text", x = 1, y = -140, label = "Alcohol", 
           size = 5, color = "blue") +
  coord_cartesian(xlim = c(0, 1),
                  (ylim = c(-100, 175)),
                  clip = "off") +
  theme(plot.margin = unit(c(0, .75, .5, .75), "inches"))
```

-----

```{r}
#| code-fold: true

m_d |> 
  broom::tidy()
```

<span style="color: red;">Question: What is the interpretation of $b_0$ in this model?</span>

-----

<span style="color: blue;">Still predicted value for $Y$ when $X$ = 0.</span>   

<span style="color: blue;">In this context, that is the predicted FPS score for the no-alcohol group (coded 0).</span>

-----

<span style="color: red;">Question: Where is $b_0$ on this graph?</span>   

```{r}
#| code-fold: true

plot_d
```

-----

<span style="color: blue;">It is the $Y$ intercept as before. The value of FPS when $X$ = 0.</span>

```{r}
#| code-fold: true

plot_d +
  annotate("text", x = -.15, y = labels$means[1], label = labels$means[1], 
           size = 6, color = "blue") +
  annotate("text", x = 0, y = -140, label = "No Alcohol", 
           size = 5, color = "blue") +
  coord_cartesian(xlim = c(0, 1),
                  (ylim = c(-100, 175)),
                  clip = "off") +
  theme(plot.margin = unit(c(0, 0, .5, .75), "inches"))
```

-----

<span style="color: red;">Question: Does alcohol affect FPS?</span>

-----

```{r}
#| code-fold: true

m_d |> 
  broom::tidy()
```


$H_0: \beta_1 = 0$   
$H_a: \beta_1 \neq 0$   

<span style="color: blue;">No. The probability of getting a $b_1$ of `r round(coef(m_d)[2], 3)` or more extreme is `r round(broom::tidy(m_d)$p.value[2], 3)` if the null hypothesis is true.  This is not sufficient evidence to reject the null.</span>

-----

## Model Comparisons ($\beta_1$)

<span style="color: red;">Question: What two models are you comparing to test your hypotheses about alcohol’s effect on FPS?</span>   

-----

$H_0: \beta_1 = 0$  
$H_a: \beta_1 \neq 0$   

<span style="color: blue;">Compact model:  $\hat{\text{FPS}}_i = \beta_0+0*\text{bg}\_2_i$</span>  
$P_c = 1$  
$\text{SSE}_c = `r round(sum((data$fps - mean(data$fps))^2),2)`$  


<span style="color: blue;">Augmented model:  $\hat{\text{FPS}}_i=\beta_0+\beta_1*\text{bg}\_2_i$</span>   
$P_a=2$  
$\text{SSE}_a = `r round(sum((data$fps - predict(m_d))^2),2)`$

-----

<span style="color: red;">Question: How do you use this information to calculate $\eta_p^2$ (PRE) for the bg_2 effect?</span> 

-----

Compact model:  $\hat{\text{FPS}}_i=\beta_0+0*\text{bg}\_2_i$  
$P_c = 1$  
$\text{SSE}_c = `r round(sum((data$fps - mean(data$fps))^2),2)`$   


Augmented model:  $\hat{\text{FPS}}_i=\beta_0+\beta_1*\text{bg}\_2_i$   
$P_a=2$  
$\text{SSE}_a = `r round(sum((data$fps - predict(m_d))^2),2)`$

<span style="color: blue;">PRE or $\eta_p^2$ is the proportion reduction in error due to the effect (the parameter). Use the same models that you would use to test the hypotheses about that parameter.</span>  

<span style="color: blue;">$\frac{\text{SSE}_c - \text{SSE}_a}{\text{SSE}_c}=\frac{`r round(sum((data$fps - mean(data$fps))^2),2)` - `r round(sum((data$fps - predict(m_d))^2),2)`}{`r round(sum((data$fps - mean(data$fps))^2),2)`} = `r round((sum((data$fps - mean(data$fps))^2)-sum((data$fps - predict(m_d))^2))/sum((data$fps - mean(data$fps))^2), 4)`$</span>

-----

## Testing $\beta_0$

<span style="color: red;">Question: Does our task produce non-zero fear potentiated startle in sober people?</span> 

-----

```{r}
#| code-fold: true

m_d |> 
  broom::tidy()
```

$H_0: \beta_0 = 0$  
$H_a: \beta_0 \neq 0$   

<span style="color: blue;">Yes. The probability of getting a $b_0$ of `r round(coef(m_d)[1], 3)` or more extreme is `r round(broom::tidy(m_d)$p.value[1], 8)` if the null hypothesis is true.  Very unlikely so reject null. Conclude $B_0 > 0$.</span>

-----

## Model Comparisons ($\beta_0$)

<span style="color: red;">Question: What two models are you comparing to test your hypotheses about mean FPS for sober people?</span>  

-----

$H_0: \beta_0 = 0$  
$H_a: \beta_0 \neq 0$   

<span style="color: blue;">Compact model: $\hat{\text{FPS}}_i=0+\beta_1*\text{bg}\_2_i$</span>  

$P_c = 1$  
$\text{SSE}_c = `r round(sum((data$fps - predict(lm(fps~bg_2 -1, data = data)))^2),2)`$  


<span style="color: blue;">Augmented model: $\hat{\text{FPS}}_i=\beta_0+\beta_1*\text{bg}\_2_i$</span>   

$P_a=2$  
$\text{SSE}_a = `r round(sum((data$fps - predict(m_d))^2),2)`$

-----

<span style="color: red;">Question: How do you use this information to calculate $\eta_p^2$ (PRE) for $\beta_0$?</span>  

-----

Compact model: $\hat{\text{FPS}}_i=0+\beta_1*\text{bg}\_2_i$  

$P_c = 1$  
$\text{SSE}_c = `r round(sum((data$fps - predict(lm(fps~bg_2 -1, data = data)))^2),2)`$  


Augmented model: $\hat{\text{FPS}}_i=\beta_0+\beta_1*\text{bg}\_2_i$   

$P_a=2$  
$\text{SSE}_a = `r round(sum((data$fps - predict(m_d))^2),2)`$  

<span style="color: blue;">PRE or $\eta_p^2$ is the proportion reduction in error due to the effect (the parameter). Use the same models that you would use to test the hypotheses about that parameter.</span>  

<span style="color: blue;">$\frac{\text{SSE}_c - \text{SSE}_a}{\text{SSE}_c}= \frac{`r round(sum((data$fps - predict(lm(fps~bg_2 -1, data = data)))^2),2)` - `r round(sum((data$fps - predict(m_d))^2),2)`}{`r round(sum((data$fps - predict(lm(fps~bg_2 -1, data = data)))^2),2)` } = `r round((sum((data$fps - predict(lm(fps~bg_2 -1, data = data)))^2) -sum((data$fps - predict(m_d))^2))/sum((data$fps - predict(lm(fps~bg_2 -1, data = data)))^2), 4)`$</span>

-----

<span style="color: red;">Question: How do you use this information to calculate $R^2$ for the augmented model?</span>  

-----

Mean Only model: $\hat{\text{FPS}_i}=\beta_0$  

$P_c = 1$  
$\text{SSE}_c = `r round(sum((data$fps - mean(data$fps))^2),2)`$  


Augmented model: $\hat{\text{FPS}}=\beta_0+\beta_1*\text{bg}\_2_i$   

$P_a=2$  
$\text{SSE}_a = `r round(sum((data$fps - predict(m_d))^2),2)`$  

<span style="color: blue;">$R^2$ is the proportion of explained variance over total variance in $Y$. The total variance is equivalent to the SSE of the Mean Only model (</span><span style="color: red;">WHY?</span><span style="color: blue;">).</span>   

$\frac{\text{SSE}_\text{mean}-\text{SSE}_a}{\text{SSE}_\text{mean}}=\frac{`r round(sum((data$fps - mean(data$fps))^2),2)` - `r round(sum((data$fps - predict(m_d))^2),2)`}{`r round(sum((data$fps - mean(data$fps))^2),2)`}$ = `r round((sum((data$fps - mean(data$fps))^2) - sum((data$fps - predict(m_d))^2))/sum((data$fps - mean(data$fps))^2),4)`$ 

<span style="color: blue;">At this point it equals PRE b/c $\text{SSE}_c$ is the mean only model!</span>  

-----

## Effect Sizes in R

```{r}
m_mean <- lm(fps ~ 1, data = data) 
m_d <- lm(fps ~ bg_2, data = data)
```

$\eta_p^2$
```{r}
(sum(residuals(m_mean)^2)- sum(residuals(m_d)^2))/sum(residuals(m_mean)^2) 
```

$R^2$
```{r}
broom::glance(m_d)$r.squared 
```

-----

## Unit Weighted, Centered Coefficients

```{r}
data <- data |> 
  mutate(bg_2c = if_else(bg_2 == 0, -.5, .5))
```

```{r}
m_c <- lm(fps ~ bg_2c, data = data)

m_c |> 
  broom::tidy()
```

-----

## Visual Displays of Dummy vs. Centered

```{r}
#| code-fold: true

plot_d <- plot_d +
  labs(title = "Dummy")

plot_c <- data |> 
  ggplot(aes(x = bg_2c, y = fps)) +
  geom_point(alpha = .6, size = 2) +
  geom_abline(aes(intercept = coef(m_c)[1],
                  slope = coef(m_c)[2]),
                  linewidth = 1) +
  labs(title = "Zero-centered")
  
  
plot_d + plot_c
```


<span style="color: red;">Question: $b_0, b_1$ in each?</span>  

-----

## $b_0$ with Zero-Centered Coefficients

<span style="color: red;">Question: Is $b_0$ (`r round(coef(m_c)[1], 2)`) the mean of FPS in the sample?</span>    

-----

<span style="color: blue;">It is the unweighted mean.</span>    

<span style="color: blue;">Weighted and unweighted means emerge as concepts with grouped data.   An unweighted mean is the mean of the group means, ignoring the $N$ in each group.</span>    

```{r}
data |> 
  summarise(mean = mean(fps),
            sd = sd(fps))
```

```{r}
data |> 
  group_by(bg_2) |> 
  summarise(mean = mean(fps),
            sd = sd(fps))
```

-----

## $b_0$ as Weighted Mean

A weighted mean is the mean of the groups *weighted* or proportional to their sample sizes. It is also equal to the grand mean of the DV ignoring group.  

<span style="color: red;">Question: How can you get $b_0$ to reflect the weighted mean?</span>.  

-----

<span style="color: blue;">Mean center $X$. This is the same as we did with a quantitative variable to make $b_0$ equal the grand mean.</span>   

```{r}
data <- data |> 
  mutate(bg_2mc = bg_2 - mean(bg_2))
```

```{r}
data |> 
  pull(bg_2mc)
```

-----

```{r}
mean(data$bg_2mc)
```


-----

## $b_0$ as Weighted Mean

```{r}
m_mc <- lm(fps ~ bg_2mc, data = data)

m_mc |> 
  broom::tidy()
```

-----

## Comparing $b_0$ Across Models

```{r}
#| code-fold: true

plot_d <- plot_d +
  labs(title = "Dummy") +
  annotate("text", x = -.1, y = round(coef(m_d)[1],2) + 10, label = round(coef(m_d)[1],2), 
           size = 5, color = "blue") +
  coord_cartesian(clip = "off") 

plot_c <- data |> 
  ggplot(aes(x = bg_2c, y = fps)) +
  geom_point(alpha = .6, size = 2) +
  geom_abline(aes(intercept = coef(m_c)[1],
                  slope = coef(m_c)[2]),
                  linewidth = 1) +
  labs(title = "Zero-centered")  +
  annotate("text", x = 0, y = round(coef(m_c)[1],2) + 10, label = round(coef(m_c)[1],2), 
           size = 5, color = "blue") +
  coord_cartesian(clip = "off") 

plot_mc <- data |> 
  ggplot(aes(x = bg_2mc, y = fps)) +
  geom_point(alpha = .6, size = 2) +
  geom_abline(aes(intercept = coef(m_mc)[1],
                  slope = coef(m_mc)[2]),
                  linewidth = 1) +
  labs(title = "Mean-centered") +
  annotate("text", x = .9, y = round(coef(m_mc)[1],2) + 10, label = round(coef(m_mc)[1],2), 
           size = 5, color = "blue") +
  coord_cartesian(clip = "off") 

  
  
plot_d + plot_c + plot_mc
```


-----

## Other (not useful) Coefficients

<span style="color: red;">What would be the interpretation of $b_0$ and $b_1$ if I used coefficients of -1 and 1 for bg_2?</span>

-----

<span style="color: blue;">$b_0$ will be the unweighted mean of FPS because 0 is halfway between the two groups.</span>    


<span style="color: blue;">$b_1$ will be half what it was in all previous models b/c a one unit change on $X$ will only go halfway between no-alcohol and alcohol groups.</span>

```{r}
data <- data |> 
  mutate(bg_2o = if_else(bg_2==0, -1, 1))
```

```{r}
m_o <- lm(fps ~ bg_2o, data = data)

m_o |> 
  broom::tidy()
```

-----

```{r}
data |> 
  ggplot(aes(x = bg_2o, y = fps)) +
  geom_point(alpha = .6, size = 2) +
  geom_abline(aes(intercept = coef(m_o)[1],
                  slope = coef(m_o)[2]),
                  linewidth = 1) 
```

-----

## Publication Quality Figure

```{r}
x <- tibble(bg_2 = c(0,1))

preds_pub <- x |> 
  bind_cols(predict(m_d, x, se.fit = TRUE) |> 
  as_tibble())
```

```{r}
plot_pub <- ggplot() +
  geom_col(aes(x = as.factor(preds_pub$bg_2), y = preds_pub$fit, 
               fill = as.factor(preds_pub$bg_2)),
           alpha = .4, color = "black") +
  geom_jitter(aes(x = as.factor(data$bg_2), y = data$fps), width = .02, height = NULL) +
  geom_errorbar(aes(ymin = preds_pub$fit-preds_pub$se.fit, 
                    ymax = preds_pub$fit+preds_pub$se.fit, 
                    x = as.factor(preds_pub$bg_2)), width = .4) +
  scale_fill_manual(values = c("black", "light grey")) +
  scale_x_discrete(breaks = c(0, 1),
                   labels = c("No alcohol", "Alcohol")) +
  theme(legend.position = "none") +
  labs(x = "Group",
       y = "Fear-potentiated startle") 
```

-----

```{r}
#| fig-cap: "Bars display point estimates for fear potentiated startle by group from the general linear model. Confidence intervals display +/- 1 standard error for these point estimates."

plot_pub
```



