{
  "hash": "dc282d3201540ac2594776782755ec31",
  "result": {
    "engine": "knitr",
    "markdown": "---\noutput: html_document\neditor_options: \n  chunk_output_type: console\n---\n\n\n# Unit 13: Categorical Variables > 2 Levels \n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## Learning Objectives\n\n- Two categorical coding schemes to know:   \n  \n    1. Dummy coding (reference/control group).  \n    2. Contrast coding (POCs).   \n    \n- How best to test the comparisons coded by these methods if the comparisons are:   \n\n    1. Planned and non-orthogonal.   \n    2. Planned and orthogonal.   \n    3. Unplanned.\n\n- How to test effects and contrasts when covariates are included    \n- How to test main and simple effects when categorical variables have > 2 levels.   \n\n--------------------------------------------------------------------------------\n\nWe have handled categorical variables by recoding them using dummy codes or centered coefficients. \n\nThis turned categorical/nominal variables into numeric regressors \n\nHowever, so far, we have only handled categorical variables with 2 levels\n\n--------------------------------------------------------------------------------\n\nThese single $X$ regressors coded with dummy or contrast systems yielded one comparison of the mean of $Y$ across the two levels of the categorical variable.\n\nOnce we have more than two levels/groups within the categorical variable\n\n- We will need to recode the categorical variable into $N_{levels/groups}-1$ regressors ($X$s) that represent $N - 1$ comparisons/contrasts within the overall categorical variable.\n\n- Testing the **set** of regressors will allow us to test the overall effect of the categorical variable but we will often not care about this test. We are generally much more focused on planned or unplanned comparisons between the groups/levels.\n\n---------------------------------------------------------------------------------\n\n## Example\n\nExamine the differences in overall health among patients with alcohol use disorder, patients with depression, and healthy controls.   \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\noptions(conflicts.policy = \"depends.ok\") \nlibrary(tidyverse)\nlibrary(broom)\nlibrary(patchwork)\n\ntheme_set(theme_classic()) \npath_data <- \"data_lecture\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read_csv(here::here(path_data, \"13_three_groups.csv\"),\n                 show_col_types = FALSE) |> \n  mutate(group = fct(group, levels = c(\"alcohol\", \"depress\", \"healthy\")))\n\nslice_sample(data, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 3\n   subid group   health\n   <dbl> <fct>    <dbl>\n 1    68 healthy    7.4\n 2    48 depress    4.4\n 3    44 depress    5.9\n 4    19 alcohol    4.5\n 5    54 healthy    8.9\n 6    30 depress    6.9\n 7     4 alcohol    5  \n 8    11 alcohol    7  \n 9    21 alcohol    2  \n10    23 alcohol    3  \n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n::: {.callout-important}\n# Question  \nWhy can we not handle multi-level categorical variables by simply coding each group with a different consecutive value (e.g., alcohol = 1, depress = 2 , healthy = 3)?\n:::\n\n:::{.fragment}\n[There is no meaningful way to order the multiple groups. The shape of the relationship will completely change based on arbitrary ordering of the groups (exception is when categorical variable is ordinal).]{style=\"color:blue;\"}    \n\n[Moreover, we are often interested in individual pair-wise group comparisons that would be lost by forcing a linear relationship with only one parameter estimate.]{style=\"color:blue;\"}\n:::\n\n--------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](13_categorical_variables_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n## 3 Group Dummy Coding (Non-orthogonal)  \n\nWe will start by generalizing the dummy coding approach to more than 2 levels\n\n- Need 2 regressors (`alcohol_d3`, `depress_d3`) to represent a 3 level categorical variable.   \n- Regressor 1 is coded 1 for membership in Group 1 (alcohol) and 0 for all other group membership.\n- Regressor 2 is coded 1 for membership in Group 2 (depress) and 0 for all other group membership.\n- Reference group (healthy) is coded 0 for all regressors.\n\nThis yields the following dummy coding table for our example\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group   alcohol_d3 depress_d3\n  <chr>        <dbl>      <dbl>\n1 alcohol          1          0\n2 depress          0          1\n3 healthy          0          0\n```\n\n\n:::\n:::\n\n\n\n::: {.footer}\nWe are using `_d3` in these regressor names to indicate they are dummy codes with the third level as reference\n:::\n\n--------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble_d\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group   alcohol_d3 depress_d3\n  <chr>        <dbl>      <dbl>\n1 alcohol          1          0\n2 depress          0          1\n3 healthy          0          0\n```\n\n\n:::\n:::\n\n\n\nAnd here are the two new regressors for our data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  mutate(alcohol_d3 = if_else(group == \"alcohol\", 1, 0),\n         depress_d3 = if_else(group == \"depress\", 1, 0))\n\nslice_sample(data, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 5\n   subid group   health alcohol_d3 depress_d3\n   <dbl> <fct>    <dbl>      <dbl>      <dbl>\n 1    15 alcohol    6.3          1          0\n 2     8 alcohol    6            1          0\n 3    67 healthy    6.9          0          0\n 4    40 depress    5.4          0          1\n 5     1 alcohol    6            1          0\n 6    32 depress    7.4          0          1\n 7    37 depress    7.7          0          1\n 8    23 alcohol    3            1          0\n 9    21 alcohol    2            1          0\n10    44 depress    5.9          0          1\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nNow \n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_d3 <- lm(health ~ alcohol_d3 + depress_d3, data)\n\ntidy(m_d3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     7.94     0.400     19.9  5.38e-22\n2 alcohol_d3     -3.36     0.566     -5.95 6.13e- 7\n3 depress_d3     -1.5      0.566     -2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n## 3 Group Dummy: What do the parameter estimates test?  \n\nEach parameter estimate for the $X$s represents the contrast between the mean of $Y$ in its respective target group (the group that was coded 1 for that $X$) and the **reference** group. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble_d\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group   alcohol_d3 depress_d3\n  <chr>        <dbl>      <dbl>\n1 alcohol          1          0\n2 depress          0          1\n3 healthy          0          0\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(m_d3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     7.94     0.400     19.9  5.38e-22\n2 alcohol_d3     -3.36     0.566     -5.95 6.13e- 7\n3 depress_d3     -1.5      0.566     -2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\nHere is mean `health` among the three groups\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  group_by(group) |> \n  summarise(mean = mean(health))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  group    mean\n  <fct>   <dbl>\n1 alcohol  4.58\n2 depress  6.44\n3 healthy  7.94\n```\n\n\n:::\n:::\n\n\n\n- alcohol vs healthy = 4.58 - 7.94 = -3.36\n- depress vs. healthy = 6.44 - 7.94 = -1.50\n\n--------------------------------------------------------------------------------\n\nHere is a visualization of the dummy coded regressors that allows us to see why this system works to give us target vs. reference contrasts\n\n![](figures/dummy_3d.png)\n\nNOTE: We will later see a more mathematical way to support this intuition using decompositions\n\n--------------------------------------------------------------------------------\n\n## Dummy Coding Group Mean Estimates\n\n**The Prediction equation:**   \n\n- $\\hat{Y} = 7.94+-3.36*alcohol_{d3}+ - 1.50*depress_{d3}$     \n\n\nPatients with alcohol use disorder (coded 1, 0 across $X$s:    \n\n- $= 7.94 + -3.36*(1)+-1.50*(0)$   \n- $= 4.58$   \n\n\nPatients with depression (coded 0, 1):    \n\n- $= 7.94 + -3.36*(0)+-1.50*(1)$   \n- $= 6.44$   \n\n\nHealthy controls (coded 0, 0):    \n\n- $= 7.94 + -3.36*(0)+-1.50*(0)$   \n- $= 7.94$\n\n::: {.callout-important}\n# Question \nWhat is $b_0$ when using dummy codes?\n:::\n\n:::{.fragment}\n[The predicted value (mean) for the reference group.]{style=\"color:blue;\"}  \n:::\n\n--------------------------------------------------------------------------------\n\n## Dummy Coding Decompositions\n\n**The Prediction equation:**   \n\n- $\\hat{Y} = 7.94+-3.36*alcohol_{d3}+ - 1.50*depress_{d3}$     \n\nalcohol (1, 0) vs. healthy (0, 0) contrast:   \n\n- $= (b_0 + b_1*1 + b_2*0) - (b_0 + b_1*0 + b_2*0)$   \n- $= (b_0 + b_1) - (b_0)$   \n- $= b_1$   \n\ndepress (0, 1) vs. healthy (0, 0) contrast:   \n\n- $= (b_0 + b_1*0 + b_2*1) - (b_0 + b_1*0 + b_2*0)$   \n- $= (b_0 + b_2) - (b_0)$   \n- $= b_2$   \n \nalcohol (1, 0) vs. depress (0, 1) contrast:   \n\n- $= (b_0 + b_1*1 + b_2*0) - (b_0 + b_1*0 + b_2*1)$   \n- $= (b_0 + b_1) - (b_0 + b_2)$   \n- $= b_1 - b_2$   \n\n--------------------------------------------------------------------------------\n\n## Introducing Factors and Contrasts\n\nWe can (and often do) manually code our $X$s to represent categorical predictors.\n\nHowever, R can also handle this for us directly if we set up the categorical predictor as a factor and set contrasts for it.\n\n\nWe set up `group` as a factor and indicated its levels when we read in the data earlier\n\n- `mutate(group = fct(group, levels = c(\"alcohol\", \"depress\", \"healthy\")))`\n- We prefer to use `forcats::fct()` vs. base R `factor()`\n\n\nConfirm this\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(data$group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"factor\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(data$group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"alcohol\" \"depress\" \"healthy\"\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nBy default, R assigns what it calls treatment contrasts to unordered factors (the only type of factor I use). \n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(\"contrasts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$contrasts\n        unordered           ordered \n\"contr.treatment\"      \"contr.poly\" \n```\n\n\n:::\n:::\n\n\n\nTreatment contrasts are dummy contrasts!  \n\n- Default is to assign the first level as the reference group.\n- We may not want this\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(data$group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        depress healthy\nalcohol       0       0\ndepress       1       0\nhealthy       0       1\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nWe can (re)set the reference level or even change the contrast type (more on that in a moment) using `contrasts()` on the factor \n\nHere we continue to use treatment/dummy contrasts but change the reference level to the third level (healthy)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(data$group) <- contr.treatment(levels(data$group), base = 3)\n```\n:::\n\n\n\nLets confirm this\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(data$group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        alcohol depress\nalcohol       1       0\ndepress       0       1\nhealthy       0       0\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nInternally, R is now calculating the two dummy coded regressors for you when you use group as the predictor\n\n- This can be quicker/easier in some instances\n- It does hide some of what is going on (not great for understanding)\n- Results are, of course, the same!\n- You should be comfortable with both approaches\n- Use the approach (manually coding $X$s or contrasts on factor) that best suits your needs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_d3f <- lm(health ~ group, data = data)\ntidy(m_d3f)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      7.94     0.400     19.9  5.38e-22\n2 groupalcohol    -3.36     0.566     -5.95 6.13e- 7\n3 groupdepress    -1.5      0.566     -2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nIf you want to see the internal representation of the dummy coded regressors (and all other $X$s) for any model,  you can use `model.matrix()` with any linear model object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.matrix(m_d3f) |> \n  head(n = 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept) groupalcohol groupdepress\n1            1            1            0\n2            1            1            0\n3            1            1            0\n4            1            1            0\n5            1            1            0\n6            1            1            0\n7            1            1            0\n8            1            1            0\n9            1            1            0\n10           1            1            0\n11           1            1            0\n12           1            1            0\n13           1            1            0\n14           1            1            0\n15           1            0            1\n16           1            0            1\n17           1            0            1\n18           1            0            1\n19           1            0            1\n20           1            0            1\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important}\n# Question\nNotice the (Intercept) column.  Does this give you any insight into how to think about the $b_0$ parameter estimate in any model?\n:::\n\n:::{.fragment}\n$b_0$ is just like the other parameter estimates. It is a coefficient that gets multipled by an $X$.  However, the intercept $X$ is just a column of 1!\n:::\n\n--------------------------------------------------------------------------------\n\nNow lets continue to expand our understanding of these tests of the two dummy contrasts\n\n::: {.callout-important}\n# Question \nHow are these t-tests of $b_j$ in the linear model different from what you would get if you simply ran two separate between groups t-tests?\n:::\n\n:::{.fragment}\n[The linear model t-tests of $b_j$ use the full error term including all subjects (including the “ignored” group; see dfs below). This yields a more powerful and therefore preferred test.]{style=\"color:blue;\"}     \n\n--------------------------------------------------------------------------------\n\nThe linear model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(m_d3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     7.94     0.400     19.9  5.38e-22\n2 alcohol_d3     -3.36     0.566     -5.95 6.13e- 7\n3 depress_d3     -1.5      0.566     -2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\nThe df for testing the paramemeter estimates is $N-P$ (42 - 3) = 39\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_d3$df.residual\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 39\n```\n\n\n:::\n:::\n\n\n\nThe between groups/subject t-test for alcohol vs. healthy\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  filter(group != \"depress\") |> \n  t.test(health ~ group, var.equal = TRUE,\n         data = _)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  health by group\nt = -5.6296, df = 26, p-value = 0.000006434\nalternative hypothesis: true difference in means between group alcohol and group healthy is not equal to 0\n95 percent confidence interval:\n -4.592679 -2.135892\nsample estimates:\nmean in group alcohol mean in group healthy \n             4.578571              7.942857 \n```\n\n\n:::\n:::\n\n\n\nNOTE: use of `_` to pipe the object from `filter()` into a later argument in`t.test()`\n:::\n\n--------------------------------------------------------------------------------\n\n::: {.callout-important}\n# Question \nWhat may be missing from our analysis of the `group` variable at this point and how could we get it?\n:::\n\n:::{.fragment}\n[We might want a test of the contrast between patients with alcohol use disorder vs. patients with depression.]{style=\"color:blue;\"}    \n\n[Recode the group contrasts such that the patients with depression is the reference group. Then test and interpret the alcohol vs. depress parameter estimate.]{style=\"color:blue;\"}    \n:::\n\n--------------------------------------------------------------------------------\n\nWe could do this using `contr.treatment()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(data$group) <- contr.treatment(levels(data$group), base = 2)\ncontrasts(data$group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        alcohol healthy\nalcohol       1       0\ndepress       0       0\nhealthy       0       1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm_d2f <- lm(health ~ group, data = data)\ntidy(m_d2f)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      6.44     0.400     16.1  7.90e-19\n2 groupalcohol    -1.86     0.566     -3.30 2.10e- 3\n3 grouphealthy     1.5      0.566      2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nOr we could do this by manually calculating two new dummy coded $X$s using depress as the level that is set to zero for both $X$s (using `_d2` in the names to indicate set using level 2 as reference)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  mutate(alcohol_d2 = if_else(group == \"alcohol\", 1, 0),\n         healthy_d2 = if_else(group == \"healthy\", 1, 0))\n\nslice_sample(data, n = 10) |> \n  select(-subid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 6\n   group   health alcohol_d3 depress_d3 alcohol_d2 healthy_d2\n   <fct>    <dbl>      <dbl>      <dbl>      <dbl>      <dbl>\n 1 alcohol    6.3          1          0          1          0\n 2 alcohol    1            1          0          1          0\n 3 alcohol    5.5          1          0          1          0\n 4 alcohol    6            1          0          1          0\n 5 depress    8.4          0          1          0          0\n 6 healthy    7.9          0          0          0          1\n 7 depress    6.4          0          1          0          0\n 8 alcohol    5            1          0          1          0\n 9 healthy    9.9          0          0          0          1\n10 alcohol    3            1          0          1          0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm_d2 <- lm(health ~ alcohol_d2 + healthy_d2, data)\ntidy(m_d2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     6.44     0.400     16.1  7.90e-19\n2 alcohol_d2     -1.86     0.566     -3.30 2.10e- 3\n3 healthy_d2      1.5      0.566      2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nRemember that these are the group means\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  group_by(group) |> \n  summarise(mean = mean(health))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  group    mean\n  <fct>   <dbl>\n1 alcohol  4.58\n2 depress  6.44\n3 healthy  7.94\n```\n\n\n:::\n:::\n\n\n\nAnd here are the parameter estimates from the model with healthy as reference\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(m_d3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     7.94     0.400     19.9  5.38e-22\n2 alcohol_d3     -3.36     0.566     -5.95 6.13e- 7\n3 depress_d3     -1.5      0.566     -2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\n\nAnd the parameter estimates from the model with depressed as reference\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(m_d2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     6.44     0.400     16.1  7.90e-19\n2 alcohol_d2     -1.86     0.566     -3.30 2.10e- 3\n3 healthy_d2      1.5      0.566      2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important}\nDo the differences in all the parameter estimates across these two models make sense to you?\n:::\n\n--------------------------------------------------------------------------------\n\n::: {.callout-important}\n# Question \nWhat does the 2 df F-test of $R^2$ test conceptually?\n:::\n\n:::{.fragment}\n[In this special case (with only one categorical predictor represented by multiple $X$s), it provides a test of the main effect of group.]{style=\"color:blue;\"}          \n\n[A significant main effect means that at least 1 contrast in one set of all possible sets of orthogonal contrasts is significant.]{style=\"color:blue;\"}         \n\n[It is not generally very useful. Tradition is still to report it (unless using POCs) but likely for wrong reasons (more in this later).]{style=\"color:blue;\"}\n:::\n\n--------------------------------------------------------------------------------\n\n::: {.callout-important}\n# Question \nWhy will model $R^2$ not test the main effect if there are regressors for other predictors in the model?\n:::\n\n:::{.fragment}\n[Model $R^2$ is the variance in $Y$ explained by all the regressors in the model. It will only test the main effect of a categorical predictor if only regressors for that categorical predictor are in the model.]{style=\"color:blue;\"}\n\n[We will return in a bit to testing `group` effect with other $X$s in the model]{style=\"color:blue;\"}\n:::\n\n--------------------------------------------------------------------------------\n\nHow do you get $R^2$ and its test for our model?\n\n- You can get the value for $R^2$ using `glance` as always\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(m_d3)$r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4765908\n```\n\n\n:::\n:::\n\n\n\nTo test the null hypothesis for $R^2$ (i.e., the combined effect of the two dummy coded regressors in this example) you can do a model comparison\n\n-  Augmented model is full model with both dummy regressors\n-  Compact model is mean only model (parameter estimates for both $X$s set to 0)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(lm(health ~ 1, data = data), m_d3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: health ~ 1\nModel 2: health ~ alcohol_d3 + depress_d3\n  Res.Df     RSS Df Sum of Sq      F      Pr(>F)    \n1     41 166.891                                    \n2     39  87.352  2    79.539 17.756 0.000003292 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nWe can also get variance based effect sizes for each contrast (and this is likely more important than the overall `group` effect)\n\nWhen we set healthy as the reference, we had contrasts for \n\n- alcohol vs. healthy (`alcohol_d3`)\n- depress vs. healthy (`depress_d3`)\n\nWe can first set up our functions for $\\Delta R^2$ (or for PRE if you prefer - not shown here)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2 <- function(compact, augmented) {\n  broom::glance(augmented)$r.squared - broom::glance(compact)$r.squared\n}\n```\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n$\\Delta R^2$ for alcohol vs. healthy (compact model includes only the depress vs. healthy contrast)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ depress_d3, data = data), m_d3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4747354\n```\n\n\n:::\n:::\n\n\n\n$\\Delta R^2$ for depress vs. healthy (compact model includes only the alcohol vs. healthy contrast)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ alcohol_d3, data = data), m_d3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.09437314\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n## Testing Overall Effect with Other Xs in Model\n\nYou can use the model comparison approach to get the test of the main effect of `group` even when $X$s for other predictors (e.g., covariates) are included in the model (such that $R^2$ is no longer a test of the `group` effect only)\n\nLets add a covariate to the dataset and the model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  mutate(age = rnorm(nrow(data), 50, 10))\n\nm_d3_cov <- lm(health ~ alcohol_d3 + depress_d3 + age, data = data)\n\ntidy(m_d3_cov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  term        estimate std.error statistic     p.value\n  <chr>          <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)  7.89       1.29      6.11   0.000000403\n2 alcohol_d3  -3.36       0.580    -5.79   0.00000110 \n3 depress_d3  -1.51       0.585    -2.57   0.0141     \n4 age          0.00109    0.0243    0.0448 0.964      \n```\n\n\n:::\n:::\n\n\n\nRemember that the $R^2$ for this model is not a test of the main effect of `group` but instead it is the combined effect of `group` and `age`\n\n--------------------------------------------------------------------------------\n\n:::{.callout-important}\n# Question\nWhat model comparison will get you the test of the main effect of `group`?\n:::\n\n:::{.fragment}\n[You will compare the full model with `group` and `age` to the compact model with only `age`.]{style=\"color:blue;\"}\n\n- Compact: $health ~ b_0 + 0*alcohol_{d3} + 0* depress_{d3} + b_3*age$\n- Augmented: $health ~ b_0 + b_1*alcohol_{d3} + b_2*depress_{d3} + b_3*age$\n\nThis is an F test with 2 df ($P_a - P_c$) in the numerator and 38 ($N-P_a$) in the denominator\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(lm(health ~ age, data = data), m_d3_cov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: health ~ age\nModel 2: health ~ alcohol_d3 + depress_d3 + age\n  Res.Df     RSS Df Sum of Sq      F      Pr(>F)    \n1     40 164.415                                    \n2     38  87.348  2    77.067 16.764 0.000006038 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n:::\n\n--------------------------------------------------------------------------------\n\nAnd we can do model comparisons to get $\\Delta R^2$ for the full `group` effect or the contrasts within `group`\n\n$\\Delta R^2$ for the full `group` effect\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ age, data = data), m_d3_cov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4617815\n```\n\n\n:::\n:::\n\n\n\n$\\Delta R^2$ for alcohol vs. healthy (compact model includes the depress vs. healthy contrast AND age)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ depress_d3 + age, data = data), m_d3_cov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4617473\n```\n\n\n:::\n:::\n\n\n\n$\\Delta R^2$ for depress vs. healthy (compact model includes the alcohol vs. healthy contrast AND age)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ alcohol_d3 + age, data = data), m_d3_cov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.09124153\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n## Planned Orthogonal Contrasts\n\nThe second coding option for regressors for categorical predictors yields planned orthogonal contrasts (POCs).   \n\nPlanned orthogonal contrasts allow you to:    \n\n1. Parse IV variance into its components (more on this later).\n2. Test for contrasts other than pairwise.\n\n--------------------------------------------------------------------------------\n\nYou might have contrasts that interest you that don't all use one reference group.  For example:\n\n- You predict that psychopathology will reduce overall health. \n- And you also think that the type of psychopathology matters (AUD is worse than depression)\n\nYou can set up contrasts that test these two comparisons\n\n**for conceptual understanding:**\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group    c1_a  c2_a\n  <chr>   <dbl> <dbl>\n1 alcohol   0.5     1\n2 depress   0.5    -1\n3 healthy  -1       0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group    c1_a  c2_a\n  <chr>   <dbl> <dbl>\n1 alcohol   0.5     1\n2 depress   0.5    -1\n3 healthy  -1       0\n```\n\n\n:::\n:::\n\n\n\n**A common alternative (whole numbers):**\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group    c1_b  c2_b\n  <chr>   <dbl> <dbl>\n1 alcohol     1     1\n2 depress     1    -1\n3 healthy    -2     0\n```\n\n\n:::\n:::\n\n\n\n**John's preference (unit weighted):**\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group     c1_c  c2_c\n  <chr>    <dbl> <dbl>\n1 alcohol  0.333   0.5\n2 depress  0.333  -0.5\n3 healthy -0.667   0  \n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc_a\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group    c1_a  c2_a\n  <chr>   <dbl> <dbl>\n1 alcohol   0.5     1\n2 depress   0.5    -1\n3 healthy  -1       0\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important}\n# Question \nAll of these options (first displayed above) represent two conceptual comparisons. What are these two comparisons?\n:::\n\n:::{.fragment}\n[`c1` compares a combined group of patients with alcohol use disorder and depression to healthy controls.]{style=\"color:blue;\"}       \n\n[`c2` compares patients with alcohol use disorder to patients with depression.]{style=\"color:blue;\"}\n:::\n\n-------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group    c1_a  c2_a\n  <chr>   <dbl> <dbl>\n1 alcohol   0.5     1\n2 depress   0.5    -1\n3 healthy  -1       0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group    c1_b  c2_b\n  <chr>   <dbl> <dbl>\n1 alcohol     1     1\n2 depress     1    -1\n3 healthy    -2     0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group     c1_c  c2_c\n  <chr>    <dbl> <dbl>\n1 alcohol  0.333   0.5\n2 depress  0.333  -0.5\n3 healthy -0.667   0  \n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important}\n# Question\nHow will the analyses be similar and different across these three contrasts?\n:::\n\n:::{.fragment}\n[The parameter estimates for `c1` and `c2` will be different across the three coding options. However, the statistical test of the null for each parameter will be identical (t/F and p-value). This should not be surprising given that the contrasts in each `c1` option are simply a linear transformation of the other. It is simply a change of scale similar to multiplying a quantitative variable by some constant.]{style=\"color:blue;\"}       \n \n[The model $R^2$ and the test of the null will be identical.]{style=\"color:blue;\"} \n:::\n\n--------------------------------------------------------------------------------\n\nPut all three options for regressors into the data set\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  mutate(c1_a = case_match(group,\n                           \"alcohol\" ~ 0.5,\n                           \"depress\" ~ 0.5,\n                           \"healthy\" ~ -1),\n         c2_a = case_match(group,\n                           \"alcohol\" ~ 1,\n                           \"depress\" ~ -1,\n                           \"healthy\" ~ 0),\n         c1_b = case_match(group,\n                           \"alcohol\" ~ 1,\n                           \"depress\" ~ 1,\n                           \"healthy\" ~ -2),\n         c2_b = case_match(group,\n                           \"alcohol\" ~ 1,\n                           \"depress\" ~ -1,\n                           \"healthy\" ~ 0),\n         c1_c = case_match(group,\n                           \"alcohol\" ~ 0.333,\n                           \"depress\" ~ 0.333,\n                           \"healthy\" ~ -.667),\n         c2_c = case_match(group,\n                           \"alcohol\" ~ .5,\n                           \"depress\" ~ -.5,\n                           \"healthy\" ~ 0))\n```\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  select(-contains(\"d\")) |> \n  slice_sample(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 9\n   group   health   age  c1_a  c2_a  c1_b  c2_b   c1_c  c2_c\n   <fct>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>\n 1 healthy    5.9  62.0  -1       0    -2     0 -0.667   0  \n 2 healthy    8.9  50.8  -1       0    -2     0 -0.667   0  \n 3 depress    4.4  66.0   0.5    -1     1    -1  0.333  -0.5\n 4 depress    4.9  39.1   0.5    -1     1    -1  0.333  -0.5\n 5 alcohol    3    40.1   0.5     1     1     1  0.333   0.5\n 6 alcohol    3    42.0   0.5     1     1     1  0.333   0.5\n 7 healthy    7.9  54.7  -1       0    -2     0 -0.667   0  \n 8 healthy    8.9  76.5  -1       0    -2     0 -0.667   0  \n 9 healthy    9.2  42.2  -1       0    -2     0 -0.667   0  \n10 healthy    8.9  53.6  -1       0    -2     0 -0.667   0  \n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nFit models with all three options\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_c_a <- lm(health ~ c1_a + c2_a, data = data)\nm_c_b <- lm(health ~ c1_b + c2_b, data = data)\nm_c_c <- lm(health ~ c1_c + c2_c, data = data)\n```\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nHere are results\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(m_c_a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    6.32      0.231     27.4  4.51e-27\n2 c1_a          -1.62      0.327     -4.96 1.40e- 5\n3 c2_a          -0.932     0.283     -3.30 2.10e- 3\n```\n\n\n:::\n\n```{.r .cell-code}\ntidy(m_c_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    6.32      0.231     27.4  4.51e-27\n2 c1_b          -0.811     0.163     -4.96 1.40e- 5\n3 c2_b          -0.932     0.283     -3.30 2.10e- 3\n```\n\n\n:::\n\n```{.r .cell-code}\ntidy(m_c_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     6.32     0.231     27.4  4.53e-27\n2 c1_c           -2.43     0.490     -4.96 1.40e- 5\n3 c2_c           -1.86     0.566     -3.30 2.10e- 3\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group    c1_a  c2_a\n  <chr>   <dbl> <dbl>\n1 alcohol   0.5     1\n2 depress   0.5    -1\n3 healthy  -1       0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group    c1_b  c2_b\n  <chr>   <dbl> <dbl>\n1 alcohol     1     1\n2 depress     1    -1\n3 healthy    -2     0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group     c1_c  c2_c\n  <chr>    <dbl> <dbl>\n1 alcohol  0.333   0.5\n2 depress  0.333  -0.5\n3 healthy -0.667   0  \n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important}\n# Question\nWhy are the parameter estimates for `c1` different and why do we prefer option c?\n:::\n\n:::{.fragment}\n[In each instance $b_1$ represents change in health for a 1 unit change on the `c1` regressor. For `c1_c` a 1 unit change moves fully from the alcohol/depress group to the healthy group. In contrast, $b_1$ was 2/3 the size for `c1_a` because 1 unit only moves 2/3 of the way between the two sets in the `c1_a` contrast.]{style=\"color:blue;\"}        \n:::\n\n--------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  Group     c1_c  c2_c\n  <chr>    <dbl> <dbl>\n1 alcohol  0.333   0.5\n2 depress  0.333  -0.5\n3 healthy -0.667   0  \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(m_c_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     6.32     0.231     27.4  4.53e-27\n2 c1_c           -2.43     0.490     -4.96 1.40e- 5\n3 c2_c           -1.86     0.566     -3.30 2.10e- 3\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  group_by(group) |> \n  summarise(mean = mean(health))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  group    mean\n  <fct>   <dbl>\n1 alcohol  4.58\n2 depress  6.44\n3 healthy  7.94\n```\n\n\n:::\n:::\n\n\n\nYou can do the math to confirm that $b_1$ and $b_2$ match the mean differences associated with the `c1` and `c2` comparisons.  \n\n--------------------------------------------------------------------------------\n\n## How to Calculate Unit Weights\n\nWe can write any comparison in terms of coefficients multiplied by group means for all groups in the following form:    \n\n$C = \\text{set U} - \\text{set V}$   \n\n$C = (c_1*group_1 + c_2*group_2 + ...)-(c_3*group_3+c_4*group_4 + ...)$   \n\n- You can think of this as a contrast between two sets of the groups/levels.   \n- Call them set U (with u groups included) and set V (with v groups included).\n- A third set can be ignored by assigning coefficients of 0.\n\n--------------------------------------------------------------------------------\n\n$C = \\text{set U} - \\text{set V}$   \n\n$C = (c_1*group_1 + c_2*group_2 + ...)-(c_3*group_3+c_4*group_4 + ...)$   \n\nThe coefficients in set U should all be: $\\frac{v}{(u + v)}$.   \n\nThe coefficients in set V should all be: $\\frac{u}{(u + v)}$.   \n\nThe coefficients in the ignored set should all be 0.\n\n--------------------------------------------------------------------------------\n\n::: {.callout-important}\n# Question\nHow would you describe `c1` (patient groups vs. healthy controls) and `c2` (patients with alcohol use disorder vs. depression) in terms of Set U and Set V?   And what coefficients would you assign?\n:::\n\n:::{.fragment}\n[Patient groups vs. healthy controls]{style=\"color:blue;\"}\n\n- [Set U: `alcohol`, `depress`; Set V: `healthy`]{style=\"color:blue;\"}         \n- [u = 2; v = 1]{style=\"color:blue;\"}\n\n$Contrast_1 = (c_1*alcohol + c_2*depress)-(c_3*healthy)$    \n$Contrast_1 = (\\frac{v}{(u + v)}*alcohol + \\frac{v}{(u + v)}*depress)-(\\frac{u}{(u + v)}*healthy)$    \n$Contrast_1 = (.333*alcohol + .333*depress)-(.667*healthy)$    \n\n\n[Alcohol vs. depress]{style=\"color:blue;\"}\n\n- [Set U: `alcohol`; Set V: `depress`; Ignored: `healthy`]{style=\"color:blue;\"}         \n- [u = 1; v = 1]{style=\"color:blue;\"}\n\n$Contrast_2 = (c_1*alcohol)-(c_2*depress)$     \n$Contrast_2 = (\\frac{v}{(u + v)}*alcohol)-(\\frac{u}{(u + v)}*depress) + (0* healthy)$    \n$Contrast_2 = (.5*alcohol)-(.5*depress) + (0* healthy)$    \n:::\n\n--------------------------------------------------------------------------------\n\nFor the factor contrasts approach\n\n- We can set these contrasts up as a matrix (and name the contrasts)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nour_contrasts <- matrix(c(.333, .333, -.667,\n                            .5,  -.5, 0), \n                        ncol = 2,\n                        dimnames = list(c(\"alcohol\", \"depress\", \"healthy\"),\n                                        c(\"patient_v_healthy\", \"alcohol_v_depress\")))\n\nour_contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        patient_v_healthy alcohol_v_depress\nalcohol             0.333               0.5\ndepress             0.333              -0.5\nhealthy            -0.667               0.0\n```\n\n\n:::\n:::\n\n\n\n- And then assign them to the contrasts for the factor\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(data$group) <- our_contrasts\n```\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nFor the manual approach\n\n- We can code them into our dataframe directly as before\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  select(-age, -contains(\"_d\"), -starts_with(\"c\")) |> # removing other group  regressors\n  mutate(patient_v_control = case_match(group,\n                           \"alcohol\" ~ 0.333,\n                           \"depress\" ~ 0.333,\n                           \"healthy\" ~ -.667),\n         alcohol_v_depress = case_match(group,\n                           \"alcohol\" ~ .5,\n                           \"depress\" ~ -.5,\n                           \"healthy\" ~ 0))\n```\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nLets see them!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  slice_sample(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 5\n   subid group   health patient_v_control alcohol_v_depress\n   <dbl> <fct>    <dbl>             <dbl>             <dbl>\n 1     1 alcohol    6               0.333               0.5\n 2    30 depress    6.9             0.333              -0.5\n 3    21 alcohol    2               0.333               0.5\n 4    45 depress    5.9             0.333              -0.5\n 5    37 depress    7.7             0.333              -0.5\n 6    72 healthy    6.4            -0.667               0  \n 7    12 alcohol    6.3             0.333               0.5\n 8    62 healthy    9.2            -0.667               0  \n 9    26 depress    7.4             0.333              -0.5\n10    71 healthy    5.9            -0.667               0  \n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nOf course, they yield the same results\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_poc_f <- lm(health ~ group, data = data)\ntidy(m_poc_f)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term                   estimate std.error statistic  p.value\n  <chr>                     <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)                6.32     0.231     27.4  4.53e-27\n2 grouppatient_v_healthy    -2.43     0.490     -4.96 1.40e- 5\n3 groupalcohol_v_depress    -1.86     0.566     -3.30 2.10e- 3\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm_poc <- lm(health ~ patient_v_control + alcohol_v_depress, data = data)\ntidy(m_poc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term              estimate std.error statistic  p.value\n  <chr>                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)           6.32     0.231     27.4  4.53e-27\n2 patient_v_control    -2.43     0.490     -4.96 1.40e- 5\n3 alcohol_v_depress    -1.86     0.566     -3.30 2.10e- 3\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(m_poc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term              estimate std.error statistic  p.value\n  <chr>                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)           6.32     0.231     27.4  4.53e-27\n2 patient_v_control    -2.43     0.490     -4.96 1.40e- 5\n3 alcohol_v_depress    -1.86     0.566     -3.30 2.10e- 3\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important}\n# Question \nWhat does each of the $b_j$s test?\n:::\n\n:::{.fragment}\n[Each test whether the contrast that we specified is 0 or not. More specifically, how likely would it be to get our sample $b_j$ if $\\beta_j = 0$ for each of these two contrasts.]{style=\"color:blue;\"}\n:::\n\n--------------------------------------------------------------------------------\n\n::: {.callout-important}\n# Question\nWhat does the 2 df F-test of $R^2$ test conceptually?\n:::\n\n:::{.fragment}\n[It provides a test of the main effect of `group`; same as before with dummy coded regressors. Any unique coding system using 2 regressors for three groups will work for the main effect.]{style=\"color:blue;\"}        \n\n[As before, you don’t want to use model $R^2$ for the main effect in any model other than one way ANOVA.]{style=\"color:blue;\"}\n\n[Use `anova()` function to test model contrast between full model and mean-only model.]{style=\"color:blue;\"}    \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(m_poc)$r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4765908\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(lm(health ~ 1, data = data), m_poc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: health ~ 1\nModel 2: health ~ patient_v_control + alcohol_v_depress\n  Res.Df     RSS Df Sum of Sq      F      Pr(>F)    \n1     41 166.891                                    \n2     39  87.352  2    79.539 17.756 0.000003292 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n:::\n\n--------------------------------------------------------------------------------\n\n## POC Contrast Coding: Common Contrasts\n\n**3 group contrasts**   \n\n- $Contrast_1: \\frac{(group_1 + group_2)}{2} \\text{ vs. } group_3$    \n- $Contrast_2: group_1 \\text{ vs. }  group_2$\n\nAnd here is the matrix to use for coding or to assign to factor with `contrasts()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups3 <- matrix(c(.333, .333, -.667,\n                    .5, -.5, 0), \n                  ncol = 2,\n                  dimnames = list(c(\"group1\", \"group2\", \"group3\"),\n                                  c(\"g12v3\", \"g1v2\")))\ngroups3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        g12v3 g1v2\ngroup1  0.333  0.5\ngroup2  0.333 -0.5\ngroup3 -0.667  0.0\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n**4 group contrasts: Option 1**   \n\n- $Contrast_1: \\frac{(group_1 + group_2 +group_3)}{3} \\text{ vs. } group_4$    \n- $Contrast_2: \\frac{(group_1 + group_2)}{2} \\text{ vs. } group_3$     \n- $Contrast_3: group_1 \\text{ vs. } group_2$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups4_a <- matrix(c(.25, .25, .25, -.75,\n                      .333, .333, -.667, 0,\n                      .5, -.5, 0, 0), \n                    ncol = 3,\n                    dimnames = list(c(\"group1\", \"group2\", \"group3\", \"group4\"),\n                                    c(\"g123v4\", \"g12v3\", \"g1v2\")))\ngroups4_a\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       g123v4  g12v3 g1v2\ngroup1   0.25  0.333  0.5\ngroup2   0.25  0.333 -0.5\ngroup3   0.25 -0.667  0.0\ngroup4  -0.75  0.000  0.0\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n**4 group contrasts: Option 2**   \n\n- $Contrast_1: \\frac{(group_1 + group_2)}{2} \\text{ vs. } + \\frac{(group_3 + group_4)}{2}$    \n- $Contrast_2: group_1 \\text{ vs. }  group_2$\n- $Contrast_3: group_3 \\text{ vs. }  group_4$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups4_b <- matrix(c(.5, .5, -.5, -.5,\n                      .5, -.5, 0, 0,\n                       0, 0, .5, -.5), \n                    ncol = 3,\n                    dimnames = list(c(\"group1\", \"group2\", \"group3\", \"group4\"),\n                                    c(\"g12v34\", \"g1v2\", \"g3v4\")))\ngroups4_b\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       g12v34 g1v2 g3v4\ngroup1    0.5  0.5  0.0\ngroup2    0.5 -0.5  0.0\ngroup3   -0.5  0.0  0.5\ngroup4   -0.5  0.0 -0.5\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n**4 group contrasts: polynomials**   \n\n- Linear\n- Quadratic\n- Cubic\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups4_poly <- matrix(c(-3, -1, 1, 3,\n                      1, -1, -1, 1,\n                      -1, 3, -3, 1), \n                    ncol = 3,\n                    dimnames = list(c(\"group1\", \"group2\", \"group3\", \"group4\"),\n                                    c(\"linear\", \"quadratic\", \"cubic\")))\ngroups4_poly\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       linear quadratic cubic\ngroup1     -3         1    -1\ngroup2     -1        -1     3\ngroup3      1        -1    -3\ngroup4      3         1     1\n```\n\n\n:::\n:::\n\n\n\nNOTE: Not unit weighted \n\n--------------------------------------------------------------------------------\n\n## Display: Group Means + SEM\n\nYou will often see group means with standard error of the mean (SEM) in figures.\n\nThese SEMs are calculated as the standard deviation of the group divided by the square root of the number of subjects in the group.\n\nThey do NOT use all the data for these SEMs.  We don't recommend this approach\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  group_by(group) |> \n  summarise(mean = mean(health),\n            se = sd(health)/sqrt(n())) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  group    mean    se\n  <fct>   <dbl> <dbl>\n1 alcohol  4.58 0.484\n2 depress  6.44 0.350\n3 healthy  7.94 0.350\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata |> \n  group_by(group) |> \n  summarise(mean = mean(health),\n            se = sd(health)/sqrt(n())) |> \n  ggplot(aes(x = group, y = mean)) +\n  geom_col(color = \"black\", fill = \"light grey\") +\n  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2) +\n  labs(y = \"Health\", x = NULL)\n```\n\n::: {.cell-output-display}\n![](13_categorical_variables_files/figure-revealjs/unnamed-chunk-66-1.png){width=960}\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n## Dummy Coding Group Mean Estimates\n\n::: {.callout-important}\n# Question\nHow can we get standard errors for the group mean point estimates that use ALL the observations using the linear model parameters?\n:::\n\n:::{.fragment}\n[Fit three separate models. Set a different group as the reference group in each model. $b_0$ will be the predicted mean for the reference group in each model. The standard error for $b_0$ is the standard error for this parameter.]{style=\"color:blue;\"}    \n:::\n\n--------------------------------------------------------------------------------\n\nThese standard errors are the standard errors you should graph! But there is an easier way to get these.\n\n- Alcohol\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(data$group) <- contr.treatment(levels(data$group), base = 1)\nlm(health ~ group, data = data) |> \n  tidy() \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      4.58     0.400     11.4  4.87e-14\n2 groupdepress     1.86     0.566      3.30 2.10e- 3\n3 grouphealthy     3.36     0.566      5.95 6.13e- 7\n```\n\n\n:::\n:::\n\n\n\n- Depress\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(data$group) <- contr.treatment(levels(data$group), base = 2)\nlm(health ~ group, data = data) |>  \n  tidy() \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      6.44     0.400     16.1  7.90e-19\n2 groupalcohol    -1.86     0.566     -3.30 2.10e- 3\n3 grouphealthy     1.5      0.566      2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\n- Healthy controls\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(data$group) <- contr.treatment(levels(data$group), base = 3)\nlm(health ~ group, data = data) |>  \n  tidy() \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      7.94     0.400     19.9  5.38e-22\n2 groupalcohol    -3.36     0.566     -5.95 6.13e- 7\n3 groupdepress    -1.5      0.566     -2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nUsing `predict()`\n\n- fit model (with any coding scheme)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(data$group) <- contr.treatment(levels(data$group), base = 3)\nm_3 <- lm(health ~ group, data = data)\n```\n:::\n\n\n\n\n- make a dataframe for predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- tibble(group = levels(data$group))\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 1\n  group  \n  <chr>  \n1 alcohol\n2 depress\n3 healthy\n```\n\n\n:::\n:::\n\n\n\n- add predictions and se\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- predict(m_3, newdata = x, se.fit = TRUE) |> \n  as_tibble() |> \n  mutate(upr = fit + se.fit,\n         lwr = fit - se.fit) |> \n  select(-df, -residual.scale) |> \n  bind_cols(x)\n\npreds\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n    fit se.fit   upr   lwr group  \n  <dbl>  <dbl> <dbl> <dbl> <chr>  \n1  4.58  0.400  4.98  4.18 alcohol\n2  6.44  0.400  6.84  6.04 depress\n3  7.94  0.400  8.34  7.54 healthy\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n- And now plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds |> \n  ggplot(aes(x = group, y = fit)) +\n  geom_col(color = \"black\", fill = \"light grey\") +\n  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +\n  labs(y = \"Health\", x = NULL)\n```\n\n::: {.cell-output-display}\n![](13_categorical_variables_files/figure-revealjs/unnamed-chunk-73-1.png){width=960}\n:::\n:::\n\n\n\nNOTE: You could also add raw data or residualized data if you like\n\n--------------------------------------------------------------------------------\n\n## Parsing Variance: Dummy Codes\n\nDummy-coded regressors are NOT orthogonal\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata <- data |> \n  select(-contains(\"_v_\")) |> \n  mutate(alcohol_d3 = if_else(group == \"alcohol\", 1, 0),\n         depress_d3 = if_else(group == \"depress\", 1, 0))\n\ndata |> \n  slice_sample(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 5\n   subid group   health alcohol_d3 depress_d3\n   <dbl> <fct>    <dbl>      <dbl>      <dbl>\n 1    69 healthy    7.4          0          0\n 2    47 depress    4.4          0          1\n 3    32 depress    7.4          0          1\n 4    19 alcohol    4.5          1          0\n 5    53 healthy    8.4          0          0\n 6    50 healthy    8.9          0          0\n 7    36 depress    7.7          0          1\n 8    21 alcohol    2            1          0\n 9    24 alcohol    3.5          1          0\n10    37 depress    7.7          0          1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(data$alcohol_d3, data$depress_d3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.5\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important}\n# Question\nWhat are the implications of this for the relationship between the total effect of `group` (i.e., $R^2$ in this model) vs. the sum of the $\\Delta R^2$ for the two contrasts?\n:::\n\n:::{.fragment}\n[The $\\Delta R^2$ for the two contrasts will not sum to the model $R^2$.]{style=\"color:blue;\"}\n\n::::{.callout-important}\n# Question\nDo you have any intuition about whether they will sum to more or less?\n::::\n:::\n\n--------------------------------------------------------------------------------\n\nDummy codes w/ healthy as reference\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npreds |> \n  ggplot(aes(x = group, y = fit)) +\n  geom_col(color = \"black\", fill = \"light grey\") +\n  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +\n  labs(y = \"Health\", x = NULL)\n```\n\n::: {.cell-output-display}\n![](13_categorical_variables_files/figure-revealjs/unnamed-chunk-76-1.png){width=960}\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\ndata <- data |> \n  mutate(d1_3 = if_else(group == \"alcohol\", 1, 0),\n         d2_3 = if_else(group == \"depress\", 1, 0))\n\nm_3 <- lm(health ~ d1_3 + d2_3, data = data)\n```\n:::\n\n\n\n- Model $R^2$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(m_3)$r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4765908\n```\n\n\n:::\n:::\n\n\n\n- $\\Delta R^2$ for alcohol vs. healthy\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ d2_3, data = data), m_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4747354\n```\n\n\n:::\n:::\n\n\n\n- $\\Delta R^2$ for depress vs. healthy\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ d1_3, data = data), m_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.09437314\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nDummy codes w/ depress as reference\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npreds |> \n  ggplot(aes(x = group, y = fit)) +\n  geom_col(color = \"black\", fill = \"light grey\") +\n  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +\n  labs(y = \"Health\", x = NULL)\n```\n\n::: {.cell-output-display}\n![](13_categorical_variables_files/figure-revealjs/unnamed-chunk-80-1.png){width=960}\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\ndata <- data |> \n  mutate(d1_2 = if_else(group == \"alcohol\", 1, 0),\n         d2_2 = if_else(group == \"healthy\", 1, 0))\n\nm_2 <- lm(health ~ d1_2 + d2_2, data = data)\n```\n:::\n\n\n\n- Model $R^2$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(m_2)$r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4765908\n```\n\n\n:::\n:::\n\n\n\n- $\\Delta R^2$ for alcohol vs. depress\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ d2_2, data = data), m_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1457776\n```\n\n\n:::\n:::\n\n\n\n- $\\Delta R^2$ for healthy vs. depress\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ d1_2, data = data), m_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.09437314\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\nDummy codes w/ alchol as reference\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npreds |> \n  ggplot(aes(x = group, y = fit)) +\n  geom_col(color = \"black\", fill = \"light grey\") +\n  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +\n  labs(y = \"Health\", x = NULL)\n```\n\n::: {.cell-output-display}\n![](13_categorical_variables_files/figure-revealjs/unnamed-chunk-84-1.png){width=960}\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\ndata <- data |> \n  mutate(d1_1 = if_else(group == \"depress\", 1, 0),\n         d2_1 = if_else(group == \"healthy\", 1, 0))\n\nm_1 <- lm(health ~ d1_1 + d2_1, data = data)\n```\n:::\n\n\n\n- Model $R^2$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(m_1)$r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4765908\n```\n\n\n:::\n:::\n\n\n\n- $\\Delta R^2$ for depress vs. alcohol\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ d2_1, data = data), m_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1457776\n```\n\n\n:::\n:::\n\n\n\n- $\\Delta R^2$ for healthy vs. alcohol \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ d1_1, data = data), m_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4747354\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](13_categorical_variables_files/figure-revealjs/unnamed-chunk-88-1.png){width=960}\n:::\n:::\n\n\n\n::: {.callout-important}\n# Question\nWhat did you learn from these patterns?\n:::\n\n:::{.fragment}\n[The sum of the $\\Delta R^2$ for the two contrasts does not equal the model $R^2$.]{style=\"color:blue;\"}\n\n[The magnitude of any specific \\Delta R^2 reflects the size of the mean difference for the contrast]{style=\"color:blue;\"}\n\n[Depending on which group is set to be the reference, the size of the pair of mean differences were bigger or smaller]{style=\"color:blue;\"}\n\n[Using the same reference for both contrasts tends to make both contrasts EITHER big (reference group highest/lowest mean) or small (ref group has mean in middle)]{style=\"color:blue;\"}\n\n[Whenever you \"double-dip\" a group on the same side of multiple contrasts, you will get this dependency and non-orthogonal contrasts]{style=\"color:blue;\"}\n:::\n\n-------------------------------------------------------------------------------\n\n## Parsing Variance: POCs\n\nLets do the same exercise with our orthogonal contrast codes\n\n- Alcohol and Depress vs. Healthy\n- Alcohol vs. Depress\n\nCode regressors and look at data\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata <- data |> \n  select(-contains(\"d\"), -starts_with(\"c\")) |> # removing other group  regressors\n  mutate(patient_v_control = case_match(group,\n                           \"alcohol\" ~ 0.333,\n                           \"depress\" ~ 0.333,\n                           \"healthy\" ~ -.667),\n         alcohol_v_depress = case_match(group,\n                           \"alcohol\" ~ .5,\n                           \"depress\" ~ -.5,\n                           \"healthy\" ~ 0))\n\ndata |> \n  slice_sample(n = 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 4\n   group   health patient_v_control alcohol_v_depress\n   <fct>    <dbl>             <dbl>             <dbl>\n 1 depress    4.4             0.333              -0.5\n 2 healthy    7.4            -0.667               0  \n 3 depress    7.4             0.333              -0.5\n 4 alcohol    3.5             0.333               0.5\n 5 depress    7.4             0.333              -0.5\n 6 depress    7.7             0.333              -0.5\n 7 healthy    5.9            -0.667               0  \n 8 healthy    7.9            -0.667               0  \n 9 depress    5.4             0.333              -0.5\n10 healthy    6.9            -0.667               0  \n11 alcohol    3               0.333               0.5\n12 depress    5.9             0.333              -0.5\n13 alcohol    4.5             0.333               0.5\n14 alcohol    6               0.333               0.5\n15 alcohol    5               0.333               0.5\n16 alcohol    5               0.333               0.5\n17 alcohol    6.3             0.333               0.5\n18 healthy    6.4            -0.667               0  \n19 alcohol    6.3             0.333               0.5\n20 alcohol    6               0.333               0.5\n```\n\n\n:::\n:::\n\n\n\nThe regressors are uncorrelated\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(data$alcohol_v_depress, data$patient_v_control) |> round(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n::: {.callout-important}\n# Question\nWhat are the implications of this for the relationship between the total effect of `group` (i.e., $R^2$ in this model) vs. the sum of the $\\Delta R^2$ for the two othogonal contrasts?\n:::\n\n:::{.fragment}\n[The $\\Delta R^2$ for the two contrasts WILL sum to the model $R^2$.]{style=\"color:blue;\"}\n\n--------------------------------------------------------------------------------\n\nLets confirm\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npreds |> \n  ggplot(aes(x = group, y = fit)) +\n  geom_col(color = \"black\", fill = \"light grey\") +\n  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +\n  labs(y = \"Health\", x = NULL)\n```\n\n::: {.cell-output-display}\n![](13_categorical_variables_files/figure-revealjs/unnamed-chunk-91-1.png){width=960}\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\nm_poc <- lm(health ~ patient_v_control + alcohol_v_depress, data = data)\n```\n:::\n\n\n\n- Model $R^2$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(m_poc)$r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4765908\n```\n\n\n:::\n:::\n\n\n\n- $\\Delta R^2$ for patient vs. control \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ alcohol_v_depress, data = data), m_poc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3308131\n```\n\n\n:::\n:::\n\n\n\n- $\\Delta R^2$ for alcohol vs. depress\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelta_r2(lm(health ~ patient_v_control, data = data), m_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1457776\n```\n\n\n:::\n:::\n\n\n:::\n\n--------------------------------------------------------------------------------\n\n## Single and Multiple Comparisons \n\n::: {.callout-important}\n# Question\nWhat do you gain from testing the main effect of a categorical variable that has more than 2 levels? What do you not gain?\n:::\n\n:::{.fragment}\n[You learn that some contrast across the groups/conditions in some set of orthogonal contrasts is significant. Does this really tell you something interesting?]{style=\"color:blue;\"}        \n\n[You do NOT learn which groups are different from each other. In almost all instances our question is about differences between groups (or combinations of groups; or patterns across groups). We need contrasts.]{style=\"color:blue;\"}        \n[The test of the main effect is not needed (with one exception) to reduce the probability of making any Type I errors (false alarms). In many instances, it will increase the probability of Type II errors (misses). This is a **big** misconception in our field.]{style=\"color:blue;\"}    \n:::\n\n--------------------------------------------------------------------------------\n\n**Option 1: POCs**   \n\nTest and report results for the parameter estimates for the planned orthogonal contrasts\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nm_poc |> tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term              estimate std.error statistic  p.value\n  <chr>                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)           6.32     0.231     27.4  4.53e-27\n2 patient_v_control    -2.43     0.490     -4.96 1.40e- 5\n3 alcohol_v_depress    -1.86     0.566     -3.30 2.10e- 3\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n**Option 2: Planned non-orthogonal pairwise comparisons with dummy approach**    \n\n- Test only contrasts with same reference\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncontrasts(data$group) <- contr.treatment(levels(data$group), base = 3)\nm_3 <- lm(health ~ group, data = data)\ntidy(m_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      7.94     0.400     19.9  5.38e-22\n2 groupalcohol    -3.36     0.566     -5.95 6.13e- 7\n3 groupdepress    -1.5      0.566     -2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\n- Test all pairwise contrasts (e.g., fit models with other references to get remaining contrasts)\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncontrasts(data$group) <- contr.treatment(levels(data$group), base = 2)\nm_2 <- lm(health ~ group, data = data)\ntidy(m_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      6.44     0.400     16.1  7.90e-19\n2 groupalcohol    -1.86     0.566     -3.30 2.10e- 3\n3 grouphealthy     1.5      0.566      2.65 1.15e- 2\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n**Option 3: Unplanned; observed patterns of means dictate comparisons**   \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  group_by(group) |> \n  summarise(mean = mean(health))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  group    mean\n  <fct>   <dbl>\n1 alcohol  4.58\n2 depress  6.44\n3 healthy  7.94\n```\n\n\n:::\n:::\n\n\n\nYou might test any combination of pairwise or more complicated contrasts\n\n--------------------------------------------------------------------------------\n\n::: {.callout-important}\n# Question\nWhat validity concerns do we need to evaluate for these various options?\n:::\n\n:::{.fragment}\nStatistical/conclusion validity.{style=\"color:blue;\"}     \n\n[1. Do results clearly support your theory (fundamental)?]{style=\"color:blue;\"} \n[2. Probability of Type 1 error.]{style=\"color:blue;\"}     \n[3. Probability of Type 2 error.]{style=\"color:blue;\"}     \n\n[We should wonder (and be concerned about) what happens to the probability of making an error across *all* of our tests.]{style=\"color:blue;\"} \n:::\n\n--------------------------------------------------------------------------------\n\n**Test-wise error rate:** The probability of making a type I (or II) error for any specific statistical test. \n\n[What is it for type I and type II?]{style=\"color:red;\"}\n\n**Family-wise error rate:** The probability of making a type I (or II) error among a *family* of statistical tests reported (and performed).   \n\n**Experiment-wise error rate:** The probability of making a type I (or II) error among all statistical tests reported (and performed).   \n\n**Bonferroni Inequality:**   \n\n- $alpha_{set} \\le set\\_size*alpha_{test}$\n\n--------------------------------------------------------------------------------\n\n- In Psychology, we are generally concerned with test-wise and family-wise error rates (and most discussion is about Type I errors).  \n\n- Orthogonal effects in factorial ANOVA (e.g., two main effects and interaction in 2-way ANOVA) are typically considered to come from different families (different questions).\n\n- POCs within a multi-df effect are typically considered to come from different families. This makes most sense if the contrasts are testing clearly different questions.\n\n- Non-orthogonal contrasts within multi-df effect are clearly related (in same family).\n\n--------------------------------------------------------------------------------\n\n::: {.callout-important}\n# Question\nWhat do we now know about statistical validity for POC approaches?\n:::\n\n:::{.fragment}\n[Can only use POCs when your research questions map onto $n_{levels}-1$ orthogonal predictions.]{style=\"color:blue;\"}    \n\n[Need to proceed cautiously because statistical results may support predictions but patterns of means may undermine your conclusions (pharmacological and expectancy example - draw graphs for two scenarios).]{style=\"color:blue;\"}     \n\n[Must be comfortable with these contrasts testing *different* questions and therefore being in different families.]{style=\"color:blue;\"}\n:::\n\n--------------------------------------------------------------------------------\n\n::: {.callout-important}\n# Question\nWhat do we do with multiple planned, non-orthogonal contrasts, and worse still unplanned contrasts?\n:::\n\n:::{.fragment}\n**Many** procedures exist. Kirk summarizes more but...\n\n[**For planned, non-orthogonal**]{style=\"color:blue;\"}         \n\n- **Fisher LSD** is reasonable with planned, non-orthogonal contrasts for 3 level variables (family-wise alpha controlled and reasonable power).   \n\n- **Holm-Bonferonni** is most flexible but need to keep planned contrasts to a minimum (family-wise type I is strictly controlled, but power drops with increasing number of contrasts). Fisher LSD may be more powerful in some instances with 3 level variables.    \n\n\n[**For post-hoc/unplanned**]{style=\"color:blue;\"}        \n\n- **Scheffe** can be used when you can't limit yourself a priori. Power sucks!   \n:::\n\n--------------------------------------------------------------------------------\n\n## Fisher LSD (Protected Testing)\n\n1. First test omnibus (multi-df) effect (main effect or interaction). If non-significant, stop.    \n\n2. If omnibus effect is significant, test pairwise comparisons among groups/conditions using dummy codes (other contrasts may be used if planned). No additional “protection” is needed.   \n\n::: {.callout-important}\n# Question\nHow is family-wise alpha controlled?\n:::\n\n:::{.fragment}\n[Only proceed when omnibus test indicates some comparison is significant (see monte carlo of null main effect).]{style=\"color:blue;\"}     \n\n[Problems emerge if omnibus is significant but you do multiple tests, only some of which are significant). Not a problem, generally, with 3 level variable and 3 tests (e.g. pairwise comparisons). Inadequate with more levels (monte-carlo for three group with effect; thought experiment with 1 significant group difference in 4 level).]{style=\"color:blue;\"}    \n:::\n\n--------------------------------------------------------------------------------\n\n## Holm-Bonferroni Method\n\n1. Suppose there are $k$ null hypotheses to be tested and the overall type I error rate is $\\alpha$. \n\n2. Order the tests from smallest to largest p-value.\n\n3. Multiply the smallest p-value by $k$ and compare to $\\alpha$. If reject, continue. \n\n4. Multiply the next smallest p-value by $k-1$. Its new p-value is the max of this p-value and all preceding it.\n\n5. Continue doing this until a hypothesis cannot be rejected. At that point, stop and accept all remaining hypotheses.\n\nNOTE: Does **NOT** require significant omnibus test for type I protection.\n\n:::{.footer}\nHolm, S. (1979). A simple sequentially rejective multiple test procedure. *Scandinavian Journal of Statistics*, 6 (2): 65–70.\n:::\n\n--------------------------------------------------------------------------------\n\nHere are some p-values for a set of 7 planned comparisons\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(p = c(.001, .009, .005, .100, .200, .040, .011))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.001 0.009 0.005 0.100 0.200 0.040 0.011\n```\n\n\n:::\n:::\n\n\n\nBonerroni adjusts them by multipying each by 7.  Too conservative! (low power)\n\n\n::: {.cell}\n\n```{.r .cell-code}\np.adjust(p, method= 'bonferroni')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.007 0.063 0.035 0.700 1.000 0.280 0.077\n```\n\n\n:::\n:::\n\n\n\nHolm-Bonferroni adjusts them in a stepwise fashion.  \n\n- Always better than Boneferroni\n- Provides good protection against inflation of Type I errors\n- Power drops (Type II increases) as number of comparisons/tests increases\n- Easy to apply to any statistical tests\n\n\n::: {.cell}\n\n```{.r .cell-code}\np.adjust(p, method= 'holm')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.007 0.045 0.030 0.200 0.200 0.120 0.045\n```\n\n\n:::\n:::\n\n\n\n--------------------------------------------------------------------------------\n\n## Scheffe Test\n\n1. Adjust the F-statistic for each comparison by dividing it by (number of groups - 1).\n2. Get new p-value using: `pf(F, df1, df2, lower.tail = FALSE)`.\n\n- Can be used for complete exploratory comparisons.\n- Test of omnibus effect is **not** required. \n- If you are working with t values, square them to convert to F before dividing.\n- Provides good alpha protection (Type I errors). \n- Very conservative with high Type II errors.",
    "supporting": [
      "13_categorical_variables_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}