---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Unit 13: Categorical Variables > 2 Levels 

```{r}
#| echo: false

options(scipen = 999) # turns off scientific notation
options(knitr.kable.NA = '')
```


## Learning Objectives

- Two categorical coding schemes to know:   
  
    1. Dummy coding (reference/control group).  
    2. Contrast coding (POCs).   
    
- How best to test the comparisons coded by these methods if the comparisons are:   

    1. Planned and non-orthogonal.   
    2. Planned and orthogonal.   
    3. Unplanned.

- How to test effects and contrasts when covariates are included    
- How to test main and simple effects when categorical variables have > 2 levels.   

--------------------------------------------------------------------------------

We have handled categorical variables by recoding them using dummy codes or centered coefficients. 

This turned categorical/nominal variables into numeric regressors 

However, so far, we have only handled categorical variables with 2 levels

--------------------------------------------------------------------------------

These single $X$ regressors coded with dummy or contrast systems yielded one comparison of the mean of $Y$ across the two levels of the categorical variable.

Once we have more than two levels/groups within the categorical variable

- We will need to recode the categorical variable into $N_{levels/groups}-1$ regressors ($X$s) that represent $N - 1$ comparisons/contrasts within the overall categorical variable.

- Testing the **set** of regressors will allow us to test the overall effect of the categorical variable but we will often not care about this test. We are generally much more focused on planned or unplanned comparisons between the groups/levels.

---------------------------------------------------------------------------------

## Example

Examine the differences in overall health among patients with alcohol use disorder, patients with depression, and healthy controls.   

```{r}
#| code-fold: true
#| message: false

options(conflicts.policy = "depends.ok") 
library(tidyverse)
library(broom)
library(patchwork)

theme_set(theme_classic()) 
path_data <- "data_lecture"
```

```{r}
data <- read_csv(here::here(path_data, "13_three_groups.csv"),
                 show_col_types = FALSE) |> 
  mutate(group = fct(group, levels = c("alcohol", "depress", "healthy")))

slice_sample(data, n = 10)
```

--------------------------------------------------------------------------------

::: {.callout-important}
# Question  
Why can we not handle multi-level categorical variables by simply coding each group with a different consecutive value (e.g., alcohol = 1, depress = 2 , healthy = 3)?
:::

:::{.fragment}
[There is no meaningful way to order the multiple groups. The shape of the relationship will completely change based on arbitrary ordering of the groups (exception is when categorical variable is ordinal).]{style="color:blue;"}    

[Moreover, we are often interested in individual pair-wise group comparisons that would be lost by forcing a linear relationship with only one parameter estimate.]{style="color:blue;"}
:::

--------------------------------------------------------------------------------

```{r}
#| echo: false 

order_1 <- data |> 
  mutate(group = case_match(group,
                            "alcohol" ~ 1,
                            "depress" ~ 2,
                            "healthy" ~ 3)) |> 
  ggplot(aes(x = group, y = health)) +
  geom_point() +
  scale_y_continuous(breaks = c(2, 4, 6, 8, 10), limits = c(0, 10)) +
  scale_x_continuous(name = NULL, breaks = c(1, 2, 3), 
                     labels = c("alcohol", "depress", "healthy"))

order_2 <- data |> 
  mutate(group = case_match(group,
                            "alcohol" ~ 2,
                            "depress" ~ 3,
                            "healthy" ~ 1)) |> 
  ggplot(aes(x = group, y = health)) +
  geom_point() +
  scale_y_continuous(breaks = c(2, 4, 6, 8, 10), limits = c(0, 10)) +
  scale_x_continuous(name = NULL, breaks = c(1, 2, 3), 
                     labels = c("healthy", "alcohol", "depress"))

order_3 <- data |> 
  mutate(group = case_match(group,
                            "alcohol" ~ 3,
                            "depress" ~ 1,
                            "healthy" ~ 2)) |> 
  ggplot(aes(x = group, y = health)) +
  geom_point() +
  scale_y_continuous(breaks = c(2, 4, 6, 8, 10), limits = c(0, 10)) +
  scale_x_continuous(name = NULL, breaks = c(1, 2, 3), 
                     labels = c("depress", "healthy", "alcohol"))

order_1 + order_2 + order_3
```

--------------------------------------------------------------------------------

## 3 Group Dummy Coding (Non-orthogonal)  

We will start by generalizing the dummy coding approach to more than 2 levels

- Need 2 regressors (`alcohol_d3`, `depress_d3`) to represent a 3 level categorical variable.   
- Regressor 1 is coded 1 for membership in Group 1 (alcohol) and 0 for all other group membership.
- Regressor 2 is coded 1 for membership in Group 2 (depress) and 0 for all other group membership.
- Reference group (healthy) is coded 0 for all regressors.

This yields the following dummy coding table for our example

```{r}
#| echo: false

(tibble_d <- tibble(Group = c("alcohol", "depress", "healthy"),
       alcohol_d3 = c(1, 0, 0),
       depress_d3 = c(0, 1, 0)))
```

::: {.footer}
We are using `_d3` in these regressor names to indicate they are dummy codes with the third level as reference
:::

--------------------------------------------------------------------------------

```{r}
tibble_d
```

And here are the two new regressors for our data
```{r}
data <- data |> 
  mutate(alcohol_d3 = if_else(group == "alcohol", 1, 0),
         depress_d3 = if_else(group == "depress", 1, 0))

slice_sample(data, n = 10)
```

--------------------------------------------------------------------------------

Now 
```{r}
m_d3 <- lm(health ~ alcohol_d3 + depress_d3, data)

tidy(m_d3)
```

--------------------------------------------------------------------------------

## 3 Group Dummy: What do the parameter estimates test?  

Each parameter estimate for the $X$s represents the contrast between the mean of $Y$ in its respective target group (the group that was coded 1 for that $X$) and the **reference** group. 

```{r}
tibble_d
```

--------------------------------------------------------------------------------

```{r}
tidy(m_d3)
```

Here is mean `health` among the three groups

```{r}
data |> 
  group_by(group) |> 
  summarise(mean = mean(health))
```

- alcohol vs healthy = 4.58 - 7.94 = -3.36
- depress vs. healthy = 6.44 - 7.94 = -1.50

--------------------------------------------------------------------------------

Here is a visualization of the dummy coded regressors that allows us to see why this system works to give us target vs. reference contrasts

![](figures/dummy_3d.png)

NOTE: We will later see a more mathematical way to support this intuition using decompositions

--------------------------------------------------------------------------------

## Dummy Coding Group Mean Estimates

**The Prediction equation:**   

- $\hat{Y} = 7.94+-3.36*alcohol_{d3}+ - 1.50*depress_{d3}$     


Patients with alcohol use disorder (coded 1, 0 across $X$s:    

- $= 7.94 + -3.36*(1)+-1.50*(0)$   
- $= 4.58$   


Patients with depression (coded 0, 1):    

- $= 7.94 + -3.36*(0)+-1.50*(1)$   
- $= 6.44$   


Healthy controls (coded 0, 0):    

- $= 7.94 + -3.36*(0)+-1.50*(0)$   
- $= 7.94$

::: {.callout-important}
# Question 
What is $b_0$ when using dummy codes?
:::

:::{.fragment}
[The predicted value (mean) for the reference group.]{style="color:blue;"}  
:::

--------------------------------------------------------------------------------

## Dummy Coding Decompositions

**The Prediction equation:**   

- $\hat{Y} = 7.94+-3.36*alcohol_{d3}+ - 1.50*depress_{d3}$     

alcohol (1, 0) vs. healthy (0, 0) contrast:   

- $= (b_0 + b_1*1 + b_2*0) - (b_0 + b_1*0 + b_2*0)$   
- $= (b_0 + b_1) - (b_0)$   
- $= b_1$   

depress (0, 1) vs. healthy (0, 0) contrast:   

- $= (b_0 + b_1*0 + b_2*1) - (b_0 + b_1*0 + b_2*0)$   
- $= (b_0 + b_2) - (b_0)$   
- $= b_2$   
 
alcohol (1, 0) vs. depress (0, 1) contrast:   

- $= (b_0 + b_1*1 + b_2*0) - (b_0 + b_1*0 + b_2*1)$   
- $= (b_0 + b_1) - (b_0 + b_2)$   
- $= b_1 - b_2$   

--------------------------------------------------------------------------------

## Introducing Factors and Contrasts

We can (and often do) manually code our $X$s to represent categorical predictors.

However, R can also handle this for us directly if we set up the categorical predictor as a factor and set contrasts for it.


We set up `group` as a factor and indicated its levels when we read in the data earlier

- `mutate(group = fct(group, levels = c("alcohol", "depress", "healthy")))`
- We prefer to use `forcats::fct()` vs. base R `factor()`


Confirm this

```{r}
class(data$group)
```

```{r}
levels(data$group)
```

--------------------------------------------------------------------------------

By default, R assigns what it calls treatment contrasts to unordered factors (the only type of factor I use). 
```{r}
options("contrasts")
```

Treatment contrasts are dummy contrasts!  

- Default is to assign the first level as the reference group.
- We may not want this
```{r}
contrasts(data$group)
```

--------------------------------------------------------------------------------

We can (re)set the reference level or even change the contrast type (more on that in a moment) using `contrasts()` on the factor 

Here we continue to use treatment/dummy contrasts but change the reference level to the third level (healthy)

```{r}
contrasts(data$group) <- contr.treatment(levels(data$group), base = 3)
```

Lets confirm this
```{r}
contrasts(data$group)
```

--------------------------------------------------------------------------------

Internally, R is now calculating the two dummy coded regressors for you when you use group as the predictor

- This can be quicker/easier in some instances
- It does hide some of what is going on (not great for understanding)
- Results are, of course, the same!
- You should be comfortable with both approaches
- Use the approach (manually coding $X$s or contrasts on factor) that best suits your needs
```{r}
m_d3f <- lm(health ~ group, data = data)
tidy(m_d3f)
```

--------------------------------------------------------------------------------

If you want to see the internal representation of the dummy coded regressors (and all other $X$s) for any model,  you can use `model.matrix()` with any linear model object.
```{r}
model.matrix(m_d3f) |> 
  head(n = 20)
```

::: {.callout-important}
# Question
Notice the (Intercept) column.  Does this give you any insight into how to think about the $b_0$ parameter estimate in any model?
:::

:::{.fragment}
$b_0$ is just like the other parameter estimates. It is a coefficient that gets multipled by an $X$.  However, the intercept $X$ is just a column of 1!
:::

--------------------------------------------------------------------------------

Now lets continue to expand our understanding of these tests of the two dummy contrasts

::: {.callout-important}
# Question 
How are these t-tests of $b_j$ in the linear model different from what you would get if you simply ran two separate between groups t-tests?
:::

:::{.fragment}
[The linear model t-tests of $b_j$ use the full error term including all subjects (including the “ignored” group; see dfs below). This yields a more powerful and therefore preferred test.]{style="color:blue;"}     

--------------------------------------------------------------------------------

The linear model
```{r}
tidy(m_d3)
```

The df for testing the paramemeter estimates is $N-P$ (42 - 3) = 39
```{r}
m_d3$df.residual
```

The between groups/subject t-test for alcohol vs. healthy
```{r}
data |> 
  filter(group != "depress") |> 
  t.test(health ~ group, var.equal = TRUE,
         data = _)
```

NOTE: use of `_` to pipe the object from `filter()` into a later argument in`t.test()`
:::

--------------------------------------------------------------------------------

::: {.callout-important}
# Question 
What may be missing from our analysis of the `group` variable at this point and how could we get it?
:::

:::{.fragment}
[We might want a test of the contrast between patients with alcohol use disorder vs. patients with depression.]{style="color:blue;"}    

[Recode the group contrasts such that the patients with depression is the reference group. Then test and interpret the alcohol vs. depress parameter estimate.]{style="color:blue;"}    
:::

--------------------------------------------------------------------------------

We could do this using `contr.treatment()`
```{r}
contrasts(data$group) <- contr.treatment(levels(data$group), base = 2)
contrasts(data$group)
```

```{r}
m_d2f <- lm(health ~ group, data = data)
tidy(m_d2f)
```

--------------------------------------------------------------------------------

Or we could do this by manually calculating two new dummy coded $X$s using depress as the level that is set to zero for both $X$s (using `_d2` in the names to indicate set using level 2 as reference)

```{r}
data <- data |> 
  mutate(alcohol_d2 = if_else(group == "alcohol", 1, 0),
         healthy_d2 = if_else(group == "healthy", 1, 0))

slice_sample(data, n = 10) |> 
  select(-subid)
```

```{r}
m_d2 <- lm(health ~ alcohol_d2 + healthy_d2, data)
tidy(m_d2)
```

--------------------------------------------------------------------------------

Remember that these are the group means

```{r}
data |> 
  group_by(group) |> 
  summarise(mean = mean(health))
```

And here are the parameter estimates from the model with healthy as reference
```{r}
tidy(m_d3)
```


And the parameter estimates from the model with depressed as reference
```{r}
tidy(m_d2)
```

::: {.callout-important}
Do the differences in all the parameter estimates across these two models make sense to you?
:::

--------------------------------------------------------------------------------

::: {.callout-important}
# Question 
What does the 2 df F-test of $R^2$ test conceptually?
:::

:::{.fragment}
[In this special case (with only one categorical predictor represented by multiple $X$s), it provides a test of the main effect of group.]{style="color:blue;"}          

[A significant main effect means that at least 1 contrast in one set of all possible sets of orthogonal contrasts is significant.]{style="color:blue;"}         

[It is not generally very useful. Tradition is still to report it (unless using POCs) but likely for wrong reasons (more in this later).]{style="color:blue;"}
:::

--------------------------------------------------------------------------------

::: {.callout-important}
# Question 
Why will model $R^2$ not test the main effect if there are regressors for other predictors in the model?
:::

:::{.fragment}
[Model $R^2$ is the variance in $Y$ explained by all the regressors in the model. It will only test the main effect of a categorical predictor if only regressors for that categorical predictor are in the model.]{style="color:blue;"}

[We will return in a bit to testing `group` effect with other $X$s in the model]{style="color:blue;"}
:::

--------------------------------------------------------------------------------

How do you get $R^2$ and its test for our model?

- You can get the value for $R^2$ using `glance` as always
```{r}
glance(m_d3)$r.squared
```

To test the null hypothesis for $R^2$ (i.e., the combined effect of the two dummy coded regressors in this example) you can do a model comparison

-  Augmented model is full model with both dummy regressors
-  Compact model is mean only model (parameter estimates for both $X$s set to 0)
```{r}
anova(lm(health ~ 1, data = data), m_d3)
```

--------------------------------------------------------------------------------

We can also get variance based effect sizes for each contrast (and this is likely more important than the overall `group` effect)

When we set healthy as the reference, we had contrasts for 

- alcohol vs. healthy (`alcohol_d3`)
- depress vs. healthy (`depress_d3`)

We can first set up our functions for $\Delta R^2$ (or for PRE if you prefer - not shown here)

```{r}
delta_r2 <- function(compact, augmented) {
  broom::glance(augmented)$r.squared - broom::glance(compact)$r.squared
}
```

--------------------------------------------------------------------------------

$\Delta R^2$ for alcohol vs. healthy (compact model includes only the depress vs. healthy contrast)

```{r}
delta_r2(lm(health ~ depress_d3, data = data), m_d3)
```

$\Delta R^2$ for depress vs. healthy (compact model includes only the alcohol vs. healthy contrast)
```{r}
delta_r2(lm(health ~ alcohol_d3, data = data), m_d3)
```

--------------------------------------------------------------------------------

## Testing Overall Effect with Other Xs in Model

You can use the model comparison approach to get the test of the main effect of `group` even when $X$s for other predictors (e.g., covariates) are included in the model (such that $R^2$ is no longer a test of the `group` effect only)

Lets add a covariate to the dataset and the model

```{r}
data <- data |> 
  mutate(age = rnorm(nrow(data), 50, 10))

m_d3_cov <- lm(health ~ alcohol_d3 + depress_d3 + age, data = data)

tidy(m_d3_cov)
```

Remember that the $R^2$ for this model is not a test of the main effect of `group` but instead it is the combined effect of `group` and `age`

--------------------------------------------------------------------------------

:::{.callout-important}
# Question
What model comparison will get you the test of the main effect of `group`?
:::

:::{.fragment}
[You will compare the full model with `group` and `age` to the compact model with only `age`.]{style="color:blue;"}

- Compact: $health ~ b_0 + 0*alcohol_{d3} + 0* depress_{d3} + b_3*age$
- Augmented: $health ~ b_0 + b_1*alcohol_{d3} + b_2*depress_{d3} + b_3*age$

This is an F test with 2 df ($P_a - P_c$) in the numerator and 38 ($N-P_a$) in the denominator

```{r}
anova(lm(health ~ age, data = data), m_d3_cov)
```
:::

--------------------------------------------------------------------------------

And we can do model comparisons to get $\Delta R^2$ for the full `group` effect or the contrasts within `group`

$\Delta R^2$ for the full `group` effect

```{r}
delta_r2(lm(health ~ age, data = data), m_d3_cov)
```

$\Delta R^2$ for alcohol vs. healthy (compact model includes the depress vs. healthy contrast AND age)

```{r}
delta_r2(lm(health ~ depress_d3 + age, data = data), m_d3_cov)
```

$\Delta R^2$ for depress vs. healthy (compact model includes the alcohol vs. healthy contrast AND age)
```{r}
delta_r2(lm(health ~ alcohol_d3 + age, data = data), m_d3_cov)
```

--------------------------------------------------------------------------------

## Planned Orthogonal Contrasts

The second coding option for regressors for categorical predictors yields planned orthogonal contrasts (POCs).   

Planned orthogonal contrasts allow you to:    

1. Parse IV variance into its components (more on this later).
2. Test for contrasts other than pairwise.

--------------------------------------------------------------------------------

You might have contrasts that interest you that don't all use one reference group.  For example:

- You predict that psychopathology will reduce overall health. 
- And you also think that the type of psychopathology matters (AUD is worse than depression)

You can set up contrasts that test these two comparisons.  There are several equivalent ways to do this.

**for conceptual understanding:**

```{r}
#| echo: false

(c_a <- tibble(Group = c("alcohol", "depress", "healthy"),
       c1_a = c(.5, .5, -1),
       c2_a = c(1, -1, 0)))
```

**A common alternative (whole numbers):**

```{r}
#| echo: false

(c_b <- tibble(Group = c("alcohol", "depress", "healthy"),
       c1_b = c(1, 1, -2),
       c2_b = c(1, -1, 0)))
```

--------------------------------------------------------------------------------

**John's preference (unit weighted):**

```{r}
#| echo: false

(c_c <- tibble(Group = c("alcohol", "depress", "healthy"),
       c1_c = c(.333, .333, -.667),
       c2_c = c(.5, -.5, 0)))
```

--------------------------------------------------------------------------------

```{r}
c_a
```

::: {.callout-important}
# Question 
All of these options (first displayed above) represent two conceptual comparisons. What are these two comparisons?
:::

:::{.fragment}
[`c1` compares a combined group of patients with alcohol use disorder and depression to healthy controls.]{style="color:blue;"}       

[`c2` compares patients with alcohol use disorder to patients with depression.]{style="color:blue;"}
:::

-------------------------------------------------------------------------------

```{r}
#| echo: false
c_a
c_b
c_c
```

::: {.callout-important}
# Question
How will the analyses be similar and different across these three contrasts?
:::

:::{.fragment}
[The parameter estimates for `c1` and `c2` will be different across the three coding options. However, the statistical test of the null for each parameter will be identical (t/F and p-value). This should not be surprising given that the contrasts in each `c1` option are simply a linear transformation of the other. It is simply a change of scale similar to multiplying a quantitative variable by some constant.]{style="color:blue;"}       
 
[The model $R^2$ and the test of the null will be identical.]{style="color:blue;"} 
:::

--------------------------------------------------------------------------------

Put all three options for regressors into the data set
```{r}
#| code-fold: true

data <- data |> 
  mutate(c1_a = case_match(group,
                           "alcohol" ~ 0.5,
                           "depress" ~ 0.5,
                           "healthy" ~ -1),
         c2_a = case_match(group,
                           "alcohol" ~ 1,
                           "depress" ~ -1,
                           "healthy" ~ 0),
         c1_b = case_match(group,
                           "alcohol" ~ 1,
                           "depress" ~ 1,
                           "healthy" ~ -2),
         c2_b = case_match(group,
                           "alcohol" ~ 1,
                           "depress" ~ -1,
                           "healthy" ~ 0),
         c1_c = case_match(group,
                           "alcohol" ~ 0.333,
                           "depress" ~ 0.333,
                           "healthy" ~ -.667),
         c2_c = case_match(group,
                           "alcohol" ~ .5,
                           "depress" ~ -.5,
                           "healthy" ~ 0))
```

And view a few rows
```{r}
data |> 
  select(-contains("d")) |> 
  slice_sample(n = 10)
```

--------------------------------------------------------------------------------

Fit models with all three options
```{r}
m_c_a <- lm(health ~ c1_a + c2_a, data = data)
m_c_b <- lm(health ~ c1_b + c2_b, data = data)
m_c_c <- lm(health ~ c1_c + c2_c, data = data)
```

--------------------------------------------------------------------------------

Here are results

```{r}
tidy(m_c_a)
tidy(m_c_b)
tidy(m_c_c)
```

--------------------------------------------------------------------------------

```{r}
#| echo: false
c_a
c_b
c_c
```

::: {.callout-important}
# Question
Why are the parameter estimates for `c1` different and why do we prefer option c?
:::

:::{.fragment}
[In each instance $b_1$ represents change in health for a 1 unit change on the `c1` regressor. For `c1_c` a 1 unit change moves fully from the alcohol/depress group to the healthy group. In contrast, $b_1$ was 2/3 the size for `c1_a` because 1 unit only moves 2/3 of the way between the two sets in the `c1_a` contrast.]{style="color:blue;"}        
:::

--------------------------------------------------------------------------------

```{r}
#| echo: false
c_c
```

```{r}
tidy(m_c_c)
```

```{r}
data |> 
  group_by(group) |> 
  summarise(mean = mean(health))
```

You can do the math to confirm that $b_1$ and $b_2$ for the unit-weighted contrasts match the mean differences associated with the `c1` and `c2` comparisons.  

--------------------------------------------------------------------------------

## How to Calculate Unit Weights

We can write any comparison in terms of coefficients multiplied by group means for all groups in the following form:    

$C = \text{set U} - \text{set V}$   

$C = (c_1*group_1 + c_2*group_2 + ...)-(c_3*group_3+c_4*group_4 + ...)$   

- You can think of this as a contrast between two sets of the groups/levels.   
- Call them set U (with u groups included) and set V (with v groups included).
- A third set can be ignored by assigning coefficients of 0.

--------------------------------------------------------------------------------

$C = \text{set U} - \text{set V}$   

$C = (c_1*group_1 + c_2*group_2 + ...)-(c_3*group_3+c_4*group_4 + ...)$   

The coefficients in set U should all be: $\frac{v}{(u + v)}$.   

The coefficients in set V should all be: $\frac{u}{(u + v)}$.   

The coefficients in the ignored set should all be 0.

--------------------------------------------------------------------------------

::: {.callout-important}
# Question
How would you describe `c1` (patient groups vs. healthy controls) and `c2` (patients with alcohol use disorder vs. depression) in terms of Set U and Set V?   And what coefficients would you assign?
:::

:::{.fragment}
[Patient groups vs. healthy controls]{style="color:blue;"}

- [Set U: `alcohol`, `depress`; Set V: `healthy`]{style="color:blue;"}         
- [u = 2; v = 1]{style="color:blue;"}

$Contrast_1 = (c_1*alcohol + c_2*depress)-(c_3*healthy)$    
$Contrast_1 = (\frac{v}{(u + v)}*alcohol + \frac{v}{(u + v)}*depress)-(\frac{u}{(u + v)}*healthy)$    
$Contrast_1 = (.333*alcohol + .333*depress)-(.667*healthy)$    


[Alcohol vs. depress]{style="color:blue;"}

- [Set U: `alcohol`; Set V: `depress`; Ignored: `healthy`]{style="color:blue;"}         
- [u = 1; v = 1]{style="color:blue;"}

$Contrast_2 = (c_1*alcohol)-(c_2*depress)$     
$Contrast_2 = (\frac{v}{(u + v)}*alcohol)-(\frac{u}{(u + v)}*depress) + (0* healthy)$    
$Contrast_2 = (.5*alcohol)-(.5*depress) + (0* healthy)$    
:::

--------------------------------------------------------------------------------

For the manual approach

- We can code them into our dataframe directly as before

```{r}
data <- data |> 
  select(-age, -contains("_d"), -starts_with("c")) |> # removing other group  regressors
  mutate(patient_v_control = case_match(group,
                           "alcohol" ~ 0.333,
                           "depress" ~ 0.333,
                           "healthy" ~ -.667),
         alcohol_v_depress = case_match(group,
                           "alcohol" ~ .5,
                           "depress" ~ -.5,
                           "healthy" ~ 0))
```

--------------------------------------------------------------------------------

Lets see them!
```{r}
data |> 
  slice_sample(n = 10)
```

--------------------------------------------------------------------------------

Alternatively, for the factor contrasts approach

- We can set these contrasts up as a matrix (and name the contrasts)
```{r}
our_contrasts <- matrix(c(.333, .333, -.667,
                            .5,  -.5, 0), 
                        ncol = 2,
                        dimnames = list(c("alcohol", "depress", "healthy"),
                                        c("patient_v_healthy", "alcohol_v_depress")))

our_contrasts
```

- And then assign them to the contrasts for the factor
```{r}
contrasts(data$group) <- our_contrasts
```


--------------------------------------------------------------------------------

Of course, they yield the same results

```{r}
m_poc_f <- lm(health ~ group, data = data)
tidy(m_poc_f)
```

```{r}
m_poc <- lm(health ~ patient_v_control + alcohol_v_depress, data = data)
tidy(m_poc)
```

--------------------------------------------------------------------------------

```{r}
tidy(m_poc)
```

::: {.callout-important}
# Question 
What does each of the $b_j$s test?
:::

:::{.fragment}
[Each test whether the contrast that we specified is 0 or not. More specifically, how likely would it be to get our sample $b_j$ if $\beta_j = 0$ for each of these two contrasts.]{style="color:blue;"}
:::

--------------------------------------------------------------------------------

::: {.callout-important}
# Question
What does the 2 df F-test of $R^2$ test conceptually?
:::

:::{.fragment}
[It provides a test of the main effect of `group`; same as before with dummy coded regressors. Any unique coding system using 2 regressors for three groups will work for the main effect.]{style="color:blue;"}        

[As before, you don’t want to use model $R^2$ for the main effect in any model other than one way ANOVA.]{style="color:blue;"}

[Use `anova()` function to test model contrast between full model and mean-only model.]{style="color:blue;"}    

```{r}
glance(m_poc)$r.squared
anova(lm(health ~ 1, data = data), m_poc)
```
:::

--------------------------------------------------------------------------------

## POC Contrast Coding: Common Contrasts

**3 group contrasts**   

- $Contrast_1: \frac{(group_1 + group_2)}{2} \text{ vs. } group_3$    
- $Contrast_2: group_1 \text{ vs. }  group_2$

And here is the matrix to use for coding or to assign to factor with `contrasts()`
```{r}
groups3 <- matrix(c(.333, .333, -.667,
                    .5, -.5, 0), 
                  ncol = 2,
                  dimnames = list(c("group1", "group2", "group3"),
                                  c("g12v3", "g1v2")))
groups3
```

--------------------------------------------------------------------------------

**4 group contrasts: Option 1**   

- $Contrast_1: \frac{(group_1 + group_2 +group_3)}{3} \text{ vs. } group_4$    
- $Contrast_2: \frac{(group_1 + group_2)}{2} \text{ vs. } group_3$     
- $Contrast_3: group_1 \text{ vs. } group_2$

```{r}
groups4_a <- matrix(c(.25, .25, .25, -.75,
                      .333, .333, -.667, 0,
                      .5, -.5, 0, 0), 
                    ncol = 3,
                    dimnames = list(c("group1", "group2", "group3", "group4"),
                                    c("g123v4", "g12v3", "g1v2")))
groups4_a
```

--------------------------------------------------------------------------------

**4 group contrasts: Option 2**   

- $Contrast_1: \frac{(group_1 + group_2)}{2} \text{ vs. } + \frac{(group_3 + group_4)}{2}$    
- $Contrast_2: group_1 \text{ vs. }  group_2$
- $Contrast_3: group_3 \text{ vs. }  group_4$

```{r}
groups4_b <- matrix(c(.5, .5, -.5, -.5,
                      .5, -.5, 0, 0,
                       0, 0, .5, -.5), 
                    ncol = 3,
                    dimnames = list(c("group1", "group2", "group3", "group4"),
                                    c("g12v34", "g1v2", "g3v4")))
groups4_b
```

--------------------------------------------------------------------------------

**4 group contrasts: polynomials**   

- Linear
- Quadratic
- Cubic

```{r}
groups4_poly <- matrix(c(-3, -1, 1, 3,
                      1, -1, -1, 1,
                      -1, 3, -3, 1), 
                    ncol = 3,
                    dimnames = list(c("group1", "group2", "group3", "group4"),
                                    c("linear", "quadratic", "cubic")))
groups4_poly
```

NOTE: Not unit weighted 

--------------------------------------------------------------------------------

## Display: Group Means + SEM

You will often see group means with standard error of the mean (SEM) in figures.

These SEMs are calculated as the standard deviation of the group divided by the square root of the number of subjects in the group.

They do NOT use all the data for these SEMs.  We don't recommend this approach
```{r}
data |> 
  group_by(group) |> 
  summarise(mean = mean(health),
            se = sd(health)/sqrt(n())) 
```

--------------------------------------------------------------------------------

```{r}
#| code-fold: true

data |> 
  group_by(group) |> 
  summarise(mean = mean(health),
            se = sd(health)/sqrt(n())) |> 
  ggplot(aes(x = group, y = mean)) +
  geom_col(color = "black", fill = "light grey") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2) +
  labs(y = "Health", x = NULL)
```

--------------------------------------------------------------------------------

## Dummy Coding Group Mean Estimates

::: {.callout-important}
# Question
How can we get standard errors for the group mean point estimates that use ALL the observations using the linear model parameters?
:::

:::{.fragment}
[Fit three separate models. Set a different group as the reference group in each model. $b_0$ will be the predicted mean for the reference group in each model. The standard error for $b_0$ is the standard error for this parameter.]{style="color:blue;"}    
:::

--------------------------------------------------------------------------------

These standard errors are the standard errors you should graph! But there is an easier way to get these.

- Alcohol
```{r}
contrasts(data$group) <- contr.treatment(levels(data$group), base = 1)
lm(health ~ group, data = data) |> 
  tidy() 
```

- Depress
```{r}
contrasts(data$group) <- contr.treatment(levels(data$group), base = 2)
lm(health ~ group, data = data) |>  
  tidy() 
```

- Healthy controls
```{r}
contrasts(data$group) <- contr.treatment(levels(data$group), base = 3)
lm(health ~ group, data = data) |>  
  tidy() 
```

--------------------------------------------------------------------------------

Using `predict()`

- fit model (with any coding scheme)

```{r}
contrasts(data$group) <- contr.treatment(levels(data$group), base = 3)
m_3 <- lm(health ~ group, data = data)
```


- make a dataframe for predictions
```{r}
x <- tibble(group = levels(data$group))
x
```

- add predictions and se
```{r}
preds <- predict(m_3, newdata = x, se.fit = TRUE) |> 
  as_tibble() |> 
  mutate(upr = fit + se.fit,
         lwr = fit - se.fit) |> 
  select(-df, -residual.scale) |> 
  bind_cols(x)

preds
```

--------------------------------------------------------------------------------

- And now plot

```{r}
preds |> 
  ggplot(aes(x = group, y = fit)) +
  geom_col(color = "black", fill = "light grey") +
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +
  labs(y = "Health", x = NULL)
```

NOTE: You could also add raw data or residualized data if you like

--------------------------------------------------------------------------------

## Parsing Variance: Dummy Codes

Dummy-coded regressors are NOT orthogonal

```{r}
#| code-fold: true

data <- data |> 
  select(-contains("_v_")) |> 
  mutate(alcohol_d3 = if_else(group == "alcohol", 1, 0),
         depress_d3 = if_else(group == "depress", 1, 0))

data |> 
  slice_sample(n = 10)
```
 
```{r}
cor(data$alcohol_d3, data$depress_d3)
```

--------------------------------------------------------------------------------

::: {.callout-important}
# Question
What are the implications of this for the relationship between the total effect of `group` (i.e., $R^2$ in this model) vs. the sum of the $\Delta R^2$ for the two contrasts?
:::

:::{.fragment}
[The $\Delta R^2$ for the two contrasts will not sum to the model $R^2$.]{style="color:blue;"}

::::{.callout-important}
# Question
Do you have any intuition about whether they will sum to more or less?
::::
:::

--------------------------------------------------------------------------------

Dummy codes w/ healthy as reference

```{r}
#| code-fold: true

preds |> 
  ggplot(aes(x = group, y = fit)) +
  geom_col(color = "black", fill = "light grey") +
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +
  labs(y = "Health", x = NULL)


data <- data |> 
  mutate(d1_3 = if_else(group == "alcohol", 1, 0),
         d2_3 = if_else(group == "depress", 1, 0))

m_3 <- lm(health ~ d1_3 + d2_3, data = data)
```


Model $R^2$
```{r}
glance(m_3)$r.squared
```


$\Delta R^2$ for alcohol vs. healthy
```{r}
delta_r2(lm(health ~ d2_3, data = data), m_3)
```


$\Delta R^2$ for depress vs. healthy
```{r}
delta_r2(lm(health ~ d1_3, data = data), m_3)
```

--------------------------------------------------------------------------------

Dummy codes w/ depress as reference

```{r}
#| code-fold: true

preds |> 
  ggplot(aes(x = group, y = fit)) +
  geom_col(color = "black", fill = "light grey") +
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +
  labs(y = "Health", x = NULL)

data <- data |> 
  mutate(d1_2 = if_else(group == "alcohol", 1, 0),
         d2_2 = if_else(group == "healthy", 1, 0))

m_2 <- lm(health ~ d1_2 + d2_2, data = data)
```


Model $R^2$
```{r}
glance(m_2)$r.squared
```


$\Delta R^2$ for alcohol vs. depress
```{r}
delta_r2(lm(health ~ d2_2, data = data), m_2)
```


$\Delta R^2$ for healthy vs. depress
```{r}
delta_r2(lm(health ~ d1_2, data = data), m_2)
```

--------------------------------------------------------------------------------

Dummy codes w/ alchol as reference

```{r}
#| code-fold: true

preds |> 
  ggplot(aes(x = group, y = fit)) +
  geom_col(color = "black", fill = "light grey") +
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +
  labs(y = "Health", x = NULL)

data <- data |> 
  mutate(d1_1 = if_else(group == "depress", 1, 0),
         d2_1 = if_else(group == "healthy", 1, 0))

m_1 <- lm(health ~ d1_1 + d2_1, data = data)
```


Model $R^2$
```{r}
glance(m_1)$r.squared
```


$\Delta R^2$ for depress vs. alcohol
```{r}
delta_r2(lm(health ~ d2_1, data = data), m_1)
```


$\Delta R^2$ for healthy vs. alcohol 
```{r}
delta_r2(lm(health ~ d1_1, data = data), m_1)
```

--------------------------------------------------------------------------------

```{r}
#| echo: false

preds |> 
  ggplot(aes(x = group, y = fit)) +
  geom_col(color = "black", fill = "light grey") +
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +
  labs(y = "Health", x = NULL)
```

::: {.callout-important}
# Question
What did you learn from these patterns?
:::

:::{.fragment}
[The sum of the $\Delta R^2$ for the two contrasts does not equal the model $R^2$.]{style="color:blue;"}

[The magnitude of any specific $\Delta R^2$ reflects the size of the mean difference for the contrast]{style="color:blue;"}

[Depending on which group is set to be the reference, the size of the pair of mean differences were bigger or smaller]{style="color:blue;"}

[Using the same reference for both contrasts tends to make both contrasts EITHER big (reference group highest/lowest mean) or small (ref group has mean in middle)]{style="color:blue;"}

[Whenever you "double-dip" a group on the same side of multiple contrasts, you will get this dependency and non-orthogonal contrasts]{style="color:blue;"}
:::

-------------------------------------------------------------------------------

## Parsing Variance: POCs

Lets do the same exercise with our orthogonal contrast codes

- Alcohol and Depress vs. Healthy
- Alcohol vs. Depress

Code regressors and look at data
```{r}
#| code-fold: true
 
data <- data |> 
  select(-contains("d"), -starts_with("c")) |> # removing other group  regressors
  mutate(patient_v_control = case_match(group,
                           "alcohol" ~ 0.333,
                           "depress" ~ 0.333,
                           "healthy" ~ -.667),
         alcohol_v_depress = case_match(group,
                           "alcohol" ~ .5,
                           "depress" ~ -.5,
                           "healthy" ~ 0))

data |> 
  slice_sample(n = 20)
```

The regressors are uncorrelated
```{r}
cor(data$alcohol_v_depress, data$patient_v_control) |> round(5)
```

--------------------------------------------------------------------------------

::: {.callout-important}
# Question
What are the implications of this for the relationship between the total effect of `group` (i.e., $R^2$ in this model) vs. the sum of the $\Delta R^2$ for the two othogonal contrasts?
:::

:::{.fragment}
[The $\Delta R^2$ for the two contrasts WILL sum to the model $R^2$.]{style="color:blue;"}
:::

--------------------------------------------------------------------------------

Lets confirm
```{r}
#| code-fold: true

preds |> 
  ggplot(aes(x = group, y = fit)) +
  geom_col(color = "black", fill = "light grey") +
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +
  labs(y = "Health", x = NULL)

m_poc <- lm(health ~ patient_v_control + alcohol_v_depress, data = data)
```


Model $R^2$
```{r}
glance(m_poc)$r.squared
```


$\Delta R^2$ for patient vs. control 
```{r}
delta_r2(lm(health ~ alcohol_v_depress, data = data), m_poc)
```


$\Delta R^2$ for alcohol vs. depress
```{r}
delta_r2(lm(health ~ patient_v_control, data = data), m_1)
```
:::

--------------------------------------------------------------------------------

## Single and Multiple Comparisons 

::: {.callout-important}
# Question
What do you gain from testing the main effect of a categorical variable that has more than 2 levels? What do you not gain?
:::

:::{.fragment}
[You learn that some contrast across the groups/conditions in some set of orthogonal contrasts is significant. Does this really tell you something interesting?]{style="color:blue;"}        

[You do NOT learn which groups are different from each other. In almost all instances our question is about differences between groups (or combinations of groups; or patterns across groups). We need contrasts.]{style="color:blue;"}        
[The test of the main effect is not needed (with one exception) to reduce the probability of making any Type I errors (false alarms). In many instances, it will increase the probability of Type II errors (misses). This is a **big** misconception in our field.]{style="color:blue;"}    
:::

--------------------------------------------------------------------------------

**Option 1: POCs**   

Test and report results for the parameter estimates for the planned orthogonal contrasts
```{r}
#| code-fold: true
m_poc |> tidy()
```

--------------------------------------------------------------------------------

**Option 2: Planned non-orthogonal pairwise comparisons with dummy approach**    

- Test only contrasts with same reference

```{r}
#| code-fold: true

contrasts(data$group) <- contr.treatment(levels(data$group), base = 3)
m_3 <- lm(health ~ group, data = data)
tidy(m_3)
```

- Test all pairwise contrasts (e.g., fit models with other references to get remaining contrasts)

```{r}
#| code-fold: true

contrasts(data$group) <- contr.treatment(levels(data$group), base = 2)
m_2 <- lm(health ~ group, data = data)
tidy(m_2)
```

--------------------------------------------------------------------------------

**Option 3: Unplanned; observed patterns of means dictate comparisons**   

```{r}
data |> 
  group_by(group) |> 
  summarise(mean = mean(health))
```

You might test any combination of pairwise or more complicated contrasts

--------------------------------------------------------------------------------

::: {.callout-important}
# Question
What validity concerns do we need to evaluate for these various options?
:::

:::{.fragment}
[Statistical/conclusion validity.]{style="color:blue;"}     

[1. Do results clearly support your theory (fundamental)?]{style="color:blue;"} 

[2. Probability of Type 1 error.]{style="color:blue;"}     

[3. Probability of Type 2 error.]{style="color:blue;"}     

[We should wonder (and be concerned about) what happens to the probability of making an error across *all* of our tests.]{style="color:blue;"} 
:::

--------------------------------------------------------------------------------

**Test-wise error rate:** The probability of making a type I (or II) error for any specific statistical test. 

[What is it for type I and type II?]{style="color:red;"}

**Family-wise error rate:** The probability of making a type I (or II) error among a *family* of statistical tests reported (and performed).   

**Experiment-wise error rate:** The probability of making a type I (or II) error among all statistical tests reported (and performed).   

**Bonferroni Inequality:**   

- $alpha_{set} \le set\_size*alpha_{test}$

--------------------------------------------------------------------------------

- In Psychology, we are generally concerned with test-wise and family-wise error rates (and most discussion is about Type I errors).  

- Orthogonal effects in factorial ANOVA (e.g., two main effects and interaction in 2-way ANOVA) are typically considered to come from different families (different questions).

- POCs within a multi-df effect are typically considered to come from different families. This makes most sense if the contrasts are testing clearly different questions.

- Non-orthogonal contrasts within multi-df effect are clearly related (in same family).

--------------------------------------------------------------------------------

::: {.callout-important}
# Question
What do we now know about statistical validity for POC approaches?
:::

:::{.fragment}
[Can only use POCs when your research questions map onto $n_{levels}-1$ orthogonal predictions.]{style="color:blue;"}    

[Need to proceed cautiously because statistical results may support predictions but patterns of means may undermine your conclusions (pharmacological and expectancy example - draw graphs for two scenarios).]{style="color:blue;"}     

[Must be comfortable with these contrasts testing *different* questions and therefore being in different families.]{style="color:blue;"}
:::

--------------------------------------------------------------------------------

::: {.callout-important}
# Question
What do we do with multiple planned, non-orthogonal contrasts, and worse still unplanned contrasts?
:::

:::{.fragment}
**Many** procedures exist. Kirk summarizes more but...

[**For planned, non-orthogonal**]{style="color:blue;"}         

- **Fisher LSD** is reasonable with planned, non-orthogonal contrasts for 3 level variables (family-wise alpha controlled and reasonable power).   

- **Holm-Bonferonni** is most flexible but need to keep planned contrasts to a minimum (family-wise type I is strictly controlled, but power drops with increasing number of contrasts). Fisher LSD may be more powerful in some instances with 3 level variables.    


[**For post-hoc/unplanned**]{style="color:blue;"}        

- **Scheffe** can be used when you can't limit yourself a priori. Power sucks!   
:::

--------------------------------------------------------------------------------

## Fisher LSD (Protected Testing)

1. First test omnibus (multi-df) effect (main effect or interaction). If non-significant, stop.    

2. If omnibus effect is significant, test pairwise comparisons among groups/conditions using dummy codes (other contrasts may be used if planned). No additional “protection” is needed.   

::: {.callout-important}
# Question
How is family-wise alpha controlled?
:::

:::{.fragment}
[Only proceed when omnibus test indicates some comparison is significant (see monte carlo of null main effect).]{style="color:blue;"}     

[Problems emerge if omnibus is significant but you do multiple tests, only some of which are significant. Not a problem, generally, with 3 level variable and 3 tests (e.g. pairwise comparisons). Inadequate with more levels (monte-carlo for three group with effect; thought experiment with 1 significant group difference in 4 level).]{style="color:blue;"}    
:::

--------------------------------------------------------------------------------

## Holm-Bonferroni Method

1. Suppose there are $k$ null hypotheses to be tested and the overall type I error rate is $\alpha$. 

2. Order the tests from smallest to largest p-value.

3. Multiply the smallest p-value by $k$ and compare to $\alpha$. If reject, continue. 

4. Multiply the next smallest p-value by $k-1$. Its new p-value is the max of this p-value and all preceding it.

5. Continue doing this until a hypothesis cannot be rejected. At that point, stop and accept all remaining hypotheses.

NOTE: Does **NOT** require significant omnibus test for type I protection.

:::{.footer}
Holm, S. (1979). A simple sequentially rejective multiple test procedure. *Scandinavian Journal of Statistics*, 6 (2): 65–70.
:::

--------------------------------------------------------------------------------

Here are some p-values for a set of 7 planned comparisons
```{r}
(p = c(.001, .009, .005, .100, .200, .040, .011))
```

Bonerroni adjusts them by multipying each by 7.  Too conservative! (low power)
```{r}
p.adjust(p, method= 'bonferroni')
```

Holm-Bonferroni adjusts them in a stepwise fashion.  

- Always better than Boneferroni
- Provides good protection against inflation of Type I errors
- Power drops (Type II increases) as number of comparisons/tests increases
- Easy to apply to any statistical tests
```{r}
p.adjust(p, method= 'holm')
```

--------------------------------------------------------------------------------

## Scheffe Test

1. Adjust the F-statistic for each comparison by dividing it by (number of groups - 1).
2. Get new p-value using: `pf(F, df1, df2, lower.tail = FALSE)`.

- Can be used for complete exploratory comparisons.
- Test of omnibus effect is **not** required. 
- If you are working with t values, square them to convert to F before dividing.
- Provides good alpha protection (Type I errors). 
- Very conservative with high Type II errors.