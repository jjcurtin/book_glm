--- 
output: html_document 
editor_options:  
  chunk_output_type: console
--- 
 

# Inferences about Two Continuous Predictors and their Interaction

```{r}
#| echo: false

options(scipen = 999) # turns off scientfic notation
options(knitr.kable.NA = '')
```


## Interactive Models: Two Quantitative Variables

**Example:**   

Effect of positive attitudes (1-5) about birth control and peer pressure to not use birth control (1-5) on intention to use birth control (0-30) among sexually active female adolescents.


```{r}
#| message: false

library(tidyverse)
library(patchwork)

theme_set(theme_classic()) 

path_data <- "data_lecture"

data <- read_csv(here::here(path_data, "10_interactions_birth_control.csv"),
                 show_col_types = FALSE) |> 
  glimpse()
```

-----

```{r}
data |> 
  pivot_longer(att:bc, names_to = "var") |> 
  group_by(var) |> 
  summarise(mean = mean(value), 
            sd = sd(value), 
            min = min(value), 
            max = max(value))
```


-----

<span style="color: red;">Question: If you regressed BC on Att and PP in two separate linear models, what can you tell me about these two models based on the correlations below?</span>

```{r}
data |> 
  select(-subid) |> 
  cor()
```


-----

<span style="color: blue;">Regression coefficient for Att will be positive. Regression coefficient for PP will be negative. $R^2$ will be bigger for Att model ($R^2$ = .56) than for PP model ($R^2$ = .25)</span>

-----

```{r}
m_att <- lm (bc ~ att, data = data)

broom::tidy(m_att)

broom::glance(m_att)$r.squared
```

```{r}
m_pp <- lm (bc ~ pp, data = data)

broom::tidy(m_pp)

broom::glance(m_pp)$r.squared
```


-----

<span style="color: red;">Question: Based on the correlations, what can you tell me about the model including both Att and PP as regressors?</span>

```{r}
data |> 
  select(-subid) |> 
  cor()
```

-----

<span style="color: blue;">The regression coefficients for Att and PP will match the coefficients from their respective bivariate models b/c Att and PP are fully orthogonal (uncorrelated). PP and Att each predict fully unique variance in BC.</span>   

<span style="color: blue;">The $R^2$ for the additive model will be equal to the sum of the $R^2$s from the two bivariate models, again b/c Att and PP are orthogonal.</span>

-----

<span style="color: red;">Question: What about $\eta_p^2$ for Att (or PP) in the 1 predictor model vs. the 2 predictor model? Specify the augmented and compact models to test Att for 1 and 2 predictor approaches. Specify the formula for $\eta_p^2$.</span>

-----

<span style="color: blue;">**Test for Att in 1 predictor model:**</span>   

<span style="color: blue;">$\text{BC}_a = b_0 + b_1*\text{Att}$</span>    
<span style="color: blue;">$\text{BC}_c = b_0 + 0*\text{Att}$</span>    


<span style="color: blue;">**Test for Att in 2 predictor model:**</span>   

<span style="color: blue;">$\text{BC}_a = b_0 + b_1*\text{Att} + b_2*\text{PP}$</span>  
<span style="color: blue;">$\text{BC}_c = b_0 + 0*\text{Att}+ b_2*\text{PP}$</span>   


<span style="color: blue;">$\eta_p^2 = \frac{\text{SSE}_c - \text{SSE}_a}{\text{SSE}_c}$</span>   

- <span style="color: blue;">Numerator is same for the both 1 and 2 predictor tests of Att.</span>   
- <span style="color: blue;">Denominator is smaller for 2 predictor test.</span>   
- <span style="color: blue;">Therefore, $\eta_p^2$ for Att is bigger in 2 predictor model. Att produces a bigger proportional reduction in error.</span>

-----


<span style="color: red;">Question: What about $\Delta R^2$ for Att (or PP) in the 1 predictor model vs. the 2 predictor model? Specify the augmented and compact models to test Att for 1 and 2 predictor approaches. Specify the formula for $\Delta R^2$.</span>

-----

<span style="color: blue;">**Test for Att in 1 predictor model:**</span>   

<span style="color: blue;">$\text{BC}_a = b_0 + b_1*\text{Att}$</span>    
<span style="color: blue;">$\text{BC}_c = b_0 + 0*\text{Att}$</span>    


<span style="color: blue;">**Test for Att in 2 predictor model:**</span>   

<span style="color: blue;">$\text{BC}_a = b_0 + b_1*\text{Att} + b_2*\text{PP}$</span>  
<span style="color: blue;">$\text{BC}_c = b_0 + 0*\text{Att}+ b_2*\text{PP}$</span>   


<span style="color: blue;">$\Delta R^2 = \frac{\text{SSE}_c - \text{SSE}_a}{\text{SSE}_\text{mean only}}$</span>   

- <span style="color: blue;">Numerator is same for the both 1 and 2 predictor tests of Att.</span>   
- <span style="color: blue;">Denominator is same for both 1 and 2 predictor tests.</span>   
- <span style="color: blue;">Therefore, $\Delta R^2$ for Att does not change. Att explains the same proportion of **total** variance (error) in both models.</span>

-----

```{r}
m_add <- lm(bc ~ att + pp, data = data)

broom::tidy(m_add)
```

$\text{BC} = 8.0 + 3.0 * \text{Att} + -2.0*\text{PP}$   


<span style="color: red;">Question: What has this model required (or what havent we tested for)?</span>

-----

<span style="color: blue;">It requires that the effect of each IV on the DV is constant across all levels/scores of the other IV.</span>   

<span style="color: blue;">We have not tested for an interaction.</span>

-----

<span style="color: red;">Question: Where are $b_\text{Att}, b_\text{PP},$ and $b_0$ in the figure below?</span>

```{r}
#| code-fold: true

preds <- expand.grid(att = 1:5, pp = c(1, 3, 5))
preds_y <- predict(m_add, newdata = preds)

plot_m_add <- ggplot() +
  geom_line(aes(x = preds$att, y = preds_y, color = factor(preds$pp)), 
            linewidth = 1) +
  labs(x = "Attitude about Birth Control",
       y = "Birth Control Use",
       color = "Peer Pressure") 

plot_m_add
```

-----

<span style="color: blue;">$b_\text{Att}$ = slope of lines. Constant for all three lines.</span>    

<span style="color: blue;">$b_\text{PP}$ = separation of lines. Lines are separated by $2*b_\text{PP}$. Constant across Att.</span>    

<span style="color: blue;">$b_0$ = predicted value at Att = 0 and PP= 0. Not displayed in figure.</span> 

-----

<span style="color: red;">Question: How might we benefit from including a third regressor in the model to represent the interaction between Att and PP? Hint, there are two benefits.</span>

-----

1. <span style="color: blue;">If Att X PP effect is significant, it will increase $R^2$, decrease SEs, and therefore increase power to test all effects.</span>   

2. <span style="color: blue;">If Att X PP is significant, it will provide us with a more complex, nuanced perspective on the nature of the Att and PP effects on BC.</span>  

**Definition: An interaction exists when the effect of 1 predictor on the DV differs across levels/values of the other predictor.**  

<!-- John, you also had this note on your slide "LINK to additive results in this example…" I wasn't sure what it meant-->

-----

- Regressors for interaction terms are calculated as the product of the regressors (for the predictors) in the interaction. In this case, we simply multiply Att X PP.   

- You will typically want to **center** the IVs in the primary model to yield tests of *main effects* of each IV as well as tests of the interaction (More on this as the slides develop).     

- In R, you don’t need to actually compute the product term regressor directly. `A:B` in the `lm()` formula will include the A X B interaction regressor(s).    

- `A*B` is further shorthand to include A, B, and A X B in the model.   

- You should **not** include A X B in a model that does not include lower order effects (e.g., A, and B).    

-----

<span style="color: red;">Question: What will change in the two predictor model if we center both IVs?</span>

-----

1. <span style="color: blue;">$b_0$ and its SE will change. $b_0$ is the predicted value at 0 on all regressors in the model.</span> <span style="color: red;">Will SE be bigger or smaller in centered model?</span>    

2. <span style="color: blue;">$b_\text{Att}$ and $b_\text{PP}$ (and their SEs) will remain the same. The additive model forces the effect for each IV to be same across all values of other regressors. Therefore, the effect of ATT is the same if PP = 0 or PP= 1, or PP=3, etc. Given this, centering PP does not change $b$ for ATT.</span>    

3. <span style="color: blue;">Of course, $R^2$ also remains the same.</span>

-----

```{r}
broom::tidy(m_add)
broom::glance(m_add)$r.squared
```

```{r}
data <- data |> 
  mutate(att_c = att - mean(att),
         pp_c = pp - mean(pp))

m_add_c <- lm(bc ~ att_c + pp_c, data = data)

broom::tidy(m_add_c)
broom::glance(m_add_c)$r.squared
```

-----

<span style="color: red;">Question: What will change when we add the interaction term (with centered IVs) relative to the centered two predictor model?</span>

-----

1. <span style="color: blue;">An additional regressor will be included for Att x PP.</span>  

2. <span style="color: blue;">If Att x PP accounts for DV variance, $R^2$ will increase and SEs for coefficients (and intercept) will be reduced.</span>  

3. <span style="color: blue;">$b_0$ will remain the predicted value at 0 for all regressors. No change from centered two predictor model.</span>  

4. <span style="color: blue;">$b_\text{Att}$ and $b_\text{PP}$ are respective effects at 0 on all other regressors. Including an interaction now allows for each IV effect to vary across levels/values of other IVs.</span>    

    <span style="color: blue;">Thus, $b_\text{Att}$ is now the (*simple*) effect of Att at PP (centered) = 0 and the $b_\text{PP}$ is now the (*simple*) effect of PP at Att (centered) = 0.</span>  

-----

## Main Effects and Simple Effects

In ANOVA terms, The **Main Effect** of an IV is the overall effect of that IV on the DV averaging across the levels of the other IV(s) in the model.      

A **Simple Effect** of an IV is the effect of that IV at a specific level of the other IV(s) in the model.     

From this perspective, you can think about a main effect as a special simple effect where the specific level of the other IV is its average value.    


-----

```{r}
m_int_c <- lm(bc ~ att_c * pp_c, data = data)

broom::tidy(m_int_c)
broom::glance(m_int_c)$r.squared
```

```{r}
broom::tidy(m_add_c)
broom::glance(m_add_c)$r.squared
```

-----

$\text{BC} = 11.0 + 3.0 * \text{Att}_c + -2.0*\text{PP}_c$    

$\text{BC} = 11.0 + 3.0 * \text{Att}_c + -2.0*\text{PP}_c + -1.0*\text{Att}_c*\text{PP}_c$     


<span style="color: red;">Link intercepts and coefficients from each model to their respective figures.</span>    

*Note:* figures use raw (not centered) predictors. Means for both predictors are 3.


```{r}
#| code-fold: true
m_int <- lm(bc ~ att * pp, data = data)

preds_int_y <- predict(m_int, newdata = preds)

plot_m_int <- ggplot() +
  geom_line(aes(x = preds$att, y = preds_int_y, color = factor(preds$pp)), 
            linewidth = 1) +
  labs(x = "Attitude about Birth Control",
       y = "Birth Control Use",
       color = "Peer Pressure") 

plot_m_add + plot_m_int
```


-----

$\text{BC} = 11.0 + 3.0 * \text{Att}_c + -2.0*\text{PP}_c + -1.0*\text{Att}_c*\text{PP}_c$     

<span style="color: red;">Question: What would the interactive model look like if we hadn’t centered each IV?</span>   

-----

```{r}
m_int <- lm(bc ~ att * pp, data = data) 

broom::tidy(m_int)

broom::glance(m_int)$r.squared
```

-----

$\text{BC} = 11.0 + 3.0 * \text{Att}_c + -2.0*\text{PP}_c + -1.0*\text{Att}_c*\text{PP}_c$ 

$\text{BC} = -1.0 + 6.0 * \text{Att} + 1.0*\text{PP} + -1.0*\text{Att}*\text{PP}$   

<span style="color: red;">Link intercept and coefficients from the raw model to the expanded figure below on right.</span>   

```{r}
#| code-fold: true

preds_expanded <- expand.grid(att = 0:5, pp = 0:5)
preds_int_y_expanded <- predict(m_int, newdata = preds_expanded)

plot_m_int_expanded <- ggplot() +
  geom_line(aes(x = preds_expanded$att, y = preds_int_y_expanded, 
                color = factor(preds_expanded$pp)), 
            linewidth = 1) +
  labs(x = "Attitude about Birth Control",
       y = "Birth Control Use",
       color = "Peer Pressure") 

plot_m_int + plot_m_int_expanded
```

-----

$\text{BC} = 11.0 + 3.0 * \text{Att}_c + -2.0*\text{PP}_c + -1.0*\text{Att}_c*\text{PP}_c$ 

$\text{BC} = -1.0 + 6.0 * \text{Att} + 1.0*\text{PP} + -1.0*\text{Att}*\text{PP}$    


<span style="color: red;">Question: So what does $b_{\text{Att}*\text{PP}}$ indicate?</span>   

-----

<span style="color: blue;">The coefficient for the interaction indicates how the simple effect of each IV changes for a one unit increase on the other IV.</span>    


**The interaction coefficient applies symmetrically to both IV effects.**

-----

Considering Att in raw model:   

- Att effect is 6 for PP = 0    
- Att effect is 5 for PP = 1    
- Att effect is 4 for PP = 2    
- Att effect is 3 for PP = 3   
- Att effect is 2 for PP = 4   
- Att effect is 1 for PP = 5    

```{r}
#| code-fold: true

plot_m_int_expanded
```

-----

Considering PP in raw model:   

- PP effect is 1 for Att = 0   
- PP effect is 0 for Att = 1    
- PP effect is -1 for Att = 2    
- PP effect is -2 for Att = 3    
- PP effect is -3 for Att = 4    
- PP effect is -4 for Att = 5     

```{r}
#| code-fold: true

plot_m_int_expanded
```

-----

## Interactive Models: Coefficient Magnitudes

- Interaction and its test is obtained from any model (regardless of centering).    

- *Main* effects of IVs are obtained from model with all IVs centered on mean. You may or may not choose to report these main effects depending on the situation.     

- Magnitude of *simple* effects of either IV can be calculated directly from the raw or centered model (I prefer the raw model for ease of thinking in raw units). <span style="color: red;">How?</span>

-----

## Interactive Models: Raw Model Coefficients

```{r}
m_int <- lm(bc ~ att * pp, data = data) 
broom::tidy(m_int)
```

-----

## Interactive Models: Simple Effect Magnitudes

Magnitude of *simple* effects of either IV can be calculated directly from the raw or centered model (I prefer the raw model for ease of thinking in raw units). <span style="color: red;">How?</span>   

$\text{BC} = -1.0 + 6.0 * \text{Att} + 1.0*\text{PP} + -1.0*\text{Att}*\text{PP}$   

<span style="color: blue;">Effect of Att = 6.0 + -1.0 * PP</span>    
<span style="color: blue;">Effect of PP = 1.0 + -1.0 * Att</span>     

<span style="color: red;">Question: How could you obtain formal significance tests for any specific simple effects (e.g., effect of Att at PP = 1, 3, & 5)?</span>

-----

$\text{BC} = -1.0 + 6.0 * \text{Att} + 1.0*\text{PP} + -1.0*\text{Att}*\text{PP}$   

<span style="color: blue;">Effect of Att = 6.0 + -1.0 * PP</span>    
<span style="color: blue;">Effect of Att = 6.0 + -1.0 * (1) = 5</span>    

```{r}
data <- data |> 
  mutate(pp_1 = pp - 1)

m_pp_1 <- lm(bc ~ att * pp_1, data = data)
broom::tidy(m_pp_1)
```


-----


$\text{BC} = -1.0 + 6.0 * \text{Att} + 1.0*\text{PP} + -1.0*\text{Att}*\text{PP}$   

<span style="color: blue;">Effect of Att = 6.0 + -1.0 * PP</span>    
<span style="color: blue;">Effect of Att = 6.0 + -1.0 * (5) = 1</span>    

```{r}
data <- data |> 
  mutate(pp_5 = pp - 5)

m_pp_5 <- lm(bc ~ att * pp_5, data = data)
broom::tidy(m_pp_5)
```

-----

## Interactive Models: Reporting Considerations

<span style="color: red;">Question: So what do you report and in what order?</span>

-----

<span style="color: blue;">There is no one answer here.  Some say you never report main effects when there are significant interactions.  This camp would say, report only interaction and possibly simple effects.</span>    

<span style="color: blue;">Others (including me) believe that main effects are sometimes useful to report even when interaction is significant. *Main* effects (effect at “mean” of other IV) provides an anchor for effect. The interaction then indicates how this effect changes across values of the other IV. *Simple* effects can sometimes allow you to describe further how this effect changes at various values of other IV.</span>    

<span style="color: blue;">The other complexity surrounds the nature of the two IVs.  Sometimes, often, one is focal and one is moderator. However, sometimes neither/both are focal...</span>

-----

## Interactive Models: Sample Report

*A sample brief report: Attitudes are focal, main effect and simple effects reported.*   

We analyzed birth control use in a General Linear Model with Positive Attitudes about Birth Control (ATT) and Negative Peer Pressure (PP) as quantitatively measured predictors. We also included the interaction between these two predictors in the model. We mean-centered all predictors.   

The overall model accounted for a significant amount of variance in Birth Control use, $R^2= 0.94, F(3,121) = 605.00, p < .001$.  The effect of ATT was significant, 95% CI(b) = [2.8, 3.2], $\Delta R^2 = 0.56, t(121) = 33.00, p < .001$, such that birth control use increased by 3 units for every one unit increase in positive attitudes about birth control for participants who experienced average peer pressure (i.e., PP=3). However, PP significantly moderated the ATT effect on Birth Control, 95% CI(b)= [-1.1, -0.9], $\Delta R^2 = 0.13, t(121) = 15.56, p < .001$, indicating that the magnitude of the ATT effect decreased for every one unit increase in PP (see Figure 1).  Despite this, the simple effects of ATT remained significant across meaningful levels of PP.  For example, the simple effect of ATT for participants who were experiencing high negative peer pressure (i.e., PP = 5) was significant, 95% CI(b)= [0.7, 1.3], $\Delta R^2 = 0.02, t(121) = 6.35, p < .001$.  The simple effect of ATT for participants who were experiencing low negative peer pressure (PP=1) was also significant, 95% CI(b)= [4.7, 5.3], $\Delta R^2 = 0.52, t(121)= 31.75, p < .001$.  

-----

```{r}
preds_pub <- expand.grid(att = 1:5, pp = c(2, 4))
preds_pub_y <- predict(m_int, newdata = preds_pub, se.fit = TRUE) 

preds_pub <- preds_pub |> 
  bind_cols(preds_pub_y) |> 
  as_tibble() |>  
  mutate(upper = fit + se.fit,
         lower= fit - se.fit)

plot_pub <- preds_pub |> 
  ggplot() +
  geom_ribbon(aes(x = att, ymin = lower, ymax = upper, group = factor(pp)), 
              alpha = 0.4) +
  geom_line(aes(x = att, y = fit, 
                color = factor(pp)), 
            linewidth = 1) +
  labs(x = "Attitude about Birth Control",
       y = "Birth Control Use",
       color = "Peer Pressure") 
```

-----

```{r}
plot_pub
```


-----

## Two Quantitative Variables: Summary

For two quantitative IVs, you now know:   

- How to quantify and test *main* effects (effect of IV at mean of other IV).   
- How to quantify and test for interaction.   
- How to quantify and test *simple* effects of each IV at levels of other IV.   
- How to graphically display effects.    

In case it wasn’t obvious, this is the conceptual equivalent of a factorial ANOVA with two quantitative (rather than categorical) IVs.   
